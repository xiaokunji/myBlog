<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>airflow | 米二</title><meta name=keywords content=" 1. 简介, 2、Airflow 的服务构成, 3. Airflow 的 Web 界面, 1、DAG 列表, 2、作业操作框, 4. DAG 配置, -*- coding: utf-8 -*-, 用[]可以并行执行多个job,task >> [job1,job2], 等同于 task.set_downstream(run_this_last)"><meta name=description content="     "><meta name=author content="xkj"><link rel=canonical href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/airflow/airflow.html><link crossorigin=anonymous href=/assets/css/stylesheet.b3faf608c544858ba700943ffe182cb647f38432d29a07d73234965beacb26f6.css integrity="sha256-s/r2CMVEhYunAJQ//hgstkfzhDLSmgfXMjSWW+rLJvY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=16x16 href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=32x32 href=https://xiaokunji.com/img/Q.svg><link rel=apple-touch-icon href=https://xiaokunji.com/Q.svg><link rel=mask-icon href=https://xiaokunji.com/Q.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/airflow/airflow.html><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="airflow"><meta property="og:description" content="     "><meta property="og:type" content="article"><meta property="og:url" content="https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/airflow/airflow.html"><meta property="article:section" content="hadoop生态圈"><meta property="article:published_time" content="2022-08-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-04T11:26:13+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="airflow"><meta name=twitter:description content="     "><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"airflow","item":"https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/airflow/airflow.html"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"airflow","name":"airflow","description":"     ","keywords":[" 1. 简介"," 2、Airflow 的服务构成"," 3. Airflow 的 Web 界面"," 1、DAG 列表"," 2、作业操作框"," 4. DAG 配置"," -*- coding: utf-8 -*-"," 用[]可以并行执行多个job, task \u003e\u003e [job1,job2]"," 等同于 task.set_downstream(run_this_last)"],"articleBody":"[toc]\n1. 简介 Airflow是一个可编程，调度和监控的工作流平台，基于有向无环图(DAG)，airflow可以定义一组有依赖的任务，按照依赖依次执行。airflow提供了丰富的命令行工具用于系统管控，而其web管理界面同样也可以方便的管控调度任务，并且对任务运行状态进行实时监控，方便了系统的运维和管理。\nAirflow 中常见的名词概念：\nDAG\nDAG 意为有向无循环图，在 Airflow 中则定义了整个完整的作业。同一个 DAG 中的所有 Task 拥有相同的调度时间。\nTask\nTask 为 DAG 中具体的作业任务，它必须存在于某一个 DAG 之中。Task 在 DAG 中配置依赖关系，跨 DAG 的依赖是可行的，但是并不推荐。跨 DAG 依赖会导致 DAG 图的直观性降低，并给依赖管理带来麻烦。\nDAG Run\n当一个 DAG 满足它的调度时间，或者被外部触发时，就会产生一个 DAG Run。可以理解为由 DAG 实例化的实例。\nTask Instance\n当一个 Task 被调度启动时，就会产生一个 Task Instance。可以理解为由 Task 实例化的实例。\n2、Airflow 的服务构成 一个正常运行的 Airflow 系统一般由以下几个服务构成\nWebServer\n​\tAirflow 提供了一个可视化的 Web 界面。启动 WebServer 后，就可以在 Web 界面上查看定义好的 DAG 并监控及改变运行状况。也可以在 Web 界面中对一些变量进行配置。\nWorker\n​\t一般来说我们用 Celery Worker 来执行具体的作业。Worker 可以部署在多台机器上，并可以分别设置接收的队列。当接收的队列中有作业任务时，Worker 就会接收这个作业任务，并开始执行。Airflow 会自动在每个部署 Worker 的机器上同时部署一个 Serve Logs 服务，这样我们就可以在 Web 界面上方便的浏览分散在不同机器上的作业日志了。\nScheduler\n​\t整个 Airflow 的调度由 Scheduler 负责发起，每隔一段时间 Scheduler 就会检查所有定义完成的 DAG 和定义在其中的作业，如果有符合运行条件的作业，Scheduler 就会发起相应的作业任务以供 Worker 接收。\nFlower\n​\tFlower 提供了一个可视化界面以监控所有 Celery Worker 的运行状况。这个服务并不是必要的。\n3. Airflow 的 Web 界面 1、DAG 列表 DAG 列表\n左侧 On/Off 按钮控制 DAG 的运行状态，Off 为暂停状态，On 为运行状态。注意：所有 DAG 脚本初次部署完成时均为 Off 状态。 若 DAG 名称处于不可点击状态，可能为 DAG 被删除或未载入。若 DAG 未载入，可点击右侧刷新按钮进行刷新。注意：由于可以部署若干 WebServer，所以单次刷新可能无法刷新所有 WebServer 缓存，可以尝试多次刷新。 Recent Tasks 会显示最近一次 DAG Run（可以理解为 DAG 的执行记录）中 Task Instances（可以理解为作业的执行记录）的运行状态，如果 DAG Run 的状态为 running，此时显示最近完成的一次以及正在运行的 DAG Run 中所有 Task Instances 的状态。 Last Run 显示最近一次的 execution date。注意：execution date 并不是真实执行时间，具体细节在下文 DAG 配置中详述。将鼠标移至 execution date 右侧 info 标记上，会显示 start date，start date 为真实运行时间。start date 一般为 execution date 所对应的下次执行时间。 2、作业操作框 在 DAG 的树状图和 DAG 图中都可以点击对应的 Task Instance 以弹出 Task Instance 模态框，以进行 Task Instance 的相关操作。注意：选择的 Task Instance 为对应 DAG Run 中的 Task Instance。\n作业操作框\n在作业名字的右边有一个漏斗符号，点击后整个 DAG 的界面将只显示该作业及该作业的依赖作业。当该作业所处的 DAG 较大时，此功能有较大的帮助。 Task Instance Details 显示该 Task Instance 的详情，可以从中得知该 Task Instance 的当前状态，以及处于当前状态的原因。例如，若该 Task Instance 为 no status 状态，迟迟不进入 queued 及 running 状态，此时就可通过 Task Instance Details 中的 Dependency 及 Reason 得知原因。 Rendered 显示该 Task Instance 被渲染后的命令。 Run 指令可以直接执行当前作业。 Clear 指令为清除当前 Task Instance 状态，清除任意一个 Task Instance 都会使当前 DAG Run 的状态变更为 running。注意：如果被清除的 Task Instance 的状态为 running，则会尝试 kill 该 Task Instance 所执行指令，并进入 shutdown 状态，并在 kill 完成后将此次执行标记为 failed（如果 retry 次数没有用完，将标记为 up_for_retry）。Clear 有额外的5个选项，均为多选，这些选项从左到右依次为： Past: 同时清除所有过去的 DAG Run 中此 Task Instance 所对应的 Task Instance。 Future: 同时清除所有未来的 DAG Run 中此 Task Instance 所对应的 Task Instance。注意：仅清除已生成的 DAG Run 中的 Task Instance。 Upstream: 同时清除该 DAG Run 中所有此 Task Instance 上游的 Task Instance。 Downstream: 同时清除该 DAG Run 中所有此 Task Instance 下游的 Task Instance。 Recursive: 当此 Task Instance 为 sub DAG 时，循环清除所有该 sub DAG 中的 Task Instance。注意：若当此 Task Instance 不是 sub DAG 则忽略此选项。 Mark Success 指令为讲当前 Task Instance 状态标记为 success。注意：如果该 Task Instance 的状态为 running，则会尝试 kill 该 Task Instance 所执行指令，并进入 shutdown 状态，并在 kill 完成后将此次执行标记为 failed（如果 retry 次数没有用完，将标记为 up_for_retry）。 4. DAG 配置 Airflow 中的 DAG 是由 Python 脚本来配置的，因而可扩展性非常强。Airflow 提供了一些 DAG 例子，\n# -*- coding: utf-8 -*- import airflow from airflow.operators.bash_operator import BashOperator from airflow.operators.dummy_operator import DummyOperator from airflow.models import DAG args = { 'owner': 'airflow', 'start_date': airflow.utils.dates.days_ago(2) # 作业的开始时间，即作业将在这个时间点以后开始调度。 } dag = DAG( dag_id='example_bash_operator', # 给 DAG 取一个名字,不能重复 default_args=args, schedule_interval='0 0 * * *' # 配置 DAG 的执行周期，语法和 crontab 的一致 ) cmd = 'ls -l' run_this_last = DummyOperator(task_id='run_this_last', dag=dag) run_this = BashOperator( task_id='run_after_loop', bash_command='echo 1', dag=dag) run_this.set_downstream(run_this_last) for i in range(3): i = str(i) task = BashOperator( task_id='runme_'+i, bash_command='echo \"{{ task_instance_key_str }}\" \u0026\u0026 sleep 1', dag=dag) task.set_downstream(run_this) task = BashOperator( task_id='also_run_this', bash_command='echo \"run_id={{ run_id }} | dag_run={{ dag_run }}\"', dag=dag) # 用[]可以并行执行多个job, task \u003e\u003e [job1,job2] # 等同于 task.set_downstream(run_this_last) task \u003e\u003e run_this_last 那么现在，让我们看一下当一个新配置的 DAG 生效后第一次调度会在什么时候。其实第一次调度时间是在作业中配置的 start date 的第二个满足 schedule interval 的时间点，并且记录的 execution date 为作业中配置的 start date 的第一个满足 schedule interval 的时间点.\n假设我们配置了一个作业的 start date 为 2017年10月1日，配置的 schedule interval 为 **00 12 * * *** 那么第一次执行的时间将是 2017年10月2日 12点 而此时记录的 execution date 为 2017年10月1日 12点。因此 execution date 并不是如其字面说的表示执行时间，真正的执行时间是 execution date 所显示的时间的下一个满足 schedule interval 的时间点。\n浅谈 实战 使用 搭建及问题 官网 ","wordCount":"2298","inLanguage":"zh","datePublished":"2022-08-22T00:00:00Z","dateModified":"2023-09-04T11:26:13.519235124Z","author":{"@type":"Person","name":"xkj"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/airflow/airflow.html"},"publisher":{"@type":"Organization","name":"米二","logo":{"@type":"ImageObject","url":"https://xiaokunji.com/img/Q.svg"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaokunji.com/zh/ accesskey=h title="米二 (Alt + H)"><img src=https://xiaokunji.com/img/Q.svg alt aria-label=logo height=35>米二</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaokunji.com/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://xiaokunji.com/zh/ title=🏠主页><span>🏠主页</span></a></li><li><a href=https://xiaokunji.com/zh/search title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://xiaokunji.com/zh/post.html title=📚文章><span>📚文章</span></a></li><li><a href=https://xiaokunji.com/zh/archives.html title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://xiaokunji.com/zh/tags.html title=🔖标签><span>🔖标签</span></a></li><li><a href=https://xiaokunji.com/zh/categories.html title=📖分类><span>📖分类</span></a></li><li><a href=https://xiaokunji.com/zh/links.html title=🤝友链><span>🤝友链</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><nav aria-label=breadcrumb><ul><a href=https://xiaokunji.com/zh/>🏠</a> <span>></span>
<a href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>hadoop生态圈</a> <span>></span>
<a href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/airflow.html>airflow</a> <span>></span></ul></nav><h1 class=post-title>airflow</h1><div class=post-description></div><div class=post-meta>创建:&nbsp;<span title='2022-08-22 00:00:00 +0000 UTC'>2022-08-22</span>&nbsp;·&nbsp;更新:&nbsp;2023-09-04&nbsp;·&nbsp;xkj
&nbsp;|&nbsp;分类: &nbsp;<ul class=post-categories-meta><a href=https://xiaokunji.com/zh/categories/Hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>Hadoop生态圈</a></ul><span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv>1</span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#1-%e7%ae%80%e4%bb%8b aria-label="1. 简介">1. 简介</a></li><li><a href=#2airflow-%e7%9a%84%e6%9c%8d%e5%8a%a1%e6%9e%84%e6%88%90 aria-label="2、Airflow 的服务构成">2、Airflow 的服务构成</a></li><li><a href=#3-airflow-%e7%9a%84-web-%e7%95%8c%e9%9d%a2 aria-label="3. Airflow 的 Web 界面">3. Airflow 的 Web 界面</a><ul><li><a href=#1dag-%e5%88%97%e8%a1%a8 aria-label="1、DAG 列表">1、DAG 列表</a></li><li><a href=#2%e4%bd%9c%e4%b8%9a%e6%93%8d%e4%bd%9c%e6%a1%86 aria-label=2、作业操作框>2、作业操作框</a></li></ul></li><li><a href=#4-dag-%e9%85%8d%e7%bd%ae aria-label="4. DAG 配置">4. DAG 配置</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>[toc]</p><h1 id=1-简介>1. 简介<a hidden class=anchor aria-hidden=true href=#1-简介>#</a></h1><p>Airflow是一个可编程，调度和监控的工作流平台，基于有向无环图(DAG)，airflow可以定义一组有依赖的任务，按照依赖依次执行。airflow提供了丰富的命令行工具用于系统管控，而其web管理界面同样也可以方便的管控调度任务，并且对任务运行状态进行实时监控，方便了系统的运维和管理。</p><p>Airflow 中常见的名词概念：</p><ul><li><p><strong>DAG</strong></p><p>DAG 意为有向无循环图，在 Airflow 中则定义了整个完整的作业。同一个 DAG 中的所有 Task 拥有相同的调度时间。</p></li><li><p><strong>Task</strong></p><p>Task 为 DAG 中具体的作业任务，它必须存在于某一个 DAG 之中。Task 在 DAG 中配置依赖关系，跨 DAG 的依赖是可行的，但是并不推荐。跨 DAG 依赖会导致 DAG 图的直观性降低，并给依赖管理带来麻烦。</p></li><li><p><strong>DAG Run</strong></p><p>当一个 DAG 满足它的调度时间，或者被外部触发时，就会产生一个 DAG Run。可以理解为由 DAG 实例化的实例。</p></li><li><p><strong>Task Instance</strong></p><p>当一个 Task 被调度启动时，就会产生一个 Task Instance。可以理解为由 Task 实例化的实例。</p></li></ul><h1 id=2airflow-的服务构成>2、Airflow 的服务构成<a hidden class=anchor aria-hidden=true href=#2airflow-的服务构成>#</a></h1><p>一个正常运行的 Airflow 系统一般由以下几个服务构成</p><ul><li><p><strong>WebServer</strong></p><p>​ Airflow 提供了一个可视化的 Web 界面。启动 WebServer 后，就可以在 Web 界面上查看定义好的 DAG 并监控及改变运行状况。也可以在 Web 界面中对一些变量进行配置。</p></li><li><p><strong>Worker</strong></p><p>​ 一般来说我们用 Celery Worker 来执行具体的作业。Worker 可以部署在多台机器上，并可以分别设置接收的队列。当接收的队列中有作业任务时，Worker 就会接收这个作业任务，并开始执行。Airflow 会自动在每个部署 Worker 的机器上同时部署一个 Serve Logs 服务，这样我们就可以在 Web 界面上方便的浏览分散在不同机器上的作业日志了。</p></li><li><p><strong>Scheduler</strong></p><p>​ 整个 Airflow 的调度由 Scheduler 负责发起，每隔一段时间 Scheduler 就会检查所有定义完成的 DAG 和定义在其中的作业，如果有符合运行条件的作业，Scheduler 就会发起相应的作业任务以供 Worker 接收。</p></li><li><p><strong>Flower</strong></p><p>​ Flower 提供了一个可视化界面以监控所有 Celery Worker 的运行状况。这个服务并不是必要的。</p></li></ul><p><img loading=lazy src=https://pic4.zhimg.com/80/v2-35a160b63e7389fe12f451e299ab0c00_720w.jpg alt=img></p><h1 id=3-airflow-的-web-界面>3. Airflow 的 Web 界面<a hidden class=anchor aria-hidden=true href=#3-airflow-的-web-界面>#</a></h1><h2 id=1dag-列表>1、DAG 列表<a hidden class=anchor aria-hidden=true href=#1dag-列表>#</a></h2><p><img loading=lazy src=https://upload-images.jianshu.io/upload_images/9094111-c4d1bb23df2557e3.png?imageMogr2/auto-orient/strip%7cimageView2/2/w/1169/format/webp alt=img></p><p>DAG 列表</p><ol><li>左侧 On/Off 按钮控制 DAG 的运行状态，Off 为暂停状态，On 为运行状态。注意：所有 DAG 脚本初次部署完成时均为 Off 状态。</li><li>若 DAG 名称处于不可点击状态，可能为 DAG 被删除或未载入。若 DAG 未载入，可点击右侧刷新按钮进行刷新。注意：由于可以部署若干 WebServer，所以单次刷新可能无法刷新所有 WebServer 缓存，可以尝试多次刷新。</li><li>Recent Tasks 会显示最近一次 DAG Run（可以理解为 DAG 的执行记录）中 Task Instances（可以理解为作业的执行记录）的运行状态，如果 DAG Run 的状态为 running，此时显示最近完成的一次以及正在运行的 DAG Run 中所有 Task Instances 的状态。</li><li>Last Run 显示最近一次的 execution date。注意：execution date 并不是真实执行时间，具体细节在下文 DAG 配置中详述。将鼠标移至 execution date 右侧 info 标记上，会显示 start date，start date 为真实运行时间。start date 一般为 execution date 所对应的下次执行时间。</li></ol><h2 id=2作业操作框>2、作业操作框<a hidden class=anchor aria-hidden=true href=#2作业操作框>#</a></h2><p>在 DAG 的树状图和 DAG 图中都可以点击对应的 Task Instance 以弹出 Task Instance 模态框，以进行 Task Instance 的相关操作。注意：选择的 Task Instance 为对应 DAG Run 中的 Task Instance。</p><p><img loading=lazy src=https://upload-images.jianshu.io/upload_images/9094111-b857d859b23a2650.png?imageMogr2/auto-orient/strip%7cimageView2/2/w/649/format/webp alt=img></p><p>作业操作框</p><ol><li>在作业名字的右边有一个漏斗符号，点击后整个 DAG 的界面将只显示该作业及该作业的依赖作业。当该作业所处的 DAG 较大时，此功能有较大的帮助。</li><li>Task Instance Details 显示该 Task Instance 的详情，可以从中得知该 Task Instance 的当前状态，以及处于当前状态的原因。例如，若该 Task Instance 为 no status 状态，迟迟不进入 queued 及 running 状态，此时就可通过 Task Instance Details 中的 Dependency 及 Reason 得知原因。</li><li>Rendered 显示该 Task Instance 被渲染后的命令。</li><li>Run 指令可以直接执行当前作业。</li><li>Clear 指令为清除当前 Task Instance 状态，<strong>清除任意一个 Task Instance 都会使当前 DAG Run 的状态变更为 running</strong>。注意：如果被清除的 Task Instance 的状态为 running，则会尝试 kill 该 Task Instance 所执行指令，并进入 shutdown 状态，并在 kill 完成后将此次执行标记为 failed（如果 retry 次数没有用完，将标记为 up_for_retry）。Clear 有额外的5个选项，均为多选，这些选项从左到右依次为：<ul><li><strong>Past</strong>: 同时清除所有过去的 DAG Run 中此 Task Instance 所对应的 Task Instance。</li><li><strong>Future</strong>: 同时清除所有未来的 DAG Run 中此 Task Instance 所对应的 Task Instance。注意：仅清除已生成的 DAG Run 中的 Task Instance。</li><li><strong>Upstream</strong>: 同时清除该 DAG Run 中所有此 Task Instance 上游的 Task Instance。</li><li><strong>Downstream</strong>: 同时清除该 DAG Run 中所有此 Task Instance 下游的 Task Instance。</li><li><strong>Recursive</strong>: 当此 Task Instance 为 sub DAG 时，循环清除所有该 sub DAG 中的 Task Instance。注意：若当此 Task Instance 不是 sub DAG 则忽略此选项。</li></ul></li><li>Mark Success 指令为讲当前 Task Instance 状态标记为 success。注意：如果该 Task Instance 的状态为 running，则会尝试 kill 该 Task Instance 所执行指令，并进入 shutdown 状态，并在 kill 完成后将此次执行标记为 failed（如果 retry 次数没有用完，将标记为 up_for_retry）。</li></ol><h1 id=4-dag-配置>4. DAG 配置<a hidden class=anchor aria-hidden=true href=#4-dag-配置>#</a></h1><p>Airflow 中的 DAG 是由 Python 脚本来配置的，因而可扩展性非常强。Airflow 提供了一些 DAG 例子，</p><div class=highlight><pre tabindex=0 style=color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#8b949e;font-style:italic># -*- coding: utf-8 -*-</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>import</span> <span style=color:#ff7b72>airflow</span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>from</span> <span style=color:#ff7b72>airflow.operators.bash_operator</span> <span style=color:#ff7b72>import</span> BashOperator
</span></span><span style=display:flex><span><span style=color:#ff7b72>from</span> <span style=color:#ff7b72>airflow.operators.dummy_operator</span> <span style=color:#ff7b72>import</span> DummyOperator
</span></span><span style=display:flex><span><span style=color:#ff7b72>from</span> <span style=color:#ff7b72>airflow.models</span> <span style=color:#ff7b72>import</span> DAG
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>args <span style=color:#ff7b72;font-weight:700>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#a5d6ff>&#39;owner&#39;</span>: <span style=color:#a5d6ff>&#39;airflow&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#a5d6ff>&#39;start_date&#39;</span>: airflow<span style=color:#ff7b72;font-weight:700>.</span>utils<span style=color:#ff7b72;font-weight:700>.</span>dates<span style=color:#ff7b72;font-weight:700>.</span>days_ago(<span style=color:#a5d6ff>2</span>) <span style=color:#8b949e;font-style:italic># 作业的开始时间，即作业将在这个时间点以后开始调度。</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dag <span style=color:#ff7b72;font-weight:700>=</span> DAG(
</span></span><span style=display:flex><span>    dag_id<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;example_bash_operator&#39;</span>,  <span style=color:#8b949e;font-style:italic># 给 DAG 取一个名字,不能重复</span>
</span></span><span style=display:flex><span>    default_args<span style=color:#ff7b72;font-weight:700>=</span>args,
</span></span><span style=display:flex><span>    schedule_interval<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;0 0 * * *&#39;</span>  <span style=color:#8b949e;font-style:italic># 配置 DAG 的执行周期，语法和 crontab 的一致</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cmd <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>&#39;ls -l&#39;</span>
</span></span><span style=display:flex><span>run_this_last <span style=color:#ff7b72;font-weight:700>=</span> DummyOperator(task_id<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;run_this_last&#39;</span>, dag<span style=color:#ff7b72;font-weight:700>=</span>dag)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>run_this <span style=color:#ff7b72;font-weight:700>=</span> BashOperator(
</span></span><span style=display:flex><span>    task_id<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;run_after_loop&#39;</span>, bash_command<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;echo 1&#39;</span>, dag<span style=color:#ff7b72;font-weight:700>=</span>dag)
</span></span><span style=display:flex><span>run_this<span style=color:#ff7b72;font-weight:700>.</span>set_downstream(run_this_last)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> i <span style=color:#ff7b72;font-weight:700>in</span> range(<span style=color:#a5d6ff>3</span>):
</span></span><span style=display:flex><span>    i <span style=color:#ff7b72;font-weight:700>=</span> str(i)
</span></span><span style=display:flex><span>    task <span style=color:#ff7b72;font-weight:700>=</span> BashOperator(
</span></span><span style=display:flex><span>        task_id<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;runme_&#39;</span><span style=color:#ff7b72;font-weight:700>+</span>i,
</span></span><span style=display:flex><span>        bash_command<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;echo &#34;{{ task_instance_key_str }}&#34; &amp;&amp; sleep 1&#39;</span>,
</span></span><span style=display:flex><span>        dag<span style=color:#ff7b72;font-weight:700>=</span>dag)
</span></span><span style=display:flex><span>    task<span style=color:#ff7b72;font-weight:700>.</span>set_downstream(run_this)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>task <span style=color:#ff7b72;font-weight:700>=</span> BashOperator(
</span></span><span style=display:flex><span>    task_id<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;also_run_this&#39;</span>,
</span></span><span style=display:flex><span>    bash_command<span style=color:#ff7b72;font-weight:700>=</span><span style=color:#a5d6ff>&#39;echo &#34;run_id={{ run_id }} | dag_run={{ dag_run }}&#34;&#39;</span>,
</span></span><span style=display:flex><span>    dag<span style=color:#ff7b72;font-weight:700>=</span>dag)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic># 用[]可以并行执行多个job, task &gt;&gt; [job1,job2]</span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic># 等同于 task.set_downstream(run_this_last)</span>
</span></span><span style=display:flex><span>task <span style=color:#ff7b72;font-weight:700>&gt;&gt;</span> run_this_last
</span></span></code></pre></div><blockquote><p>那么现在，让我们看一下当一个新配置的 DAG 生效后第一次调度会在什么时候。其实第一次调度时间是在作业中配置的 start date 的第二个满足 schedule interval 的时间点，并且记录的 execution date 为作业中配置的 start date 的第一个满足 schedule interval 的时间点.</p><p>假设我们配置了一个作业的 start date 为 <strong>2017年10月1日</strong>，配置的 schedule interval 为 **00 12 * * *** 那么第一次执行的时间将是 <strong>2017年10月2日 12点</strong> 而此时记录的 execution date 为 <strong>2017年10月1日 12点</strong>。因此 execution date 并不是如其字面说的表示执行时间，真正的执行时间是 execution date 所显示的时间的下一个满足 schedule interval 的时间点。</p></blockquote><blockquote><p><a href=https://www.jianshu.com/p/e878bbc9ead2 target=_blank rel=noopener>浅谈</a></p><p><a href=https://zhuanlan.zhihu.com/p/43383509 target=_blank rel=noopener>实战</a></p><p><a href=https://www.cnblogs.com/cord/p/9450910.html target=_blank rel=noopener>使用</a></p><p><a href=https://zhuanlan.zhihu.com/p/36043468 target=_blank rel=noopener>搭建及问题</a></p><p><a href=https://airflow.apache.org/docs/stable/project.html target=_blank rel=noopener>官网</a></p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://xiaokunji.com/zh/tags/airflow.html>airflow</a></li><li><a href=https://xiaokunji.com/zh/tags/Hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>Hadoop生态圈</a></li></ul></footer></article></main><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><footer class=footer><span>Copyright
&copy;
-2023
<a href=https://xiaokunji.com/zh/ style=color:#939393>米二</a>
All Rights Reserved</span>
<span id=busuanzi_container><span class="fa fa-user">用户数:</span><span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye">访问数:</span><span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>