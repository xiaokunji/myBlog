<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>小文件 | 米二</title><meta name=keywords content="每个Map最大输入大小(这个值决定了合并后文件的数量),一个节点上split的至少的大小(这个值决定了多个DataNode上的文件是否需要合并),一个交换机下split的至少的大小(这个值决定了多个交换机上的文件是否需要合并),执行Map前进行小文件合并,===设置map输出和reduce输出进行合并的相关参数：,设置map端输出进行合并，默认为true,设置reduce端输出进行合并，默认为false,设置合并文件的大小,当输出文件的平均大小小于该值时，启动一个独立的MapReduce任务进行文件merge。, 设置每个reducer处理的大小为5个G, 使用distribute by rand()将数据随机分配给reduce,避免出现有的文件特别大,有的文件特别小,用来控制归档是否可用,通知Hive在创建归档时是否可以设置父目录,控制需要归档文件的大小,使用以下命令进行归档,对已归档的分区恢复为原文件,::注意，归档的分区不能够INSERT OVERWRITE，必须先unarchive"><meta name=description content="     "><meta name=author content="xkj"><link rel=canonical href=https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E5%B0%8F%E6%96%87%E4%BB%B6/><link crossorigin=anonymous href=/assets/css/stylesheet.a2492b1919558dad2b0783841b531329520921f957f354ded4c3fc4d21dcc77f.css integrity="sha256-okkrGRlVja0rB4OEG1MTKVIJIflX81Te1MP8TSHcx38=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://xiaokunji.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://xiaokunji.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://xiaokunji.github.io/img/Q.gif><link rel=apple-touch-icon href=https://xiaokunji.github.io/Q.gif><link rel=mask-icon href=https://xiaokunji.github.io/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E5%B0%8F%E6%96%87%E4%BB%B6/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="小文件"><meta property="og:description" content="     "><meta property="og:type" content="article"><meta property="og:url" content="https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E5%B0%8F%E6%96%87%E4%BB%B6/"><meta property="article:section" content="Hadoop生态圈"><meta property="article:published_time" content="2023-08-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-22T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="小文件"><meta name=twitter:description content="     "><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":3,"name":"小文件","item":"https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E5%B0%8F%E6%96%87%E4%BB%B6/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"小文件","name":"小文件","description":"     ","keywords":["每个Map最大输入大小(这个值决定了合并后文件的数量)","一个节点上split的至少的大小(这个值决定了多个DataNode上的文件是否需要合并)","一个交换机下split的至少的大小(这个值决定了多个交换机上的文件是否需要合并)","执行Map前进行小文件合并","===设置map输出和reduce输出进行合并的相关参数：","设置map端输出进行合并，默认为true","设置reduce端输出进行合并，默认为false","设置合并文件的大小","当输出文件的平均大小小于该值时，启动一个独立的MapReduce任务进行文件merge。"," 设置每个reducer处理的大小为5个G"," 使用distribute by rand()将数据随机分配给reduce, 避免出现有的文件特别大, 有的文件特别小","用来控制归档是否可用","通知Hive在创建归档时是否可以设置父目录","控制需要归档文件的大小","使用以下命令进行归档","对已归档的分区恢复为原文件","::注意，归档的分区不能够INSERT OVERWRITE，必须先unarchive"],"articleBody":"哪里会产生小文件 ?\n源数据本身有很多小文件 动态分区会产生大量小文件 reduce个数越多, 小文件越多 按分区插入数据的时候会产生大量的小文件, 文件个数 = maptask个数 * 分区数 小文件太多造成的影响 ?\n从Hive的角度看，小文件会开很多map，一个map开一个JVM去执行，所以这些任务的初始化，启动，执行会浪费大量的资源，严重影响性能。 HDFS存储太多小文件, 会导致namenode元数据特别大, 占用太多内存, 制约了集群的扩展 小文件解决方法\n方法一: 通过调整参数进行合并\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #每个Map最大输入大小(这个值决定了合并后文件的数量) set mapred.max.split.size=256000000; #一个节点上split的至少的大小(这个值决定了多个DataNode上的文件是否需要合并) set mapred.min.split.size.per.node=100000000; #一个交换机下split的至少的大小(这个值决定了多个交换机上的文件是否需要合并) set mapred.min.split.size.per.rack=100000000; #执行Map前进行小文件合并 set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; #===设置map输出和reduce输出进行合并的相关参数： #设置map端输出进行合并，默认为true set hive.merge.mapfiles = true #设置reduce端输出进行合并，默认为false set hive.merge.mapredfiles = true #设置合并文件的大小 set hive.merge.size.per.task = 256*1000*1000 #当输出文件的平均大小小于该值时，启动一个独立的MapReduce任务进行文件merge。 set hive.merge.smallfiles.avgsize=16000000 **方法二: **\n针对按分区插入数据的时候产生大量的小文件的问题, 可以使用DISTRIBUTE BY rand() 将数据随机分配给Reduce，这样可以使得每个Reduce处理的数据大体一致.\n1 2 3 4 5 6 7 # 设置每个reducer处理的大小为5个G set hive.exec.reducers.bytes.per.reducer=5120000000; # 使用distribute by rand()将数据随机分配给reduce, 避免出现有的文件特别大, 有的文件特别小 insert overwrite table test partition(dt) select * from iteblog_tmp DISTRIBUTE BY rand(); 方法三: 使用Sequencefile作为表存储格式，不要用textfile，在一定程度上可以减少小文件\n压缩和输出小文件合并是无法并存的，两者都有时，输出小文件合并会失效。除非，表的存储方式是SequenceFile\nhttps://blog.csdn.net/djd1234567/article/details/51581201 方法四: 使用hadoop的archive归档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #用来控制归档是否可用 set hive.archive.enabled=true; #通知Hive在创建归档时是否可以设置父目录 set hive.archive.har.parentdir.settable=true; #控制需要归档文件的大小 set har.partfile.size=1099511627776; #使用以下命令进行归档 ALTER TABLE srcpart ARCHIVE PARTITION(ds='2008-04-08', hr='12'); #对已归档的分区恢复为原文件 ALTER TABLE srcpart UNARCHIVE PARTITION(ds='2008-04-08', hr='12'); #::注意，归档的分区不能够INSERT OVERWRITE，必须先unarchive https://blog.csdn.net/weixin_42582592/article/details/85084575 捷顺是采用手动的方法,文件个数和大小达标后把所有数据写到一起(通过写hive命令),当然也通过配置配合使用(本质是通过写一次操作,使配置生效)\n","wordCount":"1065","inLanguage":"zh","datePublished":"2023-08-22T00:00:00Z","dateModified":"2023-08-22T00:00:00Z","author":{"@type":"Person","name":"xkj"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E5%B0%8F%E6%96%87%E4%BB%B6/"},"publisher":{"@type":"Organization","name":"米二","logo":{"@type":"ImageObject","url":"https://xiaokunji.github.io/img/Q.gif"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaokunji.github.io/zh/ accesskey=h title="米二 (Alt + H)"><img src=https://xiaokunji.github.io/img/Q.gif alt aria-label=logo height=35>米二</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaokunji.github.io/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://xiaokunji.github.io/zh/ title=🏠主页><span>🏠主页</span></a></li><li><a href=https://xiaokunji.github.io/zh/search title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://xiaokunji.github.io/zh/post title=📚文章><span>📚文章</span></a></li><li><a href=https://xiaokunji.github.io/zh/archives/ title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://xiaokunji.github.io/zh/tags title=🔖标签><span>🔖标签</span></a></li><li><a href=https://xiaokunji.github.io/zh/categories title=📖分类><span>📖分类</span></a></li><li><a href=https://xiaokunji.github.io/zh/links title=🤝友链><span>🤝友链</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><nav aria-label=breadcrumb><ul><a href=https://xiaokunji.github.io/zh/>content</a> <span>></span>
<a href=https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/>Hadoop生态圈</a> <span>></span>
<a href=https://xiaokunji.github.io/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/>Hive</a> <span>></span></ul></nav><h1 class=post-title>小文件</h1><div class=post-description></div><div class=post-meta><span title='2023-08-22 00:00:00 +0000 UTC'>2023-08-22</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;xkj
&nbsp;|&nbsp;分类: &nbsp;<ul class=post-categories-meta><a href=https://xiaokunji.github.io/zh/categories/hadoop%E7%94%9F%E6%80%81%E5%9C%88/>Hadoop生态圈</a></ul><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv></span></span>
<script src=https://cdn.staticfile.org/twikoo//twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://xiaokunji.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script>&nbsp;| 评论: &nbsp; <span id=comment_count></span></div></header><div class=post-content><p><strong>哪里会产生小文件 ?</strong></p><ul><li>源数据本身有很多小文件</li><li>动态分区会产生大量小文件</li><li>reduce个数越多, 小文件越多</li><li>按分区插入数据的时候会产生大量的小文件, 文件个数 = maptask个数 * 分区数</li></ul><p><strong>小文件太多造成的影响 ?</strong></p><ul><li>从Hive的角度看，小文件会开很多map，一个map开一个JVM去执行，所以这些任务的初始化，启动，执行会浪费大量的资源，严重影响性能。</li><li>HDFS存储太多小文件, 会导致namenode元数据特别大, 占用太多内存, 制约了集群的扩展</li></ul><p><strong>小文件解决方法</strong></p><p><strong>方法一: 通过调整参数进行合并</strong></p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>#每个Map最大输入大小(这个值决定了合并后文件的数量)</span>
</span></span><span style=display:flex><span>set mapred.max.split.size<span style=color:#f92672>=</span>256000000;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#一个节点上split的至少的大小(这个值决定了多个DataNode上的文件是否需要合并)</span>
</span></span><span style=display:flex><span>set mapred.min.split.size.per.node<span style=color:#f92672>=</span>100000000;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#一个交换机下split的至少的大小(这个值决定了多个交换机上的文件是否需要合并)</span>
</span></span><span style=display:flex><span>set mapred.min.split.size.per.rack<span style=color:#f92672>=</span>100000000;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#执行Map前进行小文件合并</span>
</span></span><span style=display:flex><span>set hive.input.format<span style=color:#f92672>=</span>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#===设置map输出和reduce输出进行合并的相关参数：</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#设置map端输出进行合并，默认为true</span>
</span></span><span style=display:flex><span>set hive.merge.mapfiles <span style=color:#f92672>=</span> true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#设置reduce端输出进行合并，默认为false</span>
</span></span><span style=display:flex><span>set hive.merge.mapredfiles <span style=color:#f92672>=</span> true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#设置合并文件的大小</span>
</span></span><span style=display:flex><span>set hive.merge.size.per.task <span style=color:#f92672>=</span> 256*1000*1000
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#当输出文件的平均大小小于该值时，启动一个独立的MapReduce任务进行文件merge。</span>
</span></span><span style=display:flex><span>set hive.merge.smallfiles.avgsize<span style=color:#f92672>=</span><span style=color:#ae81ff>16000000</span>
</span></span></code></pre></td></tr></table></div></div><p>**方法二: **</p><p><strong>针对按分区插入数据的时候产生大量的小文件的问题, 可以使用DISTRIBUTE BY rand() 将数据随机分配给Reduce，这样可以使得每个Reduce处理的数据大体一致.</strong></p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e># 设置每个reducer处理的大小为5个G</span>
</span></span><span style=display:flex><span>set hive.exec.reducers.bytes.per.reducer<span style=color:#f92672>=</span>5120000000;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用distribute by rand()将数据随机分配给reduce, 避免出现有的文件特别大, 有的文件特别小</span>
</span></span><span style=display:flex><span>insert overwrite table test partition<span style=color:#f92672>(</span>dt<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>select</span> * from iteblog_tmp
</span></span><span style=display:flex><span>DISTRIBUTE BY rand<span style=color:#f92672>()</span>;
</span></span></code></pre></td></tr></table></div></div><p><strong>方法三: 使用Sequencefile作为表存储格式，不要用textfile，在一定程度上可以减少小文件</strong></p><blockquote><p>压缩和输出小文件合并是无法并存的，两者都有时，输出小文件合并会失效。除非，表的存储方式是SequenceFile</p><p><a href=https://blog.csdn.net/djd1234567/article/details/51581201 target=_blank rel=noopener>https://blog.csdn.net/djd1234567/article/details/51581201</a></p></blockquote><p><strong>方法四: 使用hadoop的archive归档</strong></p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>#用来控制归档是否可用</span>
</span></span><span style=display:flex><span>set hive.archive.enabled<span style=color:#f92672>=</span>true;
</span></span><span style=display:flex><span><span style=color:#75715e>#通知Hive在创建归档时是否可以设置父目录</span>
</span></span><span style=display:flex><span>set hive.archive.har.parentdir.settable<span style=color:#f92672>=</span>true;
</span></span><span style=display:flex><span><span style=color:#75715e>#控制需要归档文件的大小</span>
</span></span><span style=display:flex><span>set har.partfile.size<span style=color:#f92672>=</span>1099511627776;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#使用以下命令进行归档</span>
</span></span><span style=display:flex><span>ALTER TABLE srcpart ARCHIVE PARTITION<span style=color:#f92672>(</span>ds<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;2008-04-08&#39;</span>, hr<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;12&#39;</span><span style=color:#f92672>)</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#对已归档的分区恢复为原文件</span>
</span></span><span style=display:flex><span>ALTER TABLE srcpart UNARCHIVE PARTITION<span style=color:#f92672>(</span>ds<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;2008-04-08&#39;</span>, hr<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;12&#39;</span><span style=color:#f92672>)</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#::注意，归档的分区不能够INSERT OVERWRITE，必须先unarchive</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><p><a href=https://blog.csdn.net/weixin_42582592/article/details/85084575 target=_blank rel=noopener>https://blog.csdn.net/weixin_42582592/article/details/85084575</a></p></blockquote><blockquote><p>捷顺是采用手动的方法,文件个数和大小达标后把所有数据写到一起(通过写hive命令),当然也通过配置配合使用(本质是通过写一次操作,使配置生效)</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://xiaokunji.github.io/zh/tags/hive/>Hive</a></li><li><a href=https://xiaokunji.github.io/zh/tags/hadoop%E7%94%9F%E6%80%81%E5%9C%88/>Hadoop生态圈</a></li></ul><nav class=paginav><a class=prev href=https://xiaokunji.github.io/zh/java%E5%8F%8A%E5%85%B6%E6%A1%86%E6%9E%B6/java%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0/><span class=title>« 上一页</span><br><span>线程池</span></a>
<a class=next href=https://xiaokunji.github.io/zh/java%E5%8F%8A%E5%85%B6%E6%A1%86%E6%9E%B6/spring_boot/%E5%B0%8F%E7%9F%A5%E8%AF%86/><span class=title>下一页 »</span><br><span>小知识</span></a></nav></footer></article></main><footer class=footer><span>Copyright
&copy;
-2023
<a href=https://xiaokunji.github.io/zh/ style=color:#939393>米二</a>
All Rights Reserved</span>
<span id=busuanzi_container><span class="fa fa-user">用户数:</span><span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye">访问数:</span><span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>