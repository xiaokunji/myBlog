<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>简介及原理 | 米二</title><meta name=keywords content=" **1. 前言**, **2. 生态系统**, **3.弹性分布式数据集**, **3.1 RDD依赖关系**,  **3.2 RDD运行原理**, **3.2.1 DGA调度** , **3.2.1.1 DAGScheduler**, **3.2.1.2 TaskSched**, **4.Spark on YARN运行过程**, **4.1 YARN-Client**, **4.2 YARN-Cluster**"><meta name=description content="     "><meta name=author content="xkj"><link rel=canonical href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/Spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86.html><link crossorigin=anonymous href=/assets/css/stylesheet.b3faf608c544858ba700943ffe182cb647f38432d29a07d73234965beacb26f6.css integrity="sha256-s/r2CMVEhYunAJQ//hgstkfzhDLSmgfXMjSWW+rLJvY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=16x16 href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=32x32 href=https://xiaokunji.com/img/Q.svg><link rel=apple-touch-icon href=https://xiaokunji.com/Q.svg><link rel=mask-icon href=https://xiaokunji.com/Q.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/Spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86.html><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="简介及原理"><meta property="og:description" content="     "><meta property="og:type" content="article"><meta property="og:url" content="https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/Spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86.html"><meta property="article:section" content="hadoop生态圈"><meta property="article:published_time" content="2023-08-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-11T16:28:32+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="简介及原理"><meta name=twitter:description content="     "><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"简介及原理","item":"https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/Spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86.html"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"简介及原理","name":"简介及原理","description":"     ","keywords":[" **1. 前言**"," **2. 生态系统**"," **3.弹性分布式数据集**"," **3.1 RDD依赖关系**","  **3.2 RDD运行原理**"," **3.2.1 DGA调度** "," **3.2.1.1 DAGScheduler**"," **3.2.1.2 TaskSched**"," **4.Spark on YARN运行过程**"," **4.1 YARN-Client**"," **4.2 YARN-Cluster**"],"articleBody":"[toc]\n1. 前言 Apache Spark 是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用Scala程序设计语言 编写而成，运行于Java虚拟机（JVM）环境之上\nSpark运行在现有的Hadoop分布式文件系统基础之上（HDFS ）提供额外的增强功能。它支持将Spark应用部署到 现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是Apache Mesos 之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在\nSpark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。\nSpark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集\nSpark允许程序开发者使用有向无环图（DAG ）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。\n2. 生态系统 Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。\nSpark Core**:** 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。\n来自* \u003chttps://www.douban.com/note/536766108/?from=tag \u003e\nSpark Streaming: Spark Streaming 基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。\nSpark SQL: Spark SQL 可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。\nSpark MLlib: MLlib 是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。\nSpark GraphX: GraphX 是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。\n除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。\nSpark常用术语\n术语 描述 Application Spark的应用程序，包含一个Driver program和若干Executor SparkContext Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor Driver Program 运行Application的main()函数并且创建SparkContext Executor 是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务 Cluster Manager 在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn) Worker Node 集群中任何可以运行Application代码的节点，运行一个或多个Executor进程 Task 运行在Executor上的工作单元(rdd的转换过程) Job SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job) Stage 每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage) RDD 是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类 DAGScheduler 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler TaskScheduler 将Taskset提交给Worker node集群运行并返回结果 Transformations 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的 Action 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。 worker 集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点； 来自* \u003chttp://www.cnblogs.com/shishanyuan/p/4700615.html \u003e\n运行架构图:\n3.弹性分布式数据集 弹性分布式数据集 或RDD（Resilient Distributed Datasets）是Spark框架中的核心概念。可以将RDD视作数据库中的一张表。其中可以保存任何类型的数据。Spark将数据存储在不同分区上的RDD之中,一个RDD中有多个分区,这些分区可以分布在不同节点上(也就是说,RDD是分布存储的),分区的多少涉及对这个RDD进行并行计算的粒度,每个RDD分区计算操作都在一个单独的任务中被执行,分区个数可以自行指定和改变\nRDD可以帮助重新安排计算并优化数据处理过程。\n此外，它还具有容错性，因为RDD知道如何重新创建和重新计算数据集。\nRDD是不可变的,是只可读的。你可以用变换（Transformation）操作修改RDD，但是这个变换所返回的是一个全新的RDD，而原有的RDD仍然保持不变(有点像String的不变性),也就是说,在丢失或者操作失败后都是可以重建的,具有容错。\nspark五大特性(源自rdd类注释)\n是分区(可以存储在不同节点)的集合,因为一个rdd包含了多个分区的数据,把block块的东西整合到rdd(字段名: dependencies 存储在seq数据集中,类型是dependency,便利和取第一个)\n对每个分片并行计算(一般情况下分片大小等于分区大小)(名为computer函数,可重写)\n是其他rdd的依赖集合,就是知道该rdd从哪来,便于回溯(若宕机,存于内存中的rdd会丢失,spark会借由此重算)(字段名: partitions 存储Array中,类型是Partition ,便于通过下标获取)\n(可选)可以重新分区(调节并行度)(一个分区对应一个并行度) (主要是k-v形式的rdd有)\n(可选)给每个分片找到优先数据位置(找最近的数据处理最快嘛)(主要是来源有多个备份的rdd,例如HDFS文件,因为重写了getPreferredLocaltions方法)\n可选: 只有部分类型rdd才有的特性,\nRDD支持两种类型的操作：\n变换（Transformation） 行动（Action） 变换：变换 的返回值是一个新的RDD集合，而不是单个值。调用一个变换方法，不会有任何求值计算，它只获取一个RDD作为参数，然后返回一个新的RDD。\n变换函数包括：map，filter，flatMap，groupByKey，reduceByKey，aggregateByKey，pipe和coalesce等。\n行动：行动 操作计算并返回一个新的值。当在一个RDD对象上调用行动函数时，会在这一时刻计算全部的数据处理查询并返回结果值(Driver会接收到)。\n行动操作包括：reduce，collect，count，first，take，countByKey以及foreach等。\n注:\n只有在行动(action)时才会触发运算,也就是说变换是不会运行的计算的;\nRDD是粗粒度计算的.粗粒度:一个转化或者行动会把整个RDD里面的东西都进行操作\n3.1 RDD依赖关系 由于RDD是粗粒度的操作数据集，每个Transformation操作都会生成一个新的RDD，所以RDD之间就会形成类似流水线的前后依赖关系,进而形成了有向无环图（DAG ）；\n在spark中，RDD之间存在两种类型的依赖关系：窄依赖(Narrow Dependency)和宽依赖(Wide Dependency)\n窄依赖 :是指每个父RDD的一个Partition最多被子RDD的一个Partition所使用，例如map、filter、union等操作都会产生窄依赖；(父RDD的分区都在相同的节点)\n宽依赖 :是指每个父RDD的一个Partition会被多个子RDD的Partition所使用，例如groupByKey、reduceByKey、sortByKey等操作都会产生宽依赖；(可能跨越多个节点妈的)\n需要特别说明的是对join操作有两种情况：\n如果两个RDD在进行join操作时，一个RDD的partition仅仅和另一个RDD中已知个数的Partition进行join，那么这种类型的join操作就是窄依赖，例如图1中左半部分的join操作(join with inputs co-partitioned)； 其它情况的join操作就是宽依赖,例如图1中右半部分的join操作(join with inputs not co-partitioned)，由于是需要父RDD的所有partition进行join的转换，这就涉及到了shuffle，因此这种类型的join操作也是宽依赖。 简单的说,就是元素被用几次,只用一次就是窄依赖,超过一次就是宽依赖\n之所以这么区分依赖关系，是因为它们有本质的区别。使用窄依赖时，可以精确知道依赖的上级RDD分区。这样便于回溯。而宽依赖则开销会大。RDD仔细维护者这种依赖关系和计算方法,使得通过重新计算来恢复RDD成为可能。如果链条太长，则恢复代价太大，所以spark又提出一种检查点的机制。\n来自* \u003chttp://bbs.pinggu.org/thread-4637506-1-1.html \u003e\n3.2 RDD运行原理 那么 RDD在Spark架构中是如何运行的呢？总高层次来看，主要分为三步：\n创建 RDD 对象 DAGScheduler模块介入运算，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG 每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销。 来自* \u003chttp://www.cnblogs.com/shishanyuan/p/4721326.html \u003e\n3.2.1 DGA调度 sparkcontext在初始化时,创建了DAG调度与task调度来负责RDD action操作的调度执行。\n3.2.1.1 DAGScheduler DAGSchedule负责spark的最高级别的任务调度调度的力度是stage，它为每个job的所有stage计算一个有向无环图控制他们的并发，便找到一个最佳的路径来执行他们。具体的执行过程是将stage下的task集提交给Taskschedule对象，由它来提交到集群上去申请资源并最终完成执行。\n1.runjob过程\n所有需要执行的RDD action都会调用sparkCcontext.runJob来提交任务，而 SparkContest.runjob调用的是DAGScheduler.runjob, sunjob调用submitjob提交任务,并等待任务结束.提交任务是不是按job的先后顺序提交的,而是倒序,每个job的最后一个操作是action操作，DAG把这最后的action操作操作当做一个stage首先提交，然后逆向逐级递规填补缺少的上级stage，从而生成一颗实现最后action操作的最短有效无环图，然后从头开始计算。\n任务提交后的处理过程大致如下:\nsubmitJob生成新的job id, 发送消息jobsubmitted。\nDAG收到jobSubmitted消息,调用handleJobSubmitted来处理\nhandleJobSubmitted创建一个ResultStage,,并使用submitStage来提交这个ResultStage\n3.2.1.2 TaskSched 相对DAG schedule而言tasked sketches低级别的调度接口。允许实现不同的task调度器。每个task sketched对象只服务于一个sparkleContext的task调度。taskScheduler从DAGScheduler的每个 stage 接受一组task，并负责将他们送到集群上运行他们。\n4.Spark on YARN运行过程 spark运行在不同的资源管理器上有不同的运行过程,这里解释在YARN平台的运行,详情见\nhttp://www.cnblogs.com/shishanyuan/p/4721326.html Spark运行模式\n运行环境 模式 描述 Local 本地模式 常用于本地开发测试，本地还分为local单线程和local-cluster多线程; Standalone 集群模式 典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现HA On yarn 集群模式 运行在yarn资源管理器框架之上，由yarn负责资源管理，Spark负责任务调度和计算 On mesos 集群模式 运行在mesos资源管理器框架之上，由mesos负责资源管理，Spark负责任务调度和计算 On cloud 集群模式 比如AWS的EC2，使用这个模式能很方便的访问Amazon的S3;Spark支持多种分布式存储系统：HDFS和S3 Spark on YARN模式根据Driver在集群中的位置分为两种模式：\n一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）。\n4.1 YARN-Client Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是http://hadoop1:4040访问，而YARN通过http:// hadoop1:8088访问。\n4.2 YARN-Cluster 在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：\n第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；\n第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。\nYARN-Client 与 YARN-Cluster 区别\n理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别。\nYARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业； YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开。 来自* \u003chttp://www.cnblogs.com/shishanyuan/p/4721326.html \u003e\n","wordCount":"6536","inLanguage":"zh","datePublished":"2023-08-22T00:00:00Z","dateModified":"2023-09-11T16:28:32.033221603+08:00","author":{"@type":"Person","name":"xkj"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/Spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86.html"},"publisher":{"@type":"Organization","name":"米二","logo":{"@type":"ImageObject","url":"https://xiaokunji.com/img/Q.svg"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaokunji.com/zh/ accesskey=h title="米二 (Alt + H)"><img src=https://xiaokunji.com/img/Q.svg alt aria-label=logo height=35>米二</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaokunji.com/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://xiaokunji.com/zh/ title=🏠主页><span>🏠主页</span></a></li><li><a href=https://xiaokunji.com/zh/search title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://xiaokunji.com/zh/post.html title=📚文章><span>📚文章</span></a></li><li><a href=https://xiaokunji.com/zh/archives.html title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://xiaokunji.com/zh/tags.html title=🔖标签><span>🔖标签</span></a></li><li><a href=https://xiaokunji.com/zh/categories.html title=📖分类><span>📖分类</span></a></li><li><a href=https://xiaokunji.com/zh/links.html title=🤝友链><span>🤝友链</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><nav aria-label=breadcrumb><ul><a href=https://xiaokunji.com/zh/>🏠</a> <span>></span>
<a href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>hadoop生态圈</a> <span>></span>
<a href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/Spark.html>Spark</a> <span>></span></ul></nav><h1 class=post-title>简介及原理</h1><div class=post-description></div><div class=post-meta>创建:&nbsp;<span title='2023-08-22 00:00:00 +0000 UTC'>2023-08-22</span>&nbsp;·&nbsp;更新:&nbsp;2023-09-11&nbsp;·&nbsp;xkj
&nbsp;|&nbsp;分类: &nbsp;<ul class=post-categories-meta><a href=https://xiaokunji.com/zh/categories/Hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>Hadoop生态圈</a></ul><span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv>1</span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#1-%e5%89%8d%e8%a8%80 aria-label="1. 前言"><strong>1. 前言</strong></a></li><li><a href=#2-%e7%94%9f%e6%80%81%e7%b3%bb%e7%bb%9f aria-label="2. 生态系统"><strong>2. 生态系统</strong></a></li><li><a href=#3%e5%bc%b9%e6%80%a7%e5%88%86%e5%b8%83%e5%bc%8f%e6%95%b0%e6%8d%ae%e9%9b%86 aria-label=3.弹性分布式数据集><strong>3.弹性分布式数据集</strong></a><ul><li><a href=#31-rdd%e4%be%9d%e8%b5%96%e5%85%b3%e7%b3%bb aria-label="3.1 RDD依赖关系"><strong>3.1 RDD依赖关系</strong></a></li><li><a href=#32-rdd%e8%bf%90%e8%a1%8c%e5%8e%9f%e7%90%86 aria-label="3.2 RDD运行原理"><strong>3.2 RDD运行原理</strong></a><ul><li><a href=#321-dga%e8%b0%83%e5%ba%a6 aria-label="3.2.1 DGA调度"><strong>3.2.1 DGA调度</strong></a><ul><li><a href=#3211-dagscheduler aria-label="3.2.1.1 DAGScheduler"><strong>3.2.1.1 DAGScheduler</strong></a></li><li><a href=#3212-tasksched aria-label="3.2.1.2 TaskSched"><strong>3.2.1.2 TaskSched</strong></a></li></ul></li></ul></li></ul></li><li><a href=#4spark-on-yarn%e8%bf%90%e8%a1%8c%e8%bf%87%e7%a8%8b aria-label="4.Spark on YARN运行过程"><strong>4.Spark on YARN运行过程</strong></a><ul><li><a href=#41-yarn-client aria-label="4.1 YARN-Client"><strong>4.1 YARN-Client</strong></a></li><li><a href=#42-yarn-cluster aria-label="4.2 YARN-Cluster"><strong>4.2 YARN-Cluster</strong></a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>[toc]</p><h1 id=1-前言><strong>1. 前言</strong><a hidden class=anchor aria-hidden=true href=#1-前言>#</a></h1><p><a href=https://spark.apache.org/ target=_blank rel=noopener>Apache Spark</a>
是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用<a href=http://www.scala-lang.org/ target=_blank rel=noopener>Scala程序设计语言</a>
编写而成，运行于Java虚拟机（JVM）环境之上</p><p>Spark运行在现有的Hadoop分布式文件系统基础之上（<a href=http://wiki.apache.org/hadoop/HDFS target=_blank rel=noopener>HDFS</a>
）提供额外的增强功能。它支持<a href=http://databricks.com/blog/2014/01/21/Spark-and-Hadoop.html target=_blank rel=noopener>将Spark应用部署到</a>
现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是<a href=http://mesos.apache.org/ target=_blank rel=noopener>Apache Mesos</a>
之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在</p><p>Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。</p><p>Spark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集</p><p>Spark允许程序开发者使用有向无环图（<a href=http://en.wikipedia.org/wiki/Directed_acyclic_graph target=_blank rel=noopener>DAG</a>
）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。</p><h1 id=2-生态系统><strong>2. 生态系统</strong><a hidden class=anchor aria-hidden=true href=#2-生态系统>#</a></h1><p>Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。</p><ul><li><strong>Spark</strong> <strong>Core</strong>**:**</li></ul><p>实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。</p><blockquote><p>来自* <em>&lt;</em><a href="https://www.douban.com/note/536766108/?from=tag" target=_blank rel=noopener><em>https://www.douban.com/note/536766108/?from=tag</em></a>
<em>></em></p></blockquote><ul><li><strong>Spark Streaming:</strong></li></ul><p><a href=https://spark.apache.org/streaming/ target=_blank rel=noopener>Spark Streaming</a>
基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。</p><ul><li><strong>Spark SQL:</strong></li></ul><p><a href=https://spark.apache.org/sql/ target=_blank rel=noopener>Spark SQL</a>
可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。</p><ul><li><strong>Spark MLlib:</strong></li></ul><p><a href=https://spark.apache.org/mllib/ target=_blank rel=noopener>MLlib</a>
是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。</p><ul><li><strong>Spark GraphX:</strong></li></ul><p><a href=https://spark.apache.org/graphx/ target=_blank rel=noopener>GraphX</a>
是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。</p><p>除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。</p><p><img loading=lazy src=F:%5c%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99%5c%e4%b8%aa%e4%ba%ba%e7%ac%94%e8%ae%b0%5cMDImages%5cip_image001-1598631913582.jpeg alt=img></p><p><strong>Spark常用术语</strong></p><table><thead><tr><th><strong>术语</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>Application</td><td>Spark的应用程序，包含一个Driver program和若干Executor</td></tr><tr><td>SparkContext</td><td>Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor</td></tr><tr><td>Driver Program</td><td>运行Application的main()函数并且创建SparkContext</td></tr><tr><td>Executor</td><td>是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务</td></tr><tr><td>Cluster Manager</td><td>在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn)</td></tr><tr><td>Worker Node</td><td>集群中任何可以运行Application代码的节点，运行一个或多个Executor进程</td></tr><tr><td>Task</td><td>运行在Executor上的工作单元(rdd的转换过程)</td></tr><tr><td>Job</td><td>SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job)</td></tr><tr><td>Stage</td><td>每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage)</td></tr><tr><td>RDD</td><td>是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类</td></tr><tr><td>DAGScheduler</td><td>根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler</td></tr><tr><td>TaskScheduler</td><td>将Taskset提交给Worker node集群运行并返回结果</td></tr><tr><td>Transformations</td><td>是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的</td></tr><tr><td>Action</td><td>是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。</td></tr><tr><td>worker</td><td>集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点；</td></tr></tbody></table><blockquote><p>来自* <em>&lt;</em><a href=http://www.cnblogs.com/shishanyuan/p/4700615.html target=_blank rel=noopener><em>http://www.cnblogs.com/shishanyuan/p/4700615.html</em></a>
<em>></em></p></blockquote><p>运行架构图:</p><p><img loading=lazy src=F:%5c%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99%5c%e4%b8%aa%e4%ba%ba%e7%ac%94%e8%ae%b0%5cMDImages%5clip_image002.gif alt=img></p><h1 id=3弹性分布式数据集><strong>3.弹性分布式数据集</strong><a hidden class=anchor aria-hidden=true href=#3弹性分布式数据集>#</a></h1><p><a href=https://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds target=_blank rel=noopener>弹性分布式数据集</a>
或RDD（Resilient Distributed Datasets）是Spark框架中的核心概念。可以将RDD视作数据库中的一张表。其中可以保存任何类型的数据。Spark将数据存储在不同分区上的RDD之中,一个RDD中有多个分区,这些分区可以分布在不同节点上(也就是说,RDD是分布存储的),分区的多少涉及对这个RDD进行并行计算的粒度,每个RDD分区计算操作都在一个单独的任务中被执行,分区个数可以自行指定和改变</p><p>RDD可以帮助重新安排计算并优化数据处理过程。</p><p>此外，它还具有容错性，因为RDD知道如何重新创建和重新计算数据集。</p><p>RDD是不可变的,是只可读的。你可以用变换（Transformation）操作修改RDD，但是这个变换所返回的是一个全新的RDD，而原有的RDD仍然保持不变(有点像String的不变性),也就是说,在丢失或者操作失败后都是可以重建的,具有容错。</p><p>spark五大特性(源自rdd类注释)</p><ol><li><p>是分区(可以存储在不同节点)的集合,因为一个rdd包含了多个分区的数据,把block块的东西整合到rdd(字段名: dependencies 存储在seq数据集中,类型是dependency,便利和取第一个)</p></li><li><p>对每个分片并行计算(一般情况下分片大小等于分区大小)(名为computer函数,可重写)</p></li><li><p>是其他rdd的依赖集合,就是知道该rdd从哪来,便于回溯(若宕机,存于内存中的rdd会丢失,spark会借由此重算)(字段名: partitions 存储Array中,类型是Partition ,便于通过下标获取)</p></li><li><p>(可选)可以重新分区(调节并行度)(一个分区对应一个并行度) (主要是k-v形式的rdd有)</p></li><li><p>(可选)给每个分片找到优先数据位置(找最近的数据处理最快嘛)(主要是来源有多个备份的rdd,例如HDFS文件,因为重写了getPreferredLocaltions方法)</p></li></ol><p>可选: 只有部分类型rdd才有的特性,</p><p>RDD支持两种类型的操作：</p><ul><li>变换（Transformation）</li><li>行动（Action）</li></ul><p><strong>变换：</strong><a href=https://spark.apache.org/docs/latest/programming-guide.html#transformations target=_blank rel=noopener>变换</a>
的返回值是一个新的RDD集合，而不是单个值。调用一个变换方法，不会有任何求值计算，它只获取一个RDD作为参数，然后返回一个新的RDD。</p><p>变换函数包括：map，filter，flatMap，groupByKey，reduceByKey，aggregateByKey，pipe和coalesce等。</p><p><strong>行动：</strong><a href=https://spark.apache.org/docs/latest/programming-guide.html#actions target=_blank rel=noopener>行动</a>
操作计算并返回一个新的值。当在一个RDD对象上调用行动函数时，会在这一时刻计算全部的数据处理查询并返回结果值(Driver会接收到)。</p><p>行动操作包括：reduce，collect，count，first，take，countByKey以及foreach等。</p><p><strong>注:</strong></p><ol><li><p>只有在行动(action)时才会触发运算,也就是说变换是不会运行的计算的;</p></li><li><p>RDD是粗粒度计算的.粗粒度:一个转化或者行动会把整个RDD里面的东西都进行操作</p></li></ol><h2 id=31-rdd依赖关系><strong>3.1 RDD依赖关系</strong><a hidden class=anchor aria-hidden=true href=#31-rdd依赖关系>#</a></h2><p>由于RDD是粗粒度的操作数据集，每个Transformation操作都会生成一个新的RDD，所以RDD之间就会形成类似流水线的前后依赖关系,进而形成了有向无环图（<a href=http://en.wikipedia.org/wiki/Directed_acyclic_graph target=_blank rel=noopener>DAG</a>
）；</p><p>在spark中，RDD之间存在两种类型的依赖关系：窄依赖(Narrow Dependency)和宽依赖(Wide Dependency)</p><p><strong>窄依赖</strong> :是指每个父RDD的一个Partition最多被子RDD的一个Partition所使用，例如map、filter、union等操作都会产生窄依赖；(父RDD的分区都在相同的节点)</p><p><strong>宽依赖</strong> :是指每个父RDD的一个Partition会被多个子RDD的Partition所使用，例如groupByKey、reduceByKey、sortByKey等操作都会产生宽依赖；(可能跨越多个节点妈的)</p><p>需要特别说明的是对join操作有两种情况：</p><ul><li>如果两个RDD在进行join操作时，一个RDD的partition仅仅和另一个RDD中已知个数的Partition进行join，那么这种类型的join操作就是窄依赖，例如图1中左半部分的join操作(join with inputs co-partitioned)；</li><li>其它情况的join操作就是宽依赖,例如图1中右半部分的join操作(join with inputs not co-partitioned)，由于是需要父RDD的所有partition进行join的转换，这就涉及到了shuffle，因此这种类型的join操作也是宽依赖。</li></ul><p>简单的说,就是元素被用几次,只用一次就是窄依赖,超过一次就是宽依赖</p><p>之所以这么区分依赖关系，是因为它们有本质的区别。使用窄依赖时，可以精确知道依赖的上级RDD分区。这样便于回溯。而宽依赖则开销会大。RDD仔细维护者这种依赖关系和计算方法,使得通过重新计算来恢复RDD成为可能。如果链条太长，则恢复代价太大，所以spark又提出一种检查点的机制。</p><blockquote><p>来自* <em>&lt;</em><a href=http://bbs.pinggu.org/thread-4637506-1-1.html target=_blank rel=noopener><em>http://bbs.pinggu.org/thread-4637506-1-1.html</em></a>
<em>></em></p></blockquote><p><img loading=lazy src=F:%5c%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99%5c%e4%b8%aa%e4%ba%ba%e7%ac%94%e8%ae%b0%5cMDImages%5clip_image003.png alt=img></p><h2 id=32-rdd运行原理><strong>3.2 RDD运行原理</strong><a hidden class=anchor aria-hidden=true href=#32-rdd运行原理>#</a></h2><p>那么 RDD在Spark架构中是如何运行的呢？总高层次来看，主要分为三步：</p><ol><li>创建 RDD 对象</li><li>DAGScheduler模块介入运算，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG</li><li>每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销。</li></ol><blockquote><p>来自* <em>&lt;</em><a href=http://www.cnblogs.com/shishanyuan/p/4721326.html target=_blank rel=noopener><em>http://www.cnblogs.com/shishanyuan/p/4721326.html</em></a>
<em>></em></p></blockquote><h3 id=321-dga调度><strong>3.2.1 DGA调度</strong><a hidden class=anchor aria-hidden=true href=#321-dga调度>#</a></h3><p>sparkcontext在初始化时,创建了DAG调度与task调度来负责RDD action操作的调度执行。</p><h4 id=3211-dagscheduler><strong>3.2.1.1 DAGScheduler</strong><a hidden class=anchor aria-hidden=true href=#3211-dagscheduler>#</a></h4><p>DAGSchedule负责spark的最高级别的任务调度调度的力度是stage，它为每个job的所有stage计算一个有向无环图控制他们的并发，便找到一个最佳的路径来执行他们。具体的执行过程是将stage下的task集提交给Taskschedule对象，由它来提交到集群上去申请资源并最终完成执行。</p><p>1.runjob过程</p><p>所有需要执行的RDD action都会调用sparkCcontext.runJob来提交任务，而 SparkContest.runjob调用的是DAGScheduler.runjob, sunjob调用submitjob提交任务,并等待任务结束.提交任务是不是按job的先后顺序提交的,而是倒序,每个job的最后一个操作是action操作，DAG把这最后的action操作操作当做一个stage首先提交，然后逆向逐级递规填补缺少的上级stage，从而生成一颗实现最后action操作的最短有效无环图，然后从头开始计算。</p><p>任务提交后的处理过程大致如下:</p><ol><li><p>submitJob生成新的job id, 发送消息jobsubmitted。</p></li><li><p>DAG收到jobSubmitted消息,调用handleJobSubmitted来处理</p></li><li><p>handleJobSubmitted创建一个ResultStage,,并使用submitStage来提交这个ResultStage</p></li></ol><h4 id=3212-tasksched><strong>3.2.1.2 TaskSched</strong><a hidden class=anchor aria-hidden=true href=#3212-tasksched>#</a></h4><p>相对DAG schedule而言tasked sketches低级别的调度接口。允许实现不同的task调度器。每个task sketched对象只服务于一个sparkleContext的task调度。taskScheduler从DAGScheduler的每个 stage 接受一组task，并负责将他们送到集群上运行他们。</p><h1 id=4spark-on-yarn运行过程><strong>4.Spark on YARN运行过程</strong><a hidden class=anchor aria-hidden=true href=#4spark-on-yarn运行过程>#</a></h1><p>spark运行在不同的资源管理器上有不同的运行过程,这里解释在YARN平台的运行,详情见</p><blockquote><p><a href=http://www.cnblogs.com/shishanyuan/p/4721326.html target=_blank rel=noopener>http://www.cnblogs.com/shishanyuan/p/4721326.html</a></p></blockquote><p><strong>Spark运行模式</strong></p><table><thead><tr><th><strong>运行环境</strong></th><th><strong>模式</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>Local</td><td>本地模式</td><td>常用于本地开发测试，本地还分为local单线程和local-cluster多线程;</td></tr><tr><td>Standalone</td><td>集群模式</td><td>典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现HA</td></tr><tr><td>On yarn</td><td>集群模式</td><td>运行在yarn资源管理器框架之上，由yarn负责资源管理，Spark负责任务调度和计算</td></tr><tr><td>On mesos</td><td>集群模式</td><td>运行在mesos资源管理器框架之上，由mesos负责资源管理，Spark负责任务调度和计算</td></tr><tr><td>On cloud</td><td>集群模式</td><td>比如AWS的EC2，使用这个模式能很方便的访问Amazon的S3;Spark支持多种分布式存储系统：HDFS和S3</td></tr></tbody></table><p>Spark on YARN模式根据Driver在集群中的位置分为两种模式：</p><p>一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）。</p><h2 id=41-yarn-client><strong>4.1 YARN-Client</strong><a hidden class=anchor aria-hidden=true href=#41-yarn-client>#</a></h2><p>Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是http://hadoop1:4040访问，而YARN通过http:// hadoop1:8088访问。</p><p><img loading=lazy src=F:%5c%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99%5c%e4%b8%aa%e4%ba%ba%e7%ac%94%e8%ae%b0%5cMDImages%5cip_image004.jpeg alt=img></p><h2 id=42-yarn-cluster><strong>4.2 YARN-Cluster</strong><a hidden class=anchor aria-hidden=true href=#42-yarn-cluster>#</a></h2><p>在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：</p><p>第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；</p><p>第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。</p><p><img loading=lazy src=F:%5c%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99%5c%e4%b8%aa%e4%ba%ba%e7%ac%94%e8%ae%b0%5cMDImages%5cip_image005.jpeg alt=img></p><p><strong>YARN-Client 与 YARN-Cluster 区别</strong></p><p>理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别。</p><ul><li>YARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业；</li><li>YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开。</li></ul><blockquote><p>来自* <em>&lt;</em><a href=http://www.cnblogs.com/shishanyuan/p/4721326.html target=_blank rel=noopener><em>http://www.cnblogs.com/shishanyuan/p/4721326.html</em></a>
<em>></em></p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://xiaokunji.com/zh/tags/Spark.html>Spark</a></li><li><a href=https://xiaokunji.com/zh/tags/Hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>Hadoop生态圈</a></li></ul></footer></article></main><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><footer class=footer><span>Copyright
&copy;
-2023
<a href=https://xiaokunji.com/zh/ style=color:#939393>米二</a>
All Rights Reserved</span>
<span id=busuanzi_container><span class="fa fa-user">用户数:</span><span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye">访问数:</span><span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>