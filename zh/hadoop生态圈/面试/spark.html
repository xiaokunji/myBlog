<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>spark | 米二</title><meta name=keywords content=" **1. spark shuffle过程**, **2. spark streaming 读取kafka数据的两种方式**, 3. Spark提供的两种共享变量, **4.** **解释一下Spark Master的选举过程**, **5.** **Spark Streaming小文件问题**"><meta name=description content="     "><meta name=author content="xkj"><link rel=canonical href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark.html><link crossorigin=anonymous href=/assets/css/stylesheet.b3faf608c544858ba700943ffe182cb647f38432d29a07d73234965beacb26f6.css integrity="sha256-s/r2CMVEhYunAJQ//hgstkfzhDLSmgfXMjSWW+rLJvY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=16x16 href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=32x32 href=https://xiaokunji.com/img/Q.svg><link rel=apple-touch-icon href=https://xiaokunji.com/Q.svg><link rel=mask-icon href=https://xiaokunji.com/Q.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark.html><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="spark"><meta property="og:description" content="     "><meta property="og:type" content="article"><meta property="og:url" content="https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark.html"><meta property="article:section" content="hadoop生态圈"><meta property="article:published_time" content="2023-08-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-04T11:20:52+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="spark"><meta name=twitter:description content="     "><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"spark","item":"https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark.html"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"spark","name":"spark","description":"     ","keywords":[" **1. spark shuffle过程**"," **2. spark streaming 读取kafka数据的两种方式**"," 3. Spark提供的两种共享变量"," **4.** **解释一下Spark Master的选举过程**"," **5.** **Spark Streaming小文件问题**"],"articleBody":"[toc]\n1. spark shuffle过程 spark中管理shuffle的过程有一个shuffleManage负责管理, 在spark 2.X 之后,主要负责的是sortshufflemanager, 其中主要的是sortshuffle,shuffle分为两个阶段,shufflewriter和shuffleread\na) map task 的计算结果会写入到一个内存数据结构里面，内存数据结构默认是5M\nb) 在shuffle的时候会有一个定时器，不定期的去估算这个内存结构的大小，当内存结构中的数据超过5M时，比如现在内存结构中的数据为5.01M，那么他会申请5.01*2-5=5.02M内存给内存数据结构。\nc) 如果申请成功不会进行溢写，如果申请不成功，这时候会发生溢写磁盘。\nd) 在溢写之前内存结构中的数据会进行排序分区\ne) 然后开始溢写磁盘，写磁盘是以batch的形式去写，一个batch是1万条数据，\nf) map task执行完成后，会将这些磁盘小文件合并成一个大的磁盘文件，同时生成一个索引文件。\ng) reduce task去map端拉取数据的时候，首先解析索引文件，根据索引文件再去拉取对应的数据。\nhttps://blog.csdn.net/qq_21835703/article/details/79104733 2. spark streaming 读取kafka数据的两种方式 这两种方式分别是：\nReceiver-base 使用Kafka的高层次Consumer API来实现。receiver从Kafka中获取的数据都存储在Spark Executor的内存中，然后Spark Streaming启动的job会去处理那些数据。然而，在默认的配置下，这种方式可能会因为底层的失败而丢失数据。如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。该机制会同步地将接收到的Kafka数据写入分布式文件系统（比如HDFS）上的预写日志中。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。\nDirect Spark1.3中引入Direct方式，用来替代掉使用Receiver接收数据，这种方式会周期性地查询Kafka，获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。(使用比received更底层的api)\n3. Spark提供的两种共享变量 Spark 程序的大部分操作都是 RDD 操作，通过传入函数给 RDD 操作函数来计算，这些函数在不同的节点上并发执行，内部的变量有不同的作用域，不能相互访问，有些情况下不太方便。\n广播变量，是一个只读对象，在所有节点上都有一份缓存，创建方法是 SparkContext.broadcast()。创建之后再更新它的值是没有意义的，一般用 val 来修改定义。 计数器，只能增加，可以用计数或求和，支持自定义类型。创建方法是 SparkContext.accumulator(V, name)。只有 Driver 程序可以读这个计算器的变量，RDD 操作中读取计数器变量是无意义的。但节点可以对该计算器进行增加（？？？） 以上两种类型都是 Spark 的共享变量。\nhttps://zhuanlan.zhihu.com/p/49169166 4. 解释一下Spark Master的选举过程 与hadoop一样，spark也存在单点故障问题，为此，spark的standalone模式提供了master的HA，与hadoop一样，一个是active，一个是standby状态，当active挂了，standby会顶上。\nspark HA的主备切换主要基于两种机制：\n基于文件系统\n基于zk集群。\n前者在挂了后需要手动切换，而基于zk的HA可以自动实现切换。策略可以通过配置文件spark-env.sh配置spark.deploy.recoveryMode\n切换的过程如下：\n首先，standby的master去读取持久化（可能是磁盘或者zk）的storedAPP，storeddriver，storedworker的相关信息。读取后，如果storedAPP，storeddriver，storedworker有任何一个非空，那么就会启动master恢复机制，将持久化的APP，driver，worker信息重新注册到内存中，将application和worker的状态修改为UNknown，然后向该APP对应的driver，worer发送自己的地址信息，driver，worer如果没有挂，那么在接收到master发送的地址后，就会返回响应消息给新的master。此时，master在接收到driver，worker的消息后，会使用completeRecory对没有响应的组件进行清理，最后调用master的schedul方法，对正在等待的driver和app调度，如启动executor。\n原文链接：https://blog.csdn.net/englishsname/article/details/50631372\nhttps://blog.csdn.net/zhanglh046/article/details/78485745 5. Spark Streaming小文件问题 ​\t使用 Spark Streaming 时，如果实时计算结果要写入到 HDFS，那么不可避免的会遇到一个问题，那就是在默认情况下会产生非常多的小文件，这是由 Spark Streaming 的微批处理模式和 DStream(RDD) 的分布式(partition)特性导致的，Spark Streaming 为每个 Partition 启动一个独立的线程（一个 task/partition 一个线程）来处理数据，一旦文件输出到 HDFS，那么这个文件流就关闭了.\n处理 Spark Streaming 小文件的典型方法(大致如下):\n增加 batch 大小\nCoalesce大法好 , 小文件的基数是 batch_number * partition_number, 所以就是合并分区数\nSpark Streaming 外部来处理: 用 Hive 或者 Spark Sql 这样的“sql on hadoop”系统类进一步进行数据分析，而这些表一般都是按照半小时或者一小时、一天\n自己调用 foreach 去 append, 写入文件时,不要新建,而是追加已有的\nhttps://zhuanlan.zhihu.com/p/49169166 ","wordCount":"2263","inLanguage":"zh","datePublished":"2023-08-22T00:00:00Z","dateModified":"2023-09-04T11:20:52.736499744Z","author":{"@type":"Person","name":"xkj"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark.html"},"publisher":{"@type":"Organization","name":"米二","logo":{"@type":"ImageObject","url":"https://xiaokunji.com/img/Q.svg"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaokunji.com/zh/ accesskey=h title="米二 (Alt + H)"><img src=https://xiaokunji.com/img/Q.svg alt aria-label=logo height=35>米二</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaokunji.com/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://xiaokunji.com/zh/ title=🏠主页><span>🏠主页</span></a></li><li><a href=https://xiaokunji.com/zh/search title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://xiaokunji.com/zh/post.html title=📚文章><span>📚文章</span></a></li><li><a href=https://xiaokunji.com/zh/archives.html title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://xiaokunji.com/zh/tags.html title=🔖标签><span>🔖标签</span></a></li><li><a href=https://xiaokunji.com/zh/categories.html title=📖分类><span>📖分类</span></a></li><li><a href=https://xiaokunji.com/zh/links.html title=🤝友链><span>🤝友链</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><nav aria-label=breadcrumb><ul><a href=https://xiaokunji.com/zh/>🏠</a> <span>></span>
<a href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>hadoop生态圈</a> <span>></span>
<a href=https://xiaokunji.com/zh/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95.html>面试</a> <span>></span></ul></nav><h1 class=post-title>spark</h1><div class=post-description></div><div class=post-meta>创建:&nbsp;<span title='2023-08-22 00:00:00 +0000 UTC'>2023-08-22</span>&nbsp;·&nbsp;更新:&nbsp;2023-09-04&nbsp;·&nbsp;xkj
&nbsp;|&nbsp;分类: &nbsp;<ul class=post-categories-meta><a href=https://xiaokunji.com/zh/categories/Hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>Hadoop生态圈</a></ul><span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv>1</span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#1-spark-shuffle%e8%bf%87%e7%a8%8b aria-label="1. spark shuffle过程"><strong>1. spark shuffle过程</strong></a></li><li><a href=#2-spark-streaming-%e8%af%bb%e5%8f%96kafka%e6%95%b0%e6%8d%ae%e7%9a%84%e4%b8%a4%e7%a7%8d%e6%96%b9%e5%bc%8f aria-label="2. spark streaming 读取kafka数据的两种方式"><strong>2. spark streaming 读取kafka数据的两种方式</strong></a></li><li><a href=#3-spark%e6%8f%90%e4%be%9b%e7%9a%84%e4%b8%a4%e7%a7%8d%e5%85%b1%e4%ba%ab%e5%8f%98%e9%87%8f aria-label="3. Spark提供的两种共享变量">3. Spark提供的两种共享变量</a></li><li><a href=#4-%e8%a7%a3%e9%87%8a%e4%b8%80%e4%b8%8bspark-master%e7%9a%84%e9%80%89%e4%b8%be%e8%bf%87%e7%a8%8b aria-label="4. 解释一下Spark Master的选举过程"><strong>4.</strong> <strong>解释一下Spark Master的选举过程</strong></a></li><li><a href=#5-spark-streaming%e5%b0%8f%e6%96%87%e4%bb%b6%e9%97%ae%e9%a2%98 aria-label="5. Spark Streaming小文件问题"><strong>5.</strong> <strong>Spark Streaming小文件问题</strong></a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>[toc]</p><h1 id=1-spark-shuffle过程><strong>1. spark shuffle过程</strong><a hidden class=anchor aria-hidden=true href=#1-spark-shuffle过程>#</a></h1><p>spark中管理shuffle的过程有一个shuffleManage负责管理, 在spark 2.X 之后,主要负责的是sortshufflemanager, 其中主要的是sortshuffle,shuffle分为两个阶段,shufflewriter和shuffleread</p><p>a) map task 的计算结果会写入到一个内存数据结构里面，内存数据结构默认是5M</p><p>b) 在shuffle的时候会有一个定时器，不定期的去估算这个内存结构的大小，当内存结构中的数据超过5M时，比如现在内存结构中的数据为5.01M，那么他会申请5.01*2-5=5.02M内存给内存数据结构。</p><p>c) 如果申请成功不会进行溢写，如果申请不成功，这时候会发生溢写磁盘。</p><p>d) 在溢写之前内存结构中的数据会进行排序分区</p><p>e) 然后开始溢写磁盘，写磁盘是以batch的形式去写，一个batch是1万条数据，</p><p>f) map task执行完成后，会将这些磁盘小文件合并成一个大的磁盘文件，同时生成一个索引文件。</p><p>g) reduce task去map端拉取数据的时候，首先解析索引文件，根据索引文件再去拉取对应的数据。</p><blockquote><p><a href=https://blog.csdn.net/qq_21835703/article/details/79104733 target=_blank rel=noopener>https://blog.csdn.net/qq_21835703/article/details/79104733</a></p></blockquote><h1 id=2-spark-streaming-读取kafka数据的两种方式><strong>2. spark streaming 读取kafka数据的两种方式</strong><a hidden class=anchor aria-hidden=true href=#2-spark-streaming-读取kafka数据的两种方式>#</a></h1><p>这两种方式分别是：</p><ol><li><strong>Receiver-base</strong></li></ol><p>使用Kafka的高层次Consumer API来实现。receiver从Kafka中获取的数据都存储在Spark Executor的内存中，然后Spark Streaming启动的job会去处理那些数据。然而，在默认的配置下，这种方式可能会因为底层的失败而丢失数据。如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。该机制会同步地将接收到的Kafka数据写入分布式文件系统（比如HDFS）上的预写日志中。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。</p><ol start=2><li><strong>Direct</strong></li></ol><p>Spark1.3中引入Direct方式，用来替代掉使用Receiver接收数据，这种方式会周期性地查询Kafka，获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。(使用比received更底层的api)</p><h1 id=3-spark提供的两种共享变量>3. Spark提供的两种共享变量<a hidden class=anchor aria-hidden=true href=#3-spark提供的两种共享变量>#</a></h1><p>Spark 程序的大部分操作都是 RDD 操作，通过传入函数给 RDD 操作函数来计算，这些函数在不同的节点上并发执行，内部的变量有不同的作用域，不能相互访问，有些情况下不太方便。</p><ol><li>广播变量，<strong>是一个只读对象</strong>，在所有节点上都有一份缓存，创建方法是 SparkContext.broadcast()。创建之后再更新它的值是没有意义的，一般用 val 来修改定义。</li><li>计数器，<strong>只能增加，可以用计数或求和，支持自定义类型</strong>。创建方法是 SparkContext.accumulator(V, name)。只有 Driver 程序可以读这个计算器的变量，RDD 操作中读取计数器变量是无意义的。但节点可以对该计算器进行增加（？？？）</li></ol><p>以上两种类型都是 Spark 的共享变量。</p><blockquote><p><a href=https://zhuanlan.zhihu.com/p/49169166 target=_blank rel=noopener>https://zhuanlan.zhihu.com/p/49169166</a></p></blockquote><h1 id=4-解释一下spark-master的选举过程><strong>4.</strong> <strong>解释一下Spark Master的选举过程</strong><a hidden class=anchor aria-hidden=true href=#4-解释一下spark-master的选举过程>#</a></h1><p>与hadoop一样，spark也存在单点故障问题，为此，spark的standalone模式提供了master的HA，与hadoop一样，一个是active，一个是standby状态，当active挂了，standby会顶上。</p><p>spark HA的主备切换主要基于两种机制：</p><ol><li><p>基于文件系统</p></li><li><p>基于zk集群。</p></li></ol><p>前者在挂了后需要手动切换，而基于zk的HA可以自动实现切换。策略可以通过配置文件spark-env.sh配置spark.deploy.recoveryMode</p><p><strong>切换的过程</strong>如下：</p><p>首先，standby的master去读取持久化（可能是磁盘或者zk）的storedAPP，storeddriver，storedworker的相关信息。读取后，如果storedAPP，storeddriver，storedworker有任何一个非空，那么就会启动master恢复机制，将持久化的APP，driver，worker信息重新注册到内存中，将application和worker的状态修改为UNknown，然后向该APP对应的driver，worer发送自己的地址信息，driver，worer如果没有挂，那么在接收到master发送的地址后，就会返回响应消息给新的master。此时，master在接收到driver，worker的消息后，会使用completeRecory对没有响应的组件进行清理，最后调用master的schedul方法，对正在等待的driver和app调度，如启动executor。</p><p><img loading=lazy src=https://gitee.com/xiaokunji/my-images/raw/master/myMD/20210711173608.png alt=img></p><blockquote><p>原文链接：https://blog.csdn.net/englishsname/article/details/50631372</p><p><a href=https://blog.csdn.net/zhanglh046/article/details/78485745 target=_blank rel=noopener>https://blog.csdn.net/zhanglh046/article/details/78485745</a></p></blockquote><h1 id=5-spark-streaming小文件问题><strong>5.</strong> <strong>Spark Streaming小文件问题</strong><a hidden class=anchor aria-hidden=true href=#5-spark-streaming小文件问题>#</a></h1><p>​ 使用 Spark Streaming 时，如果实时计算结果要写入到 HDFS，那么不可避免的会遇到一个问题，那就是在默认情况下会产生非常多的小文件，这是由 Spark Streaming 的微批处理模式和 DStream(RDD) 的分布式(partition)特性导致的，Spark Streaming 为每个 Partition 启动一个独立的线程（一个 task/partition 一个线程）来处理数据，一旦文件输出到 HDFS，那么这个文件流就关闭了.</p><p>处理 Spark Streaming 小文件的典型方法(大致如下):</p><ol><li><p>增加 batch 大小</p></li><li><p>Coalesce大法好 , 小文件的基数是 batch_number * partition_number, 所以就是合并分区数</p></li><li><p>Spark Streaming 外部来处理: 用 Hive 或者 Spark Sql 这样的“sql on hadoop”系统类进一步进行数据分析，而这些表一般都是按照半小时或者一小时、一天</p></li><li><p>自己调用 foreach 去 append, 写入文件时,不要新建,而是追加已有的</p></li></ol><blockquote><p><a href=https://zhuanlan.zhihu.com/p/49169166 target=_blank rel=noopener>https://zhuanlan.zhihu.com/p/49169166</a></p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://xiaokunji.com/zh/tags/%E9%9D%A2%E8%AF%95.html>面试</a></li><li><a href=https://xiaokunji.com/zh/tags/Hadoop%E7%94%9F%E6%80%81%E5%9C%88.html>Hadoop生态圈</a></li></ul></footer></article></main><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><footer class=footer><span>Copyright
&copy;
-2023
<a href=https://xiaokunji.com/zh/ style=color:#939393>米二</a>
All Rights Reserved</span>
<span id=busuanzi_container><span class="fa fa-user">用户数:</span><span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye">访问数:</span><span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>