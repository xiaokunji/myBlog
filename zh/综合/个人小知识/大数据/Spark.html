<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Spark | 米二</title><meta name=keywords content=" 1. Mesos:, 2. DGA:, 3. yarn和spark: , 4. Spark core:, 5. RDD类型, 6. PageRank算法, 7. Spark Shuffle, 8. RDD不可变,那RDD会不会存在回收?, 9. 为什么Flink比spark快?, 10.checkpoint, 11.SparkSQL 和 impala, 12.springStream中的 updatestateByKey函数和Mapwithstate函数"><meta name=description content="     "><meta name=author content="xkj"><link rel=canonical href=https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark.html><link crossorigin=anonymous href=/assets/css/stylesheet.b3faf608c544858ba700943ffe182cb647f38432d29a07d73234965beacb26f6.css integrity="sha256-s/r2CMVEhYunAJQ//hgstkfzhDLSmgfXMjSWW+rLJvY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=16x16 href=https://xiaokunji.com/img/Q.svg><link rel=icon type=image/png sizes=32x32 href=https://xiaokunji.com/img/Q.svg><link rel=apple-touch-icon href=https://xiaokunji.com/Q.svg><link rel=mask-icon href=https://xiaokunji.com/Q.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark.html><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Spark"><meta property="og:description" content="     "><meta property="og:type" content="article"><meta property="og:url" content="https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark.html"><meta property="article:section" content="综合"><meta property="article:published_time" content="2023-08-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-04T06:04:26+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Spark"><meta name=twitter:description content="     "><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":5,"name":"Spark","item":"https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark.html"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Spark","name":"Spark","description":"     ","keywords":[" 1. Mesos:"," 2. DGA:"," 3. yarn和spark: "," 4. Spark core:"," 5. RDD类型"," 6. PageRank算法"," 7. Spark Shuffle"," 8. RDD不可变,那RDD会不会存在回收?"," 9. 为什么Flink比spark快?"," 10.checkpoint"," 11.SparkSQL 和 impala"," 12.springStream中的 updatestateByKey函数和Mapwithstate函数"],"articleBody":"[toc]\n1. Mesos: 一个资源统一管理和调度平台,类似YARN,个人感觉不如YARN好\n出自:http://dongxicheng.org/mapreduce-nextgen/mesos_vs_yarn/\n2. DGA: 在spark里每一个操作生成一个RDD，RDD之间连一条边，最后这些RDD和他们之间的边组成一个有向无环图，这个就是DAG。(一般来说,生成新的RDD后,旧的不会使用,会等着被JVM回收)\n来自 3. yarn和spark: spark可以运行在yarn上,做资源管理,但是spark有自己的资源管理平台(可以深究,TaskScheduler)\n4. Spark core: Spark Core实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。\n来自 5. RDD类型 6. PageRank算法 7. Spark Shuffle 以reduceByKey为例,涉及按key对于RDD成员进行重组。将具有相同key但分布在不同节点上的成员聚会在一个节点上,以便对他们的value进行操作,这个重组过程就是shuffle操作。因为shuffle操作会涉及数据的传输，所以成本特别高，而且过程复杂。\n简单的说就是需要操作所有数据时,整合数据的过程叫shuffle\n8. RDD不可变,那RDD会不会存在回收? RDD 使用的是java内存,每生成一个RDD,就生成了一个对象(即使不接收),当RDD不再使用时(可能是标记法吧),又JVM回收\n9. 为什么Flink比spark快? Flink所用事物类型更底层,在运行时就经过了优化 flink提供了基于每个事件的流式处理机制,而spark是用小批量来模拟流式，也就是多个事件的集合 以上只是简述,并非完全.来自: https://www.jianshu.com/p/905ca3a7edb9 10.checkpoint checkpoint在spark中主要有两块应用：\n一块是在spark core中对RDD做checkpoint，可以切断做checkpoint RDD的依赖关系，将RDD数据保存到可靠存储（如HDFS）以便数据恢复；\n另外一块是应用在spark streaming中，使用checkpoint用来保存DStreamGraph以及相关配置信息，以便在Driver崩溃重启的时候能够接着之前进度继续进行处理（如之前waiting batch的job会在重启后继续处理）。\n注: checkpoint着重的是DAG图,会保存当前RDD,比如:RDD经过很多转换,最后才触发action;\ncache着重的是数据,比如:需要重复用到该数据 https://www.cnblogs.com/superhedantou/p/9004820.html https://blog.csdn.net/j904538808/article/details/80104525 11.SparkSQL 和 impala SparkSQL优势是能做业务处理,因为是RDD,能和其他RDD无缝连接,\nimpala优势是查询速度够快,(感觉能用web系统的操作)\n12.springStream中的 updatestateByKey函数和Mapwithstate函数 SparkStreaming 7*24 小时不间断的运行，有时需要管理一些状态，比如wordCount，每个batch的数据不是独立的而是需要累加的，这时就需要sparkStreaming来维护一些状态(这些状态可以是任意类型)，目前有两种方案updateStateByKey和mapWithState，(后者性能比前者好)\nupdateStateByKey\nssc.checkpoint(\".\") // 需打开checkpiont def updateFunction(currValues:Seq[Int],preValue:Option[Int]): Option[Int] = { val currValueSum = currValues.sum //上面的Int类型都可以用对象类型替换 Some(currValueSum + preValue.getOrElse(0)) //当前值的和加上历史值 } kafkaStream.map(r =\u003e (r._2,1)).updateStateByKey(updateFunction _)// vaule值是state(任意类型),更加key对state做处理(stream来维护状态) mapWithState\n可以使用initialState(RDD)来初始化key的值。 另外，还可以指定timeout函数，该函数的作用是，如果一个key超过timeout设定的时间没有更新值，那么这个key将会失效。这个控制需要在func中实现，必须使用state.isTimingOut()来判断失效的key值。如果在失效时间之后，这个key又有新的值了，则会重新计算。如果没有使用isTimingOut，则会报错。 val initialRDD = ssc.sparkContext.parallelize(List[(String, Int)]()) words.map((_, 1)).mapWithState(StateSpec.function(func).timeout(Seconds(30)).initialState(initialRDD)).print() /** * 定义一个函数，该函数有三个类型word: String, option: Option[Int], state: State[Int] * 其中word代表统计的单词， * option代表的是历史数据（使用option是因为历史数据可能有，也可能没有，如第一次进来的数据就没有历史记录）， * state代表的是返回的状态 */ val func: (String, Option[Int], State[Int]) =\u003e Any = (word: String, option: Option[Int], state: State[Int]) =\u003e { if(state.isTimingOut()){ //如果key超过时间没有更新 println(word + \"is timeout\") }else{ val sum = option.getOrElse(0) + state.getOption().getOrElse(0) // 单词和该单词出现的频率/ 获取历史数据，当前值加上上一个批次的该状态的值 // 更新状态 state.update(sum) (word, sum) } } 链接：https://www.jianshu.com/p/9f743301f589 https://my.oschina.net/u/3875806/blog/2986549 http://spark.apache.org/docs/2.2.1/streaming-programming-guide.html ","wordCount":"1905","inLanguage":"zh","datePublished":"2023-08-22T00:00:00Z","dateModified":"2023-09-04T06:04:26.040169048Z","author":{"@type":"Person","name":"xkj"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark.html"},"publisher":{"@type":"Organization","name":"米二","logo":{"@type":"ImageObject","url":"https://xiaokunji.com/img/Q.svg"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaokunji.com/zh/ accesskey=h title="米二 (Alt + H)"><img src=https://xiaokunji.com/img/Q.svg alt aria-label=logo height=35>米二</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaokunji.com/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://xiaokunji.com/zh/ title=🏠主页><span>🏠主页</span></a></li><li><a href=https://xiaokunji.com/zh/search title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://xiaokunji.com/zh/post.html title=📚文章><span>📚文章</span></a></li><li><a href=https://xiaokunji.com/zh/archives.html title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://xiaokunji.com/zh/tags.html title=🔖标签><span>🔖标签</span></a></li><li><a href=https://xiaokunji.com/zh/categories.html title=📖分类><span>📖分类</span></a></li><li><a href=https://xiaokunji.com/zh/links.html title=🤝友链><span>🤝友链</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><nav aria-label=breadcrumb><ul><a href=https://xiaokunji.com/zh/>🏠</a> <span>></span>
<a href=https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88.html>综合</a> <span>></span>
<a href=https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86.html>个人小知识</a> <span>></span>
<a href=https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/%E5%A4%A7%E6%95%B0%E6%8D%AE.html>大数据</a> <span>></span></ul></nav><h1 class=post-title>Spark</h1><div class=post-description></div><div class=post-meta>创建:&nbsp;<span title='2023-08-22 00:00:00 +0000 UTC'>2023-08-22</span>&nbsp;·&nbsp;更新:&nbsp;2023-09-04&nbsp;·&nbsp;xkj
&nbsp;|&nbsp;分类: &nbsp;<ul class=post-categories-meta><a href=https://xiaokunji.com/zh/categories/%E7%BB%BC%E5%90%88.html>综合</a></ul><span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv>1</span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#1-mesos aria-label="1. Mesos:">1. Mesos:</a></li><li><a href=#2-dga aria-label="2. DGA:">2. DGA:</a></li><li><a href=#3-yarn%e5%92%8cspark aria-label="3. yarn和spark:">3. yarn和spark:</a></li><li><a href=#4-spark-core aria-label="4. Spark core:">4. Spark core:</a></li><li><a href=#5-rdd%e7%b1%bb%e5%9e%8b aria-label="5. RDD类型">5. RDD类型</a></li><li><a href=#6-pagerank%e7%ae%97%e6%b3%95 aria-label="6. PageRank算法">6. PageRank算法</a></li><li><a href=#7-spark-shuffle aria-label="7. Spark Shuffle">7. Spark Shuffle</a></li><li><a href=#8-rdd%e4%b8%8d%e5%8f%af%e5%8f%98%e9%82%a3rdd%e4%bc%9a%e4%b8%8d%e4%bc%9a%e5%ad%98%e5%9c%a8%e5%9b%9e%e6%94%b6 aria-label="8. RDD不可变,那RDD会不会存在回收?">8. RDD不可变,那RDD会不会存在回收?</a></li><li><a href=#9-%e4%b8%ba%e4%bb%80%e4%b9%88flink%e6%af%94spark%e5%bf%ab aria-label="9. 为什么Flink比spark快?">9. 为什么Flink比spark快?</a></li><li><a href=#10checkpoint aria-label=10.checkpoint>10.checkpoint</a></li><li><a href=#11sparksql-%e5%92%8c-impala aria-label="11.SparkSQL 和 impala">11.SparkSQL 和 impala</a></li><li><a href=#12springstream%e4%b8%ad%e7%9a%84-updatestatebykey%e5%87%bd%e6%95%b0%e5%92%8cmapwithstate%e5%87%bd%e6%95%b0 aria-label="12.springStream中的 updatestateByKey函数和Mapwithstate函数">12.springStream中的 updatestateByKey函数和Mapwithstate函数</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>[toc]</p><h1 id=1-mesos>1. Mesos:<a hidden class=anchor aria-hidden=true href=#1-mesos>#</a></h1><p>一个资源统一管理和调度平台,类似YARN,个人感觉不如YARN好<br>出自:<code>http://dongxicheng.org/mapreduce-nextgen/mesos_vs_yarn/</code></p><h1 id=2-dga>2. DGA:<a hidden class=anchor aria-hidden=true href=#2-dga>#</a></h1><p>在spark里每一个操作生成一个RDD，RDD之间连一条边，最后这些RDD和他们之间的边组成一个有向无环图，这个就是DAG。(一般来说,生成新的RDD后,旧的不会使用,会等着被JVM回收)</p><blockquote><p>来自 <code>&lt;http://blog.csdn.net/sinat_31726559/article/details/51738155></code></p></blockquote><h1 id=3-yarn和spark>3. yarn和spark:<a hidden class=anchor aria-hidden=true href=#3-yarn和spark>#</a></h1><p>spark可以运行在yarn上,做资源管理,但是spark有自己的资源管理平台(可以深究,TaskScheduler)</p><h1 id=4-spark-core>4. Spark core:<a hidden class=anchor aria-hidden=true href=#4-spark-core>#</a></h1><p>Spark Core实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。</p><blockquote><p>来自 <code>&lt;https://www.douban.com/note/536766108/?from=tag></code></p></blockquote><h1 id=5-rdd类型>5. RDD类型<a hidden class=anchor aria-hidden=true href=#5-rdd类型>#</a></h1><h1 id=6-pagerank算法>6. PageRank算法<a hidden class=anchor aria-hidden=true href=#6-pagerank算法>#</a></h1><h1 id=7-spark-shuffle>7. Spark Shuffle<a hidden class=anchor aria-hidden=true href=#7-spark-shuffle>#</a></h1><p>以reduceByKey为例,涉及按key对于RDD成员进行重组。将具有相同key但分布在不同节点上的成员聚会在一个节点上,以便对他们的value进行操作,这个重组过程就是shuffle操作。因为shuffle操作会涉及数据的传输，所以成本特别高，而且过程复杂。</p><blockquote><p>简单的说就是需要操作所有数据时,整合数据的过程叫shuffle</p></blockquote><h1 id=8-rdd不可变那rdd会不会存在回收>8. RDD不可变,那RDD会不会存在回收?<a hidden class=anchor aria-hidden=true href=#8-rdd不可变那rdd会不会存在回收>#</a></h1><p>RDD 使用的是java内存,每生成一个RDD,就生成了一个对象(即使不接收),当RDD不再使用时(可能是标记法吧),又JVM回收</p><h1 id=9-为什么flink比spark快>9. 为什么Flink比spark快?<a hidden class=anchor aria-hidden=true href=#9-为什么flink比spark快>#</a></h1><ol><li>Flink所用事物类型更底层,在运行时就经过了优化</li><li>flink提供了基于每个事件的流式处理机制,而spark是用小批量来模拟流式，也就是多个事件的集合</li></ol><blockquote><p>以上只是简述,并非完全.来自: <a href=https://www.jianshu.com/p/905ca3a7edb9 target=_blank rel=noopener>https://www.jianshu.com/p/905ca3a7edb9</a></p></blockquote><h1 id=10checkpoint>10.checkpoint<a hidden class=anchor aria-hidden=true href=#10checkpoint>#</a></h1><p>checkpoint在spark中主要有两块应用：<br>一块是在spark core中对RDD做checkpoint，可以切断做checkpoint RDD的依赖关系，将RDD数据保存到可靠存储（如HDFS）以便数据恢复；<br>另外一块是应用在spark streaming中，使用checkpoint用来保存DStreamGraph以及相关配置信息，以便在Driver崩溃重启的时候能够接着之前进度继续进行处理（如之前waiting batch的job会在重启后继续处理）。</p><blockquote><p>注: <strong>checkpoint着重的是DAG图,会保存当前RDD,比如:RDD经过很多转换,最后才触发action;<br>cache着重的是数据,比如:需要重复用到该数据</strong>
<a href=https://www.cnblogs.com/superhedantou/p/9004820.html target=_blank rel=noopener>https://www.cnblogs.com/superhedantou/p/9004820.html</a>
<a href=https://blog.csdn.net/j904538808/article/details/80104525 target=_blank rel=noopener>https://blog.csdn.net/j904538808/article/details/80104525</a></p></blockquote><h1 id=11sparksql-和-impala>11.SparkSQL 和 impala<a hidden class=anchor aria-hidden=true href=#11sparksql-和-impala>#</a></h1><p><code>SparkSQL</code>优势是能做业务处理,因为是RDD,能和其他RDD无缝连接,<br><code>impala</code>优势是查询速度够快,(感觉能用web系统的操作)</p><h1 id=12springstream中的-updatestatebykey函数和mapwithstate函数>12.springStream中的 updatestateByKey函数和Mapwithstate函数<a hidden class=anchor aria-hidden=true href=#12springstream中的-updatestatebykey函数和mapwithstate函数>#</a></h1><p>SparkStreaming 7*24 小时不间断的运行，有时需要管理一些状态，比如wordCount，每个batch的数据不是独立的而是需要累加的，这时就需要sparkStreaming来维护一些状态(这些状态可以是任意类型)，目前有两种方案updateStateByKey和mapWithState，(后者性能比前者好)</p><p><strong>updateStateByKey</strong></p><div class=highlight><pre tabindex=0 style=color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>    ssc.checkpoint(&#34;.&#34;) // 需打开checkpiont
</span></span><span style=display:flex><span>    def updateFunction(currValues:Seq[Int],preValue:Option[Int]): Option[Int] = {
</span></span><span style=display:flex><span>       val currValueSum = currValues.sum
</span></span><span style=display:flex><span>        //上面的Int类型都可以用对象类型替换
</span></span><span style=display:flex><span>        Some(currValueSum + preValue.getOrElse(0)) //当前值的和加上历史值
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    kafkaStream.map(r =&gt; (r._2,1)).updateStateByKey(updateFunction _)// vaule值是state(任意类型),更加key对state做处理(stream来维护状态)
</span></span></code></pre></div><p><strong>mapWithState</strong></p><div class=highlight><pre tabindex=0 style=color:#c9d1d9;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>可以使用initialState(RDD)来初始化key的值。   
</span></span><span style=display:flex><span>另外，还可以指定timeout函数，该函数的作用是，如果一个key超过timeout设定的时间没有更新值，那么这个key将会失效。这个控制需要在func中实现，必须使用state.isTimingOut()来判断失效的key值。如果在失效时间之后，这个key又有新的值了，则会重新计算。如果没有使用isTimingOut，则会报错。
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>val initialRDD = ssc.sparkContext.parallelize(List[(String, Int)]())
</span></span><span style=display:flex><span>words.map((_, 1)).mapWithState(StateSpec.function(func).timeout(Seconds(30)).initialState(initialRDD)).print()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/**
</span></span><span style=display:flex><span>   * 定义一个函数，该函数有三个类型word: String, option: Option[Int], state: State[Int]
</span></span><span style=display:flex><span>   * 其中word代表统计的单词，
</span></span><span style=display:flex><span>   * option代表的是历史数据（使用option是因为历史数据可能有，也可能没有，如第一次进来的数据就没有历史记录），
</span></span><span style=display:flex><span>   * state代表的是返回的状态
</span></span><span style=display:flex><span>   */
</span></span><span style=display:flex><span>  val func: (String, Option[Int], State[Int]) =&gt; Any = (word: String, option: Option[Int], state: State[Int]) =&gt; {
</span></span><span style=display:flex><span>    if(state.isTimingOut()){
</span></span><span style=display:flex><span>      //如果key超过时间没有更新
</span></span><span style=display:flex><span>      println(word + &#34;is timeout&#34;)
</span></span><span style=display:flex><span>    }else{
</span></span><span style=display:flex><span>      val sum = option.getOrElse(0) + state.getOption().getOrElse(0)
</span></span><span style=display:flex><span>      // 单词和该单词出现的频率/ 获取历史数据，当前值加上上一个批次的该状态的值
</span></span><span style=display:flex><span>      // 更新状态
</span></span><span style=display:flex><span>      state.update(sum)
</span></span><span style=display:flex><span>      (word, sum)
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span></code></pre></div><blockquote><p>链接：https://www.jianshu.com/p/9f743301f589
<a href=https://my.oschina.net/u/3875806/blog/2986549 target=_blank rel=noopener>https://my.oschina.net/u/3875806/blog/2986549</a>
<a href=http://spark.apache.org/docs/2.2.1/streaming-programming-guide.html target=_blank rel=noopener>http://spark.apache.org/docs/2.2.1/streaming-programming-guide.html</a></p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://xiaokunji.com/zh/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE.html>大数据</a></li><li><a href=https://xiaokunji.com/zh/tags/%E7%BB%BC%E5%90%88.html>综合</a></li></ul><nav class=paginav><a class=prev href=https://xiaokunji.com/zh/%E7%BB%BC%E5%90%88/%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%9F%A5%E8%AF%86/java/%E6%9E%B6%E6%9E%84/SOA%E6%9E%B6%E6%9E%84%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8C%BA%E5%88%AB.html><span class=title>« 上一页</span><br><span>SOA架构和微服务架构的区别</span></a>
<a class=next href=https://xiaokunji.com/zh/java%E5%8F%8A%E5%85%B6%E6%A1%86%E6%9E%B6/java%E5%9F%BA%E7%A1%80/SPI.html><span class=title>下一页 »</span><br><span>SPI</span></a></nav></footer></article></main><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><footer class=footer><span>Copyright
&copy;
-2023
<a href=https://xiaokunji.com/zh/ style=color:#939393>米二</a>
All Rights Reserved</span>
<span id=busuanzi_container><span class="fa fa-user">用户数:</span><span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye">访问数:</span><span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>