<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <script type="application/ld+json">

{  
  "@context":"http://schema.org",
  "@type":"Website",
  "@id":"https:\/\/xiaokunji.github.io\/myBlog\/",
  "author": {
    "@type": "Person",
    "name": "Firstname Lastname",
    
    "image": "https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c"
    
  },
  "name":"Hugo tranquilpeak theme",
  "description":"[toc]\n1. 前言 Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用Scala程序设计语言编写而成，运行于Java虚拟机（JVM）环境之上\nSpark运行在现有的Hadoop分布式文件系统基础之上（HDFS）提供额外的增强功能。它支持将Spark应用部署到现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是Apache Mesos之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在\nSpark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。\nSpark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集\nSpark允许程序开发者使用有向无环图（DAG）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。\n2. 生态系统 Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell\/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib\/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。\nSpark Core**:** 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。\n来自* \u0026lt;https:\/\/www.douban.com\/note\/536766108\/?from=tag\u0026gt;\nSpark Streaming: Spark Streaming基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。\nSpark SQL: Spark SQL可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。\nSpark MLlib: MLlib是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。\nSpark GraphX: GraphX是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。\n除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。\nSpark常用术语\n术语 描述 Application Spark的应用程序，包含一个Driver program和若干Executor SparkContext Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor Driver Program 运行Application的main()函数并且创建SparkContext Executor 是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务 Cluster Manager 在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn) Worker Node 集群中任何可以运行Application代码的节点，运行一个或多个Executor进程 Task 运行在Executor上的工作单元(rdd的转换过程) Job SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job) Stage 每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage) RDD 是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类 DAGScheduler 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler TaskScheduler 将Taskset提交给Worker node集群运行并返回结果 Transformations 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的 Action 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。 worker 集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点； 来自* \u0026lt;http:\/\/www.",
  "url":"https:\/\/xiaokunji.github.io\/myBlog\/post\/hadoop%E7%94%9F%E6%80%81%E5%9C%88\/spark\/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86\/",
  "keywords":"[]"
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.116.1 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="Firstname Lastname">
<meta name="keywords" content="">
<meta name="description" content="[toc]
1. 前言 Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用Scala程序设计语言编写而成，运行于Java虚拟机（JVM）环境之上
Spark运行在现有的Hadoop分布式文件系统基础之上（HDFS）提供额外的增强功能。它支持将Spark应用部署到现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是Apache Mesos之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在
Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。
Spark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集
Spark允许程序开发者使用有向无环图（DAG）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。
2. 生态系统 Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。
Spark Core**:** 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。
来自* &lt;https://www.douban.com/note/536766108/?from=tag&gt;
Spark Streaming: Spark Streaming基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。
Spark SQL: Spark SQL可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。
Spark MLlib: MLlib是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。
Spark GraphX: GraphX是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。
除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。
Spark常用术语
术语 描述 Application Spark的应用程序，包含一个Driver program和若干Executor SparkContext Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor Driver Program 运行Application的main()函数并且创建SparkContext Executor 是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务 Cluster Manager 在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn) Worker Node 集群中任何可以运行Application代码的节点，运行一个或多个Executor进程 Task 运行在Executor上的工作单元(rdd的转换过程) Job SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job) Stage 每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage) RDD 是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类 DAGScheduler 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler TaskScheduler 将Taskset提交给Worker node集群运行并返回结果 Transformations 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的 Action 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。 worker 集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点； 来自* &lt;http://www.">


<meta property="og:description" content="[toc]
1. 前言 Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用Scala程序设计语言编写而成，运行于Java虚拟机（JVM）环境之上
Spark运行在现有的Hadoop分布式文件系统基础之上（HDFS）提供额外的增强功能。它支持将Spark应用部署到现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是Apache Mesos之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在
Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。
Spark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集
Spark允许程序开发者使用有向无环图（DAG）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。
2. 生态系统 Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。
Spark Core**:** 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。
来自* &lt;https://www.douban.com/note/536766108/?from=tag&gt;
Spark Streaming: Spark Streaming基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。
Spark SQL: Spark SQL可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。
Spark MLlib: MLlib是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。
Spark GraphX: GraphX是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。
除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。
Spark常用术语
术语 描述 Application Spark的应用程序，包含一个Driver program和若干Executor SparkContext Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor Driver Program 运行Application的main()函数并且创建SparkContext Executor 是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务 Cluster Manager 在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn) Worker Node 集群中任何可以运行Application代码的节点，运行一个或多个Executor进程 Task 运行在Executor上的工作单元(rdd的转换过程) Job SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job) Stage 每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage) RDD 是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类 DAGScheduler 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler TaskScheduler 将Taskset提交给Worker node集群运行并返回结果 Transformations 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的 Action 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。 worker 集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点； 来自* &lt;http://www.">
<meta property="og:type" content="article">
<meta property="og:title" content="Hugo tranquilpeak theme">
<meta name="twitter:title" content="Hugo tranquilpeak theme">
<meta property="og:url" content="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/">
<meta property="twitter:url" content="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/">
<meta property="og:site_name" content="Hugo tranquilpeak theme">
<meta property="og:description" content="[toc]
1. 前言 Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用Scala程序设计语言编写而成，运行于Java虚拟机（JVM）环境之上
Spark运行在现有的Hadoop分布式文件系统基础之上（HDFS）提供额外的增强功能。它支持将Spark应用部署到现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是Apache Mesos之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在
Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。
Spark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集
Spark允许程序开发者使用有向无环图（DAG）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。
2. 生态系统 Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。
Spark Core**:** 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。
来自* &lt;https://www.douban.com/note/536766108/?from=tag&gt;
Spark Streaming: Spark Streaming基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。
Spark SQL: Spark SQL可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。
Spark MLlib: MLlib是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。
Spark GraphX: GraphX是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。
除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。
Spark常用术语
术语 描述 Application Spark的应用程序，包含一个Driver program和若干Executor SparkContext Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor Driver Program 运行Application的main()函数并且创建SparkContext Executor 是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务 Cluster Manager 在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn) Worker Node 集群中任何可以运行Application代码的节点，运行一个或多个Executor进程 Task 运行在Executor上的工作单元(rdd的转换过程) Job SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job) Stage 每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage) RDD 是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类 DAGScheduler 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler TaskScheduler 将Taskset提交给Worker node集群运行并返回结果 Transformations 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的 Action 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。 worker 集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点； 来自* &lt;http://www.">
<meta name="twitter:description" content="[toc]
1. 前言 Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用Scala程序设计语言编写而成，运行于Java虚拟机（JVM）环境之上
Spark运行在现有的Hadoop分布式文件系统基础之上（HDFS）提供额外的增强功能。它支持将Spark应用部署到现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是Apache Mesos之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在
Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。
Spark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集
Spark允许程序开发者使用有向无环图（DAG）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。
2. 生态系统 Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。
Spark Core**:** 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。
来自* &lt;https://www.douban.com/note/536766108/?from=tag&gt;
Spark Streaming: Spark Streaming基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。
Spark SQL: Spark SQL可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。
Spark MLlib: MLlib是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。
Spark GraphX: GraphX是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。
除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。
Spark常用术语
术语 描述 Application Spark的应用程序，包含一个Driver program和若干Executor SparkContext Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor Driver Program 运行Application的main()函数并且创建SparkContext Executor 是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务 Cluster Manager 在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn) Worker Node 集群中任何可以运行Application代码的节点，运行一个或多个Executor进程 Task 运行在Executor上的工作单元(rdd的转换过程) Job SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job) Stage 每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage) RDD 是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类 DAGScheduler 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler TaskScheduler 将Taskset提交给Worker node集群运行并返回结果 Transformations 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的 Action 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。 worker 集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点； 来自* &lt;http://www.">
<meta property="og:locale" content="en-us">

  
  
  
  
  


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">






    <title>Hugo tranquilpeak theme</title>

    <link rel="icon" href="https://xiaokunji.github.io/myBlog/favicon.png">
    

    

    <link rel="canonical" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://xiaokunji.github.io/myBlog/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://xiaokunji.github.io/myBlog/" aria-label="Go to homepage">Hugo tranquilpeak theme</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://xiaokunji.github.io/myBlog/#about" aria-label="Open the link: /#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://xiaokunji.github.io/myBlog/#about" aria-label="Read more about the author">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Firstname Lastname</h4>
        
          <h5 class="sidebar-profile-bio">Super bio with markdown support <strong>COOL</strong></h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/content" title="我的">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">我的</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/categories" title="Categories">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/tags" title="Tags">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/archives" title="Archives">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/#about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/kakawait" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stackoverflow.com/users/636472/kakawait" target="_blank" rel="noopener" title="Stack Overflow">
    
      <i class="sidebar-button-icon fab fa-lg fa-stack-overflow" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Stack Overflow</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/index.xml" title="RSS">
    
      <i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" id="top">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title">
      
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

</div>
          
          <div class="post-content markdown">
            <div class="main-content-wrap">
              <p>[toc]</p>
<h1 id="1-前言"><strong>1. 前言</strong></h1>
<p><a href="https://spark.apache.org/">Apache Spark</a>是一个围绕速度、易用性和复杂分析构建的大数据处理框架,Spark是用<a href="http://www.scala-lang.org/">Scala程序设计语言</a>编写而成，运行于Java虚拟机（JVM）环境之上</p>
<p>Spark运行在现有的Hadoop分布式文件系统基础之上（<a href="http://wiki.apache.org/hadoop/HDFS">HDFS</a>）提供额外的增强功能。它支持<a href="http://databricks.com/blog/2014/01/21/Spark-and-Hadoop.html">将Spark应用部署到</a>现存的Hadoop v1集群（with SIMR – Spark-Inside-MapReduce）或Hadoop v2 YARN集群甚至是<a href="http://mesos.apache.org/">Apache Mesos</a>之中。也有自己的资源管理器(Standalone),可以脱离Hadoop生态圈独立存在</p>
<p>Spark通过在数据处理过程中成本更低的洗牌（Shuffle）方式，将MapReduce提升到一个更高的层次。</p>
<p>Spark将中间结果保存在内存中而不是将其写入磁盘，当内存放了足够多的数据时,会放在磁盘上(有存储策略),所以Spark可以用于处理大于集群内存容量总和的数据集</p>
<p>Spark允许程序开发者使用有向无环图（<a href="http://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>）开发复杂的多步数据管道。而且还支持跨有向无环图的内存数据共享，以便不同的作业可以共同处理同一个数据。</p>
<h1 id="2-生态系统"><strong>2. 生态系统</strong></h1>
<p>Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即时查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。</p>
<ul>
<li><strong>Spark</strong> <strong>Core</strong>**:**</li>
</ul>
<p>实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集（resilient distributed dataset，简称RDD）的API定义。 Spark Core提供了创建和操作这些集合的多个API。</p>
<blockquote>
<p>来自* <em>&lt;</em><a href="https://www.douban.com/note/536766108/?from=tag"><em>https://www.douban.com/note/536766108/?from=tag</em></a><em>&gt;</em></p>
</blockquote>
<ul>
<li><strong>Spark Streaming:</strong></li>
</ul>
<p><a href="https://spark.apache.org/streaming/">Spark Streaming</a>基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。</p>
<ul>
<li><strong>Spark SQL:</strong></li>
</ul>
<p><a href="https://spark.apache.org/sql/">Spark SQL</a>可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI(商业智能:提供报表展示分析帮助企业作出决策)和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。</p>
<ul>
<li><strong>Spark MLlib:</strong></li>
</ul>
<p><a href="https://spark.apache.org/mllib/">MLlib</a>是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。</p>
<ul>
<li><strong>Spark GraphX:</strong></li>
</ul>
<p><a href="https://spark.apache.org/graphx/">GraphX</a>是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。</p>
<p>除了这些库以外，还有一些其他的库，如BlinkDB和Tachyon。</p>
<p><img src="F:%5C%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%5C%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%5CMDImages%5Cip_image001-1598631913582.jpeg" alt="img"></p>
<p><strong>Spark常用术语</strong></p>
<table>
<thead>
<tr>
<th><strong>术语</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Application</td>
<td>Spark的应用程序，包含一个Driver program和若干Executor</td>
</tr>
<tr>
<td>SparkContext</td>
<td>Spark应用程序的入口，负责调度各个运算资源，协调各个Worker Node上的Executor</td>
</tr>
<tr>
<td>Driver Program</td>
<td>运行Application的main()函数并且创建SparkContext</td>
</tr>
<tr>
<td>Executor</td>
<td>是为Application运行在Worker node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上。每个Application都会申请各自的Executor来处理任务</td>
</tr>
<tr>
<td>Cluster Manager</td>
<td>在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn)</td>
</tr>
<tr>
<td>Worker Node</td>
<td>集群中任何可以运行Application代码的节点，运行一个或多个Executor进程</td>
</tr>
<tr>
<td>Task</td>
<td>运行在Executor上的工作单元(rdd的转换过程)</td>
</tr>
<tr>
<td>Job</td>
<td>SparkContext提交的具体Action操作，常和Action对应,一个JOB包含多个RDD及作用于相应RDD上的各种Operation(理解为一个action表示一个job)</td>
</tr>
<tr>
<td>Stage</td>
<td>每个Job会被拆分很多组task，每组任务被称为Stage，也称TaskSet(窄依赖是一个stage,宽依赖是一个stage)</td>
</tr>
<tr>
<td>RDD</td>
<td>是Resilient distributed datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类</td>
</tr>
<tr>
<td>DAGScheduler</td>
<td>根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler</td>
</tr>
<tr>
<td>TaskScheduler</td>
<td>将Taskset提交给Worker node集群运行并返回结果</td>
</tr>
<tr>
<td>Transformations</td>
<td>是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的</td>
</tr>
<tr>
<td>Action</td>
<td>是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发(懒计算)。</td>
</tr>
<tr>
<td>worker</td>
<td>集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点；</td>
</tr>
</tbody>
</table>
<blockquote>
<p>来自* <em>&lt;</em><a href="http://www.cnblogs.com/shishanyuan/p/4700615.html"><em>http://www.cnblogs.com/shishanyuan/p/4700615.html</em></a><em>&gt;</em></p>
</blockquote>
<p>运行架构图:</p>
<p><img src="F:%5C%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%5C%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%5CMDImages%5Clip_image002.gif" alt="img"></p>
<h1 id="3弹性分布式数据集"><strong>3.弹性分布式数据集</strong></h1>
<p><a href="https://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds">弹性分布式数据集</a>或RDD（Resilient Distributed Datasets）是Spark框架中的核心概念。可以将RDD视作数据库中的一张表。其中可以保存任何类型的数据。Spark将数据存储在不同分区上的RDD之中,一个RDD中有多个分区,这些分区可以分布在不同节点上(也就是说,RDD是分布存储的),分区的多少涉及对这个RDD进行并行计算的粒度,每个RDD分区计算操作都在一个单独的任务中被执行,分区个数可以自行指定和改变</p>
<p>RDD可以帮助重新安排计算并优化数据处理过程。</p>
<p>此外，它还具有容错性，因为RDD知道如何重新创建和重新计算数据集。</p>
<p>RDD是不可变的,是只可读的。你可以用变换（Transformation）操作修改RDD，但是这个变换所返回的是一个全新的RDD，而原有的RDD仍然保持不变(有点像String的不变性),也就是说,在丢失或者操作失败后都是可以重建的,具有容错。</p>
<p>spark五大特性(源自rdd类注释)</p>
<ol>
<li>
<p>是分区(可以存储在不同节点)的集合,因为一个rdd包含了多个分区的数据,把block块的东西整合到rdd(字段名: dependencies 存储在seq数据集中,类型是dependency,便利和取第一个)</p>
</li>
<li>
<p>对每个分片并行计算(一般情况下分片大小等于分区大小)(名为computer函数,可重写)</p>
</li>
<li>
<p>是其他rdd的依赖集合,就是知道该rdd从哪来,便于回溯(若宕机,存于内存中的rdd会丢失,spark会借由此重算)(字段名: partitions 存储Array中,类型是Partition ,便于通过下标获取)</p>
</li>
<li>
<p>(可选)可以重新分区(调节并行度)(一个分区对应一个并行度) (主要是k-v形式的rdd有)</p>
</li>
<li>
<p>(可选)给每个分片找到优先数据位置(找最近的数据处理最快嘛)(主要是来源有多个备份的rdd,例如HDFS文件,因为重写了getPreferredLocaltions方法)</p>
</li>
</ol>
<p>可选: 只有部分类型rdd才有的特性,</p>
<p>RDD支持两种类型的操作：</p>
<ul>
<li>变换（Transformation）</li>
<li>行动（Action）</li>
</ul>
<p><strong>变换：</strong><a href="https://spark.apache.org/docs/latest/programming-guide.html#transformations">变换</a>的返回值是一个新的RDD集合，而不是单个值。调用一个变换方法，不会有任何求值计算，它只获取一个RDD作为参数，然后返回一个新的RDD。</p>
<p>变换函数包括：map，filter，flatMap，groupByKey，reduceByKey，aggregateByKey，pipe和coalesce等。</p>
<p><strong>行动：</strong><a href="https://spark.apache.org/docs/latest/programming-guide.html#actions">行动</a>操作计算并返回一个新的值。当在一个RDD对象上调用行动函数时，会在这一时刻计算全部的数据处理查询并返回结果值(Driver会接收到)。</p>
<p>行动操作包括：reduce，collect，count，first，take，countByKey以及foreach等。</p>
<p><strong>注:</strong></p>
<ol>
<li>
<p>只有在行动(action)时才会触发运算,也就是说变换是不会运行的计算的;</p>
</li>
<li>
<p>RDD是粗粒度计算的.粗粒度:一个转化或者行动会把整个RDD里面的东西都进行操作</p>
</li>
</ol>
<h2 id="31-rdd依赖关系"><strong>3.1 RDD依赖关系</strong></h2>
<p>由于RDD是粗粒度的操作数据集，每个Transformation操作都会生成一个新的RDD，所以RDD之间就会形成类似流水线的前后依赖关系,进而形成了有向无环图（<a href="http://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>）；</p>
<p>在spark中，RDD之间存在两种类型的依赖关系：窄依赖(Narrow Dependency)和宽依赖(Wide Dependency)</p>
<p><strong>窄依赖</strong> :是指每个父RDD的一个Partition最多被子RDD的一个Partition所使用，例如map、filter、union等操作都会产生窄依赖；(父RDD的分区都在相同的节点)</p>
<p><strong>宽依赖</strong> :是指每个父RDD的一个Partition会被多个子RDD的Partition所使用，例如groupByKey、reduceByKey、sortByKey等操作都会产生宽依赖；(可能跨越多个节点妈的)</p>
<p>需要特别说明的是对join操作有两种情况：</p>
<ul>
<li>如果两个RDD在进行join操作时，一个RDD的partition仅仅和另一个RDD中已知个数的Partition进行join，那么这种类型的join操作就是窄依赖，例如图1中左半部分的join操作(join with inputs co-partitioned)；</li>
<li>其它情况的join操作就是宽依赖,例如图1中右半部分的join操作(join with inputs not co-partitioned)，由于是需要父RDD的所有partition进行join的转换，这就涉及到了shuffle，因此这种类型的join操作也是宽依赖。</li>
</ul>
<p>简单的说,就是元素被用几次,只用一次就是窄依赖,超过一次就是宽依赖</p>
<p>之所以这么区分依赖关系，是因为它们有本质的区别。使用窄依赖时，可以精确知道依赖的上级RDD分区。这样便于回溯。而宽依赖则开销会大。RDD仔细维护者这种依赖关系和计算方法,使得通过重新计算来恢复RDD成为可能。如果链条太长，则恢复代价太大，所以spark又提出一种检查点的机制。</p>
<blockquote>
<p>来自* <em>&lt;</em><a href="http://bbs.pinggu.org/thread-4637506-1-1.html"><em>http://bbs.pinggu.org/thread-4637506-1-1.html</em></a><em>&gt;</em></p>
</blockquote>
<p><img src="F:%5C%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%5C%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%5CMDImages%5Clip_image003.png" alt="img"></p>
<h2 id="32-rdd运行原理"><strong>3.2 RDD运行原理</strong></h2>
<p>那么 RDD在Spark架构中是如何运行的呢？总高层次来看，主要分为三步：</p>
<ol>
<li>创建 RDD 对象</li>
<li>DAGScheduler模块介入运算，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG</li>
<li>每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销。</li>
</ol>
<blockquote>
<p>来自* <em>&lt;</em><a href="http://www.cnblogs.com/shishanyuan/p/4721326.html"><em>http://www.cnblogs.com/shishanyuan/p/4721326.html</em></a><em>&gt;</em></p>
</blockquote>
<h3 id="321-dga调度"><strong>3.2.1 DGA调度</strong></h3>
<p>sparkcontext在初始化时,创建了DAG调度与task调度来负责RDD action操作的调度执行。</p>
<h4 id="3211-dagscheduler"><strong>3.2.1.1 DAGScheduler</strong></h4>
<p>DAGSchedule负责spark的最高级别的任务调度调度的力度是stage，它为每个job的所有stage计算一个有向无环图控制他们的并发，便找到一个最佳的路径来执行他们。具体的执行过程是将stage下的task集提交给Taskschedule对象，由它来提交到集群上去申请资源并最终完成执行。</p>
<p>1.runjob过程</p>
<p>所有需要执行的RDD action都会调用sparkCcontext.runJob来提交任务，而 SparkContest.runjob调用的是DAGScheduler.runjob,  sunjob调用submitjob提交任务,并等待任务结束.提交任务是不是按job的先后顺序提交的,而是倒序,每个job的最后一个操作是action操作，DAG把这最后的action操作操作当做一个stage首先提交，然后逆向逐级递规填补缺少的上级stage，从而生成一颗实现最后action操作的最短有效无环图，然后从头开始计算。</p>
<p>任务提交后的处理过程大致如下:</p>
<ol>
<li>
<p>submitJob生成新的job id, 发送消息jobsubmitted。</p>
</li>
<li>
<p>DAG收到jobSubmitted消息,调用handleJobSubmitted来处理</p>
</li>
<li>
<p>handleJobSubmitted创建一个ResultStage,,并使用submitStage来提交这个ResultStage</p>
</li>
</ol>
<h4 id="3212-tasksched"><strong>3.2.1.2 TaskSched</strong></h4>
<p>相对DAG schedule而言tasked sketches低级别的调度接口。允许实现不同的task调度器。每个task sketched对象只服务于一个sparkleContext的task调度。taskScheduler从DAGScheduler的每个 stage 接受一组task，并负责将他们送到集群上运行他们。</p>
<h1 id="4spark-on-yarn运行过程"><strong>4.Spark on YARN运行过程</strong></h1>
<p>spark运行在不同的资源管理器上有不同的运行过程,这里解释在YARN平台的运行,详情见</p>
<blockquote>
<p><a href="http://www.cnblogs.com/shishanyuan/p/4721326.html">http://www.cnblogs.com/shishanyuan/p/4721326.html</a></p>
</blockquote>
<p><strong>Spark运行模式</strong></p>
<table>
<thead>
<tr>
<th><strong>运行环境</strong></th>
<th><strong>模式</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Local</td>
<td>本地模式</td>
<td>常用于本地开发测试，本地还分为local单线程和local-cluster多线程;</td>
</tr>
<tr>
<td>Standalone</td>
<td>集群模式</td>
<td>典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现HA</td>
</tr>
<tr>
<td>On yarn</td>
<td>集群模式</td>
<td>运行在yarn资源管理器框架之上，由yarn负责资源管理，Spark负责任务调度和计算</td>
</tr>
<tr>
<td>On mesos</td>
<td>集群模式</td>
<td>运行在mesos资源管理器框架之上，由mesos负责资源管理，Spark负责任务调度和计算</td>
</tr>
<tr>
<td>On cloud</td>
<td>集群模式</td>
<td>比如AWS的EC2，使用这个模式能很方便的访问Amazon的S3;Spark支持多种分布式存储系统：HDFS和S3</td>
</tr>
</tbody>
</table>
<p>Spark on YARN模式根据Driver在集群中的位置分为两种模式：</p>
<p>一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）。</p>
<h2 id="41-yarn-client"><strong>4.1 YARN-Client</strong></h2>
<p>Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是http://hadoop1:4040访问，而YARN通过http:// hadoop1:8088访问。</p>
<p><img src="F:%5C%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%5C%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%5CMDImages%5Cip_image004.jpeg" alt="img"></p>
<h2 id="42-yarn-cluster"><strong>4.2 YARN-Cluster</strong></h2>
<p>在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：</p>
<p>第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；</p>
<p>第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。</p>
<p><img src="F:%5C%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%5C%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%5CMDImages%5Cip_image005.jpeg" alt="img"></p>
<p><strong>YARN-Client 与 YARN-Cluster 区别</strong></p>
<p>理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别。</p>
<ul>
<li>YARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业；</li>
<li>YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开。</li>
</ul>
<blockquote>
<p>来自* <em>&lt;</em><a href="http://www.cnblogs.com/shishanyuan/p/4721326.html"><em>http://www.cnblogs.com/shishanyuan/p/4721326.html</em></a><em>&gt;</em></p>
</blockquote>

              


            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
            
            
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" data-tooltip="" aria-label="NEXT: ">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/zookeeper/%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%8E%9F%E7%90%86/" data-tooltip="" aria-label="PREVIOUS: ">
          
              <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/" title="Share on Facebook" aria-label="Share on Facebook">
          <i class="fab fa-facebook-square" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/" title="Share on Twitter" aria-label="Share on Twitter">
          <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.linkedin.com/sharing/share-offsite/?url=https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/" title="Share on Linkedin" aria-label="Share on Linkedin">
          <i class="fab fa-linkedin" aria-hidden="true"></i>
        </a>
      </li>
    
  
  
    <li class="post-action">
      <a class="post-action-btn btn btn--default" href="#disqus_thread" aria-label="Leave a comment">
        <i class="far fa-comment"></i>
      </a>
    </li>
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="Back to top">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


            
  
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
    <script type="text/javascript">
      var disqus_config = function() {
        this.page.url = 'https:\/\/xiaokunji.github.io\/myBlog\/post\/hadoop%E7%94%9F%E6%80%81%E5%9C%88\/spark\/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86\/';
        
          this.page.identifier = '\/post\/hadoop%E7%94%9F%E6%80%81%E5%9C%88\/spark\/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86\/'
        
      };
      (function() {
        
        
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
          document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
          return;
        }
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        var disqus_shortname = 'hugo-tranquilpeak-theme';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
  


          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2023 Firstname Lastname. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" data-tooltip="" aria-label="NEXT: ">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/zookeeper/%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%8E%9F%E7%90%86/" data-tooltip="" aria-label="PREVIOUS: ">
          
              <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/" title="Share on Facebook" aria-label="Share on Facebook">
          <i class="fab fa-facebook-square" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/" title="Share on Twitter" aria-label="Share on Twitter">
          <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.linkedin.com/sharing/share-offsite/?url=https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%8E%9F%E7%90%86/" title="Share on Linkedin" aria-label="Share on Linkedin">
          <i class="fab fa-linkedin" aria-hidden="true"></i>
        </a>
      </li>
    
  
  
    <li class="post-action">
      <a class="post-action-btn btn btn--default" href="#disqus_thread" aria-label="Leave a comment">
        <i class="far fa-comment"></i>
      </a>
    </li>
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="Back to top">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


      </div>
      
<div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-times"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fxiaokunji.github.io%2FmyBlog%2Fpost%2Fhadoop%25E7%2594%259F%25E6%2580%2581%25E5%259C%2588%2Fspark%2F%25E7%25AE%2580%25E4%25BB%258B%25E5%258F%258A%25E5%258E%259F%25E7%2590%2586%2F" aria-label="Share on Facebook">
          <i class="fab fa-facebook-square" aria-hidden="true"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fxiaokunji.github.io%2FmyBlog%2Fpost%2Fhadoop%25E7%2594%259F%25E6%2580%2581%25E5%259C%2588%2Fspark%2F%25E7%25AE%2580%25E4%25BB%258B%25E5%258F%258A%25E5%258E%259F%25E7%2590%2586%2F" aria-label="Share on Twitter">
          <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fxiaokunji.github.io%2FmyBlog%2Fpost%2Fhadoop%25E7%2594%259F%25E6%2580%2581%25E5%259C%2588%2Fspark%2F%25E7%25AE%2580%25E4%25BB%258B%25E5%258F%258A%25E5%258E%259F%25E7%2590%2586%2F" aria-label="Share on Linkedin">
          <i class="fab fa-linkedin" aria-hidden="true"></i><span>Share on Linkedin</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>


    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Firstname Lastname</h4>
    
      <div id="about-card-bio">Super bio with markdown support <strong>COOL</strong></div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Your job title
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        France
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://xiaokunji.github.io/myBlog/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js" integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://xiaokunji.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>


  
    <script async crossorigin="anonymous" defer integrity="sha512-gE8KAQyFIzV1C9+GZ8TKJHZS2s+n7EjNtC+IMRn1l5+WYJTHOODUM6JSjZhFhqXmc7bG8Av6XXpckA4tYhflnw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/apache.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-EWROca+bote+7Oaaar1F6y74iZj1r1F9rm/ly7o+/FwJopbBaWtsFDmaKoZDd3QiGU2pGacBirHJNivmGLYrow==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/go.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-GDVzAn0wpx1yVtQsRWmFc6PhJiLBPdUic+h4GWgljBh904O3JU10fk9EKNpVyIoPqkFn54rgL2QBG4BmUTMpiQ==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/http.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-UgZlma8NzkrDb/NWgmLIcTrH7i/CSnLLDRFqCSNF5NGPpjKmzyM25qcoXGOup8+cDakKyaiTDd7N4dyH4YT+IA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/less.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-lot9koe73sfXIrUvIPM/UEhuMciN56RPyBdOyZgfO53P2lkWyyXN7J+njcxIIBRV+nVDQeiWtiXg+bLAJZDTfg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/nginx.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-Zd3e7XxHP00TD0Imr0PIfeM0fl0v95kMWuhyAS3Wn1UTSXTkz0OhtRgBAr4JlmADRgiXr4x7lpeUdqaGN8xIog==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/puppet.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-qtqDO052iXMSP+5d/aE/jMtL9vIIGvONgTJziC2K/ZIB1yEGa55WVxGE9/08rSQ62EoDifS9SWVGZ7ihSLhzMA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/scss.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-1NmkjnEDnwwwcu28KoQF8vs3oaPFokQHbmbtwGhFfeDsQZtVFI8zW2aE9O8yMYdpdyKV/5blE4pSWw4Z/Sv97w==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/stylus.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-B2wSfruPjr8EJL6IIzQr1eAuDwrsfIfccNf/LCEdxELCgC/S/ZMt/Uvk80aD79m7IqOqW+Sw8nbkvha20yZpzg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/swift.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-28oDiQZGKUVN6wQ7PSLPNipOcmkCALXKwOi7bnkyFf8QiMZQxG9EQoy/iiNx6Zxj2cG2SbVa4dXKigQhu7GiFw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/yaml.min.js"></script>
  


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>




    
  </body>
</html>

