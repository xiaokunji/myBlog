<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <script type="application/ld+json">

{  
  "@context":"http://schema.org",
  "@type":"Website",
  "@id":"https:\/\/xiaokunji.github.io\/myBlog\/",
  "author": {
    "@type": "Person",
    "name": "Firstname Lastname",
    
    "image": "https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c"
    
  },
  "name":"Hugo tranquilpeak theme",
  "description":"Hugo tranquilpeak theme demo",
  "url":"https:\/\/xiaokunji.github.io\/myBlog\/post\/",
  "keywords":"[]"
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.116.1 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="Firstname Lastname">
<meta name="keywords" content="">
<meta name="description" content="Hugo tranquilpeak theme demo">


<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta property="og:type" content="website">
<meta property="og:title" content="Posts">
<meta name="twitter:title" content="Posts">
<meta property="og:url" content="https://xiaokunji.github.io/myBlog/post/">
<meta property="twitter:url" content="https://xiaokunji.github.io/myBlog/post/">
<meta property="og:site_name" content="Hugo tranquilpeak theme">
<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta name="twitter:description" content="Hugo tranquilpeak theme demo">
<meta property="og:locale" content="en-us">


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">






    <title>Posts</title>

    <link rel="icon" href="https://xiaokunji.github.io/myBlog/favicon.png">
    
      <link rel="alternate" type="application/rss+xml" title="RSS" href="https://xiaokunji.github.io/myBlog/post/index.xml">
    

    

    <link rel="canonical" href="https://xiaokunji.github.io/myBlog/post/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://xiaokunji.github.io/myBlog/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://xiaokunji.github.io/myBlog/" aria-label="Go to homepage">Hugo tranquilpeak theme</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://xiaokunji.github.io/myBlog/#about" aria-label="Open the link: /#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://xiaokunji.github.io/myBlog/#about" aria-label="Read more about the author">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Firstname Lastname</h4>
        
          <h5 class="sidebar-profile-bio">Super bio with markdown support <strong>COOL</strong></h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/content" title="我的">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">我的</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/categories" title="Categories">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/tags" title="Tags">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/archives" title="Archives">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/#about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/kakawait" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stackoverflow.com/users/636472/kakawait" target="_blank" rel="noopener" title="Stack Overflow">
    
      <i class="sidebar-button-icon fab fa-lg fa-stack-overflow" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Stack Overflow</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/index.xml" title="RSS">
    
      <i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <section class="postShorten-group main-content-wrap">
          
          
          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E6%95%B0%E4%BB%93/%E6%90%AD%E5%BB%BA%E6%95%B0%E4%BB%93/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        来源: https://mp.weixin.qq.com/s/PwnQl6uji85m7BGALmOVrw
数仓建模的过程分为业务建模、领域建模、逻辑建模和物理建模，但是这 些步骤比较抽象。为了便于落地，我根据自己的经验，总结出上面的七个步骤：梳理业务流程、垂直切分、指标体系梳理、实体关系调研、维度梳理、数仓分层以及物理模型建立。每个步骤不说理论，直接放工具、模板和案例。
1. 业务流程
找到公司核心业务流程，找到谁，在什么环节，做什么关键动作，得到什么结果。 梳理每个业务节点的客户及关注重点，找到数据在哪。 分域/主题
决定数仓的建设方式，快速交活，就用自下而上的建设。要全面支撑，就顶层规划，分步实施，交活稍微慢点。
同时按照业务领域划分主题域。主题域的划分方法有：按业务流划分（推荐）、按需求分、按职责分、按产品功能分等。 指标体系
指标的意义在于统一语言，统一口径。所以指标的定义必须有严格的标准。否则如无根之水。
指标可分为原子指标、派生指标和衍生指标，其含义及命名规则举例如下：
依照指标体系建设标准，开始梳理指标体系。整个体系同样要以业务为核心进行梳理。同时梳理每个业务过程所需的维度。维度就是你观察这个业务的角度，指标就是衡量这个业务结果 好坏的量化结果。 请注意，此时不能被现有数据局限。如果分析出这个业务过程应该有这个指标，但是没有数据，请标注出来，提出收集数据的需求。
4. 实体关系
每个业务动作都会有数据产生。我们将能够获取到的数据，提取实体，绘制ER图，便于之后的维度建模。 同样以业务过程为起点向下梳理，此时的核心是业务表。把每张表中涉及的维度、指标都整理出来。 维度整理 维度标准化是将各个业务系统中相同的维度进行统一的过程。其字段名称、代码、名字都可能不一样，我们需要完全掌握，并标准化。 维度的标准尽可能参照国家标准、行业标准。例如地区可以参照国家行政区域代码。
另外，有些维度存在层级，如区域的省、市、县。绝大多数业务系统中的级联就是多层级维度。
数仓分层 数据仓库一般分为4层，名字可能会不一样，但是其目的和建设方法基本一致： 每一层采用的建模方法都不一样，其核心是逐层解耦。越到底层，越接近业务发生的记录，越到上层，越接近业务目标。
依托数仓分层的设计理论，根据实际业务场景，我们就可以梳理出整体的数据流向图。这张图会很清晰的告诉所有人，数据从那来，到哪里去，最终提供什么样的服务。 模型建立 此时才真正进入纯代码阶段。数仓、ETL工具选型；ETL流程开发；cube的建立；任务调度，设定更新方式、更新频率；每日查看日志、监控etl执行情况等等。 前面梳理清楚了，ETL会变的非常清晰
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E6%95%B0%E4%BB%93/%E6%90%AD%E5%BB%BA%E6%95%B0%E4%BB%93/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/hbase/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1. 为何HBase速度很快？ HBase能提供实时计算服务主要原因是由其架构和底层的数据结构决定的，即由LSM-Tree(Log-Structured Merge-Tree) + HTable(region分区) + Cache决定——客户端可以直接定位到要查数据所在的HRegion server服务器，然后直接在服务器的一个region上查找要匹配的数据，并且这些数据部分是经过cache缓存的。
HBase的写入速度快是因为它其实并不是真的立即写入文件中，而是先写入内存，随后异步刷入HFile。所以在客户端看来，写入速度很快。另外，写入时候将随机写入转换成顺序写，数据写入速度也很稳定。
读取速度快是因为它使用了LSM树型结构，而不是B或B+树.HBase的存储结构导致它需要磁盘寻道时间在可预测范围内，并且读取与所要查询的rowkey连续的任意数量的记录都不会引发额外的寻道开销。而且，HBase读取首先会在缓存（BlockCache）中查找，它采用了LRU（最近最少使用算法），如果缓存中没找到，会从内存中的MemStore中查找，再去HFile查找
https://zhuanlan.zhihu.com/p/83233850
2. hbase 实时查询的原理 实时查询，可以认为是从内存中查询，一般响应时间在 1 秒内。 HBase 的机制是数据先写入到内存中，当数据量达到一定的量（如 128M），再写入磁盘中， 在内存中，是不进行数据的更新或合并操作的，只增加数据，这使得用户的写操作只要进入内存中就可以立即返回，保证了 HBase I/O 的高性能。
3. 列簇怎么创建比较好？(&lt;=2) rowKey 最好要创建有规则的 rowKey，即最好是有序的。 HBase 中一张表最好只创建一到两个列族比较好，因为 HBase 不能很好的处理多个列族。
4. 描述 HBase 中 scan 和 get 的功能以及实现的异同？ HBase 的查询实现只提供两种方式：
按指定 RowKey 获取唯一一条记录，get 方法（org.apache.hadoop.hbase.client.Get）Get 的方法处理分两种 : 设置了 ClosestRowBefore 和没有设置 ClosestRowBefore 的rowlock。主要是用来保证行的事务性，即每个 get 是以一个 row 来标记的。一个 row 中可以有很多 family 和 column。
按指定的条件获取一批记录，scan 方法(org.apache.Hadoop.hbase.client.Scan）实现条件查询功能使用的就是 scan 方式。
原文链接：https://blog.csdn.net/shujuelin/article/details/89035272
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/hbase/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/hive/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1. Hive 的 sort by 和 order by 的区别 order by 会对输入做全局排序，因此只有一个reducer（多个reducer无法保证全局有序）只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。
sort by不是全局排序，其在数据进入reducer前完成排序.
因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1， 则sort by只保证每个reducer的输出有序，不保证全局有序。
2. Hbase 和 hive 有什么区别hive 与 hbase 的底层存储是什么？hive是产生的原因是什么？habase是为了弥补hadoop的什么缺陷？
答案
​ 共同点：
hbase与hive都是架构在hadoop之上的。都是用hadoop作为底层存储 区别：
Hive是建立在Hadoop之上为了减少MapReducejobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。
象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。
Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。
Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。
6. hive借用hadoop的MapReduce来完成一些hive中的命令的执行
7. hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。
8. hbase是列存储。
9. hdfs作为底层存储，hdfs是存放文件的系统，而Hbase负责组织文件。
10. hive需要用到hdfs存储文件，需要用到MapReduce计算框架。
3. 数据仓库hive中，启动hive服务器的命令有哪些？分别代表什么意思？内部表与外部表有啥区别？分区与分桶，指的是什么？ 命令：
hive &ndash;service metastore 启动元数据
hive：本地运行hive命令
hiveserver2：远程服务，开放默认端口 10000
内部表：内部表删除表时，数据也会被删除，
外部表：外部表在创建时需要加external，删除表时，表中的数据仍然会存储在hadoop中，不会丢失
分区：分文件夹：分目录，把一个大的数据集根据业务需要分割成小的数据集
分桶：分数据：分桶是将数据集分解成更容易管理的若干部分
原文链接：https://blog.csdn.net/pingsha_luoyan/article/details/97750251
4. hive中集合数据类型什么？有什么作用？什么情况下，hive需要使用集合类型？ 数据类型：
6个基本类型：整数，布尔类型，浮点数，字符，时间类型。字节数组
2个集合数据类型： struct，map，array
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/hive/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/kafka/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.kafka的message包括哪些信息 一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成。当magic的值为1的时候，会在magic和crc32之间多一个字节的数据：attributes(保存一些相关属性，比如是否压缩、压缩格式等等)；如果magic的值为0，那么不存在attributes属性body是由N个字节构成的一个消息体，包含了具体的key/value消息
2. 怎么解决kafka的数据丢失 producer端： 宏观上看保证数据的可靠安全性，肯定是依据分区数做好数据备份，设立副本数。
broker端： topic设置多分区，分区自适应所在机器，为了让各分区均匀分布在所在的broker中，分区数要大于broker数。
分区是kafka进行并行读写的单位，是提升kafka速度的关键。
Consumer端 consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。由于Kafka consumer默认是自动提交位移的，所以在后台提交位移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长，则建议把逻辑放到另一个线程中去做。为了避免数据丢失，现给出两点建议：
enable.auto.commit=false 关闭自动提交位移
在消息被完整处理之后再手动提交位移
3.为什么Kafka不支持读写分离？ 也就是说: kafka对某一个主题的读写是在一个节点完成的,分区的从节点都是用来同步的
既然是在一个节点,为什么能做到高并发?(大概是因为: 对主题的读写本质是对主分区的读写,只要主分区尽可能的分配均匀至每个节点,就能分散压力)
因为这样有两个明显的缺点：
数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。 延时问题。数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。 对于Kafka来说，必要性不是很高，因为在Kafka集群中，如果存在多个副本，经过合理的配置，可以让leader副本均匀的分布在各个broker上面，使每个 broker 上的读写负载都是一样的。
4. Kafka中的延迟队列 在发送延时消息的时候并不是先投递到要发送的真实主题（real_topic）中，而是先投递到一些 Kafka 内部的主题（delay_topic）中，这些内部主题对用户不可见，然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。
5. Kafka为什么吞吐量大、速度快？ 一、顺序读写
众所周知Kafka是将消息记录持久化到本地磁盘中的，一般人会认为磁盘读写性能差，可能会对Kafka性能如何保证提出质疑。实际上不管是内存还是磁盘，快或慢关键在于寻址的方式，磁盘分为顺序读写与随机读写，内存也一样分为顺序读写与随机读写。基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，一般而言要高出磁盘随机读写三个数量级，一些情况下磁盘顺序读写性能甚至要高于内存随机读写。
二、Page Cache
为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。这样做的好处有：
1避免Object消耗：如果是使用 Java 堆，Java对象的内存消耗比较大，通常是所存储数据的两倍甚至更多。
2避免GC问题：随着JVM中数据不断增多，垃圾回收将会变得复杂与缓慢，使用系统缓存就不会存在GC问题
相比于使用JVM或in-memory cache等数据结构，利用操作系统的Page Cache更加简单可靠。首先，操作系统层面的缓存利用率会更高，因为存储的都是紧凑的字节结构而不是独立的对象。其次，操作系统本身也对于Page Cache做了大量优化，提供了 write-behind、read-ahead以及flush等多种机制。再者，即使服务进程重启，系统缓存依然不会消失，避免了in-process cache重建缓存的过程。
通过操作系统的Page Cache，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。
三、零拷贝
linux操作系统 “零拷贝” 机制使用了sendfile方法， 允许操作系统将数据从Page Cache 直接发送到网络，只需要最后一步的copy操作将数据复制到 NIC 缓冲区， 这样避免重新复制数据 。示意图如下：
![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA3LzA4L1pyNTF6Vi5wbmc)通过这种 “零拷贝” 的机制，Page Cache 结合 sendfile 方法，Kafka消费端的性能也大幅提升。这也是为什么有时候消费端在不断消费数据时，我们并没有看到磁盘io比较高，此刻正是操作系统缓存在提供数据。
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/kafka/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1. spark shuffle过程 spark中管理shuffle的过程有一个shuffleManage负责管理, 在spark 2.X 之后,主要负责的是sortshufflemanager, 其中主要的是sortshuffle,shuffle分为两个阶段,shufflewriter和shuffleread
a) map task 的计算结果会写入到一个内存数据结构里面，内存数据结构默认是5M
b) 在shuffle的时候会有一个定时器，不定期的去估算这个内存结构的大小，当内存结构中的数据超过5M时，比如现在内存结构中的数据为5.01M，那么他会申请5.01*2-5=5.02M内存给内存数据结构。
c) 如果申请成功不会进行溢写，如果申请不成功，这时候会发生溢写磁盘。
d) 在溢写之前内存结构中的数据会进行排序分区
e) 然后开始溢写磁盘，写磁盘是以batch的形式去写，一个batch是1万条数据，
f) map task执行完成后，会将这些磁盘小文件合并成一个大的磁盘文件，同时生成一个索引文件。
g) reduce task去map端拉取数据的时候，首先解析索引文件，根据索引文件再去拉取对应的数据。
https://blog.csdn.net/qq_21835703/article/details/79104733
2. spark streaming 读取kafka数据的两种方式 这两种方式分别是：
Receiver-base 使用Kafka的高层次Consumer API来实现。receiver从Kafka中获取的数据都存储在Spark Executor的内存中，然后Spark Streaming启动的job会去处理那些数据。然而，在默认的配置下，这种方式可能会因为底层的失败而丢失数据。如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。该机制会同步地将接收到的Kafka数据写入分布式文件系统（比如HDFS）上的预写日志中。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。
Direct Spark1.3中引入Direct方式，用来替代掉使用Receiver接收数据，这种方式会周期性地查询Kafka，获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。(使用比received更底层的api)
3. Spark提供的两种共享变量 Spark 程序的大部分操作都是 RDD 操作，通过传入函数给 RDD 操作函数来计算，这些函数在不同的节点上并发执行，内部的变量有不同的作用域，不能相互访问，有些情况下不太方便。
广播变量，是一个只读对象，在所有节点上都有一份缓存，创建方法是 SparkContext.broadcast()。创建之后再更新它的值是没有意义的，一般用 val 来修改定义。 计数器，只能增加，可以用计数或求和，支持自定义类型。创建方法是 SparkContext.accumulator(V, name)。只有 Driver 程序可以读这个计算器的变量，RDD 操作中读取计数器变量是无意义的。但节点可以对该计算器进行增加（？？？） 以上两种类型都是 Spark 的共享变量。
https://zhuanlan.zhihu.com/p/49169166
4. 解释一下Spark Master的选举过程 与hadoop一样，spark也存在单点故障问题，为此，spark的standalone模式提供了master的HA，与hadoop一样，一个是active，一个是standby状态，当active挂了，standby会顶上。
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/spark/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/%E9%80%9A%E7%94%A8/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.假如我有 100亿条数据，但是我们的内存只有1M，但是我们磁盘很大 我们现在要对这100亿条数据进行排序，是没法把所有的数据一次性的load进行内存进行排序的，这就涉及到一个外部排序的问题，我们的1M内存只能装进1亿条数据，每次都只能对这 1亿条数据进行排序，排好序后输出到磁盘，总共输出100个文件，最后怎么把这100个文件进行merge成一个全局有序的大文件。
我们可以每个文件（有序的）都取一部分头部数据最为一个 buffer， 并且把这 100个 buffer放在一个堆里面，进行堆排序，比较方式就是对所有堆元素（buffer）的head元素进行比较大小， 然后不断的把每个堆顶的 buffer 的head 元素 pop 出来输出到最终文件中，(想象链表的有序合并) 然后继续堆排序，继续输出。如果哪个buffer 空了，就去对应的文件中继续补充一部分数据。最终就得到一个全局有序的大文件。
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/%E9%9D%A2%E8%AF%95/%E9%80%9A%E7%94%A8/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/java%E5%8F%8A%E5%85%B6%E6%A1%86%E6%9E%B6/dubbo/%E4%BB%8B%E7%BB%8D/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。简单的说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的东东，说白了就是个远程服务调用的分布式框架
其核心部分包含:
远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。
集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。
自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。
来自* &lt;https://blog.csdn.net/wilsonke/article/details/39896595&gt;
架构
节点角色说明
节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 来自* &lt;http://dubbo.apache.org/zh-cn/docs/user/preface/architecture.html&gt;
调用关系说明:
服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 来自* &lt;http://dubbo.apache.org/zh-cn/docs/user/preface/architecture.html&gt;
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/java%E5%8F%8A%E5%85%B6%E6%A1%86%E6%9E%B6/dubbo/%E4%BB%8B%E7%BB%8D/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
          
  <div class="pagination-bar">
    <ul class="pagination">
      
        
          <li class="pagination-prev">
            <a class="btn btn--default btn--small" href="https://xiaokunji.github.io/myBlog/post/page/7/" aria-label="NEWER POSTS">
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>NEWER POSTS</span>
            </a>
          </li>
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="https://xiaokunji.github.io/myBlog/post/page/9/" aria-label="OLDER POSTS">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
      
      <li class="pagination-number">page 8 of 40</li>
    </ul>
  </div>


        </section>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2023 Firstname Lastname. All Rights Reserved
  </span>
</footer>

      </div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Firstname Lastname</h4>
    
      <div id="about-card-bio">Super bio with markdown support <strong>COOL</strong></div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Your job title
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        France
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://xiaokunji.github.io/myBlog/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js" integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://xiaokunji.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>


  
    <script async crossorigin="anonymous" defer integrity="sha512-gE8KAQyFIzV1C9+GZ8TKJHZS2s+n7EjNtC+IMRn1l5+WYJTHOODUM6JSjZhFhqXmc7bG8Av6XXpckA4tYhflnw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/apache.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-EWROca+bote+7Oaaar1F6y74iZj1r1F9rm/ly7o+/FwJopbBaWtsFDmaKoZDd3QiGU2pGacBirHJNivmGLYrow==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/go.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-GDVzAn0wpx1yVtQsRWmFc6PhJiLBPdUic+h4GWgljBh904O3JU10fk9EKNpVyIoPqkFn54rgL2QBG4BmUTMpiQ==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/http.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-UgZlma8NzkrDb/NWgmLIcTrH7i/CSnLLDRFqCSNF5NGPpjKmzyM25qcoXGOup8+cDakKyaiTDd7N4dyH4YT+IA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/less.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-lot9koe73sfXIrUvIPM/UEhuMciN56RPyBdOyZgfO53P2lkWyyXN7J+njcxIIBRV+nVDQeiWtiXg+bLAJZDTfg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/nginx.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-Zd3e7XxHP00TD0Imr0PIfeM0fl0v95kMWuhyAS3Wn1UTSXTkz0OhtRgBAr4JlmADRgiXr4x7lpeUdqaGN8xIog==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/puppet.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-qtqDO052iXMSP+5d/aE/jMtL9vIIGvONgTJziC2K/ZIB1yEGa55WVxGE9/08rSQ62EoDifS9SWVGZ7ihSLhzMA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/scss.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-1NmkjnEDnwwwcu28KoQF8vs3oaPFokQHbmbtwGhFfeDsQZtVFI8zW2aE9O8yMYdpdyKV/5blE4pSWw4Z/Sv97w==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/stylus.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-B2wSfruPjr8EJL6IIzQr1eAuDwrsfIfccNf/LCEdxELCgC/S/ZMt/Uvk80aD79m7IqOqW+Sw8nbkvha20yZpzg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/swift.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-28oDiQZGKUVN6wQ7PSLPNipOcmkCALXKwOi7bnkyFf8QiMZQxG9EQoy/iiNx6Zxj2cG2SbVa4dXKigQhu7GiFw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/yaml.min.js"></script>
  


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>




    
  </body>
</html>

