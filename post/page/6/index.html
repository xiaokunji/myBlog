<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <script type="application/ld+json">

{  
  "@context":"http://schema.org",
  "@type":"Website",
  "@id":"https:\/\/xiaokunji.github.io\/myBlog\/",
  "author": {
    "@type": "Person",
    "name": "Firstname Lastname",
    
    "image": "https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c"
    
  },
  "name":"Hugo tranquilpeak theme",
  "description":"Hugo tranquilpeak theme demo",
  "url":"https:\/\/xiaokunji.github.io\/myBlog\/post\/",
  "keywords":"[]"
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.116.1 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="Firstname Lastname">
<meta name="keywords" content="">
<meta name="description" content="Hugo tranquilpeak theme demo">


<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta property="og:type" content="website">
<meta property="og:title" content="Posts">
<meta name="twitter:title" content="Posts">
<meta property="og:url" content="https://xiaokunji.github.io/myBlog/post/">
<meta property="twitter:url" content="https://xiaokunji.github.io/myBlog/post/">
<meta property="og:site_name" content="Hugo tranquilpeak theme">
<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta name="twitter:description" content="Hugo tranquilpeak theme demo">
<meta property="og:locale" content="en-us">


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">






    <title>Posts</title>

    <link rel="icon" href="https://xiaokunji.github.io/myBlog/favicon.png">
    
      <link rel="alternate" type="application/rss+xml" title="RSS" href="https://xiaokunji.github.io/myBlog/post/index.xml">
    

    

    <link rel="canonical" href="https://xiaokunji.github.io/myBlog/post/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://xiaokunji.github.io/myBlog/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://xiaokunji.github.io/myBlog/" aria-label="Go to homepage">Hugo tranquilpeak theme</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://xiaokunji.github.io/myBlog/#about" aria-label="Open the link: /#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://xiaokunji.github.io/myBlog/#about" aria-label="Read more about the author">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Firstname Lastname</h4>
        
          <h5 class="sidebar-profile-bio">Super bio with markdown support <strong>COOL</strong></h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/content" title="我的">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">我的</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/categories" title="Categories">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/tags" title="Tags">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/archives" title="Archives">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/#about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/kakawait" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stackoverflow.com/users/636472/kakawait" target="_blank" rel="noopener" title="Stack Overflow">
    
      <i class="sidebar-button-icon fab fa-lg fa-stack-overflow" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Stack Overflow</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/index.xml" title="RSS">
    
      <i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <section class="postShorten-group main-content-wrap">
          
          
          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/spark-sql/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.前言: SparkSQL的前身是Shark，给熟悉RDBMS但又不理解MapReduce的技术人员提供快速上手的工具，但是Shark对Hive有太多依赖(如采用Hive的语法解析器、查询优化器等等),所以SparkSQL抛弃原有Shark的代码，汲取了Shark的一些优点，如内存列存储（In-Memory Columnar Storage）、Hive兼容性等，重新开发了SparkSQL代码.
不再受限于Hive，只是兼容Hive
而Hive on Spark是一个Hive的发展计划，该计划将Spark作为Hive的底层引擎之一，也就是说，Hive将不再受限于一个引擎，可以采用Map-Reduce、Tez、Spark等引擎
来自* &lt;http://www.cnblogs.com/shishanyuan/p/4723604.html&gt;
可以这么说, sparkSQL做到了大部分HIVE的功能,但是比它快(因为重写了底层,而且用的是RDD),将操作写到代码里了
对SparkSQL来说,主要的工作就是写SQL,和写自定义函数了(类似于HIVE),
大致流程: 从数据源(HIVE,HDFS,文本等)读取数据,然后写SQL查询,(有业务处理就处理),复杂的就写自定义函数(继承UserDefinedFunction或者 UserDefinedAggregateFunction)
查sql前当然要有数据和表,在代码里只能写临时表,要想创建永久表,还是得用hive那一套(相关语句可以直接运行也可以写代码里)
目前比较流行的是SparkSQL 连接Hive,这样可以操作Hive中的数据,(在spark1.2.1后,自带Hive,但是sparksql用到了hive的元数据,所以需要额外提供mysql(用来存储元数据,当然也有自带的叫derby),但局限性比较大,估计生产中还是会用外部Hive),这样就又得学Hive,暂时放弃
1.1 Spark SQL基础 使用spark SQL有两种方式，一种是作为分布式SQL引擎,此时只需要写SQL就可以进行计算。另一种是吃饭spark程序中通过领域API的形式来操作数据(被抽象为DateFrame)。
简单的说: 一种是和SQL引擎去查数据(已经有数据了,一般和HIVE一起用); 一种是通过API的方式加载数据并操作(一般是从本地,HDFS,JDBC等加载文本数据)
2.为什么sparkSQL的性能得到提升 这个简单了解即可，
内存列存储（In-Memory Columnar Storage） 字节码生成技术 scala代码优化 3.sparkSQL组成 sparkSQL1.1总体上由四个模块组成：core、catalyst、hive、hive-Thriftserver：
core 处理数据的输入输出，从不同的数据源获取数据（RDD、Parquet、json等），将查询结果输出成schemaRDD； catalyst 处理查询语句的整个处理过程，包括解析、绑定、优化、物理计划等，说其是优化器，还不如说是查询引擎； hive 对hive数据的处理 hive-ThriftServer 提供CLI和JDBC/ODBC接口 在这四个模块中，catalyst处于最核心的部分，其性能优劣将影响整体的性能。由于发展时间尚短，还有很多不足的地方，但其插件式的设计，为未来的发展留下了很大的空间。下面是catalyst的一个设计图：
其中虚线部分是以后版本要实现的功能，实线部分是已经实现的功能。从上图看，catalyst主要的实现组件有：
sqlParse，完成sql语句的语法解析功能，目前只提供了一个简单的sql解析器；
Analyzer，主要完成绑定工作，将不同来源的Unresolved LogicalPlan和数据元数据（如hive metastore、Schema catalog）进行绑定，生成resolved LogicalPlan；
optimizer对resolved LogicalPlan进行优化，生成optimized LogicalPlan；
Planner将LogicalPlan转换成PhysicalPlan；
CostModel，主要根据过去的性能统计数据，选择最佳的物理执行计划
这些组件的基本实现方法：
先将sql语句通过解析生成Tree，然后在不同阶段使用不同的Rule应用到Tree上，通过转换完成各个组件的功能。
Analyzer使用Analysis Rules，配合数据元数据（如hive metastore、Schema catalog），完善Unresolved LogicalPlan的属性而转换成resolved LogicalPlan；
optimizer使用Optimization Rules，对resolved LogicalPlan进行合并、列裁剪、过滤器下推等优化作业而转换成optimized LogicalPlan；
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/spark-sql/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/spark-streaming/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.概述 Spark Streaming 是Spark核心API的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理。支持从多种数据源获取数据，包括Kafk、Flume、Twitter、ZeroMQ、Kinesis 以及TCP sockets，从数据源获取数据之后，可以使用诸如map、reduce、join和window等高级函数进行复杂算法的处理。最后还可以将处理结果存储到文件系统，数据库和现场仪表盘。
来自* &lt;http://www.cnblogs.com/shishanyuan/p/4747735.html&gt;
2. Streaming架构 2.1 计算流程： Spark Streaming是将流式计算分解成一系列短小的批处理作业。这里的批处理引擎是Spark Core，也就是把Spark Streaming的输入数据按照batch size（如1秒）分成一段一段的数据（Discretized Stream），每一段数据都转换成Spark中的RDD（Resilient Distributed Dataset），然后将Spark Streaming中对DStream的Transformation操作变为针对Spark中对RDD的Transformation操作，将RDD经过操作变成中间结果保存在内存中。整个流式计算根据业务的需求可以对中间的结果进行叠加或者存储到外部设备。下图显示了Spark Streaming的整个流程。
图Spark Streaming构架
2.2 容错性： 对于流式计算来说，容错性至关重要。首先我们要明确一下Spark中RDD的容错机制。每一个RDD都是一个不可变的分布式可重算的数据集，其记录着确定性的操作继承关系（lineage），所以只要输入数据是可容错的，那么任意一个RDD的分区（Partition）出错或不可用，都是可以利用原始输入数据通过转换操作而重新算出的。
对于Spark Streaming来说，其RDD的传承关系如下图所示，图中的每一个椭圆形表示一个RDD，椭圆形中的每个圆形代表一个RDD中的一个Partition，图中的每一列的多个RDD表示一个DStream（图中有三个DStream），而每一行最后一个RDD则表示每一个Batch Size所产生的中间结果RDD。我们可以看到图中的每一个RDD都是通过lineage相连接的，由于Spark Streaming输入数据可以来自于磁盘，例如HDFS（多份拷贝）或是来自于网络的数据流（Spark Streaming会将网络输入数据的每一个数据流拷贝两份到其他的机器）都能保证容错性，所以RDD中任意的Partition出错，都可以并行地在其他机器上将缺失的Partition计算出来。这个容错恢复方式比连续计算模型（如Storm）的效率更高。
Spark Streaming中RDD的lineage关系图
2.3 实时性： 对于实时性的讨论，会牵涉到流式处理框架的应用场景。Spark Streaming将流式计算分解成多个Spark Job，对于每一段数据的处理都会经过Spark DAG图分解以及Spark的任务集的调度过程。对于目前版本的Spark Streaming而言，其最小的Batch Size的选取在0.5~2秒钟之间（Storm目前最小的延迟是100ms左右）
2.4 扩展性与吞吐量： Spark目前在EC2上已能够线性扩展到100个节点（每个节点4Core），可以以数秒的延迟处理6GB/s的数据量（60M records/s），其吞吐量也比流行的Storm高2～5倍。
来自* &lt;http://www.cnblogs.com/shishanyuan/p/4747735.html&gt;
3.使用 3.1 基本使用(接收套接字) import org.apache.spark._ import org.apache.spark.streaming._ import org.apache.spark.streaming.StreamingContext._ // Create a local StreamingContext with two working thread and batch interval of 1 second.
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/spark-streaming/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/storm%E4%B8%8Espark-streaming/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        Spark Streaming与Storm的优劣分析
事实上，Spark Streaming绝对谈不上比Storm优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。
Spark Streaming仅仅在吞吐量上比Storm要优秀，而吞吐量这一点，也是历来挺Spark Streaming，贬Storm的人着重强调的。但是问题是，是不是在所有的实时计算场景下，都那么注重吞吐量？不尽然。因此，通过吞吐量说Spark Streaming强于Storm，不靠谱。
事实上，Storm在实时延迟度上，比Spark Streaming就好多了，前者是纯实时，后者是准实时。而且，Storm的事务机制、健壮性 / 容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。
Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。
来自* &lt;http://blog.csdn.net/kwu_ganymede/article/details/50296831&gt;
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/storm%E4%B8%8Espark-streaming/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/structured-streaming/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1. 介绍 Structured Streaming是Spark2.0版本提出的新的实时流框架（2.0和2.1是实验版本，从Spark2.2开始为稳定版本），相比于Spark Streaming，优点如下：
1.同样能支持多种数据源的输入和输出，参考如上的数据流图
2.以结构化的方式操作流式数据，能够像使用Spark SQL处理离线的批处理一样，处理流数据，代码更简洁，写法更简单
3.基于Event-Time，相比于Spark Streaming的Processing-Time更精确，更符合业务场景
4.解决了Spark Streaming存在的代码升级，DAG图变化引起的任务失败，无法断点续传的问题（Spark Streaming的硬伤！！！）
原文链接：https://blog.csdn.net/lovechendongxing/article/details/81748237
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/structured-streaming/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E5%91%BD%E4%BB%A4/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        注:使用spark时,需要开启HDFS,(如果运行在yarn上还需开YARN)
启动Spark: (hadoop这个命令不起作用了) start-all.sh
启动后主机有Master进程, 从机有Worker进程
停止Spark: stop-all.sh
进入Spark-Shell:(进入scala环境) spark-shell
上传jar包:(这里是运行在Standalone上,&ndash;master后是指定资源管理器)
spark-submit --master spark://master:7077 --class com.yc.hello hello.jar
更多命令:http://dataunion.org/10345.html
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E5%91%BD%E4%BB%A4/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
注:配置环境时,$SPARK_HOME/sbin一定放在hadoop的sbin前面,因为这两个文件夹中都含有start-all.sh和stop-all.sh,而spark启动/关闭用到了这两个脚本,而hadoop中这么命令已经遗弃了
源笔记:
1.修改slave文件,配置从机
如下:
slave01
slave02
slave03
2.修改spark.env.sh,如下:
export JAVA_HOME=/mysoftware/jdk1.8.0_101 export SPARK_MASTER_IP=master export SCALA_HOME=/mysoftware/scala-2.12.3 export HADOOP_HOME=/mysoftware/hadoop-2.7.3 export HADOOP_CONF_DIR=/mysoftware/hadoop-2.7.3/etc/hadoop/ 3.发送到从机即可,集群环境搭建完毕
一、安装Spark集群 1. 解压安装包 tar -zxvf ~/jar/spark-1.6.3-bin-hadoop2.6.tgz -C /data
2. 配置spark 涉及到的配置文件有以下几个：
${SPARK_HOME}/conf/spark-env.sh
${SPARK_HOME}/conf/slaves
${SPARK_HOME}/conf/spark-defaults.conf
这三个文件都是由原始的template文件复制过来的，比如cp spark-env.sh.template spark-env.sh
配置文件1：spark-env.sh
JAVA_HOME=/data/jdk1.8.0_111 SCALA_HOME=/data/scala-2.11.8 SPARK_MASTER_HOST=master SPARK_MASTER_PORT=7077 HADOOP_CONF_DIR=/data/hadoop-2.6.5/etc/hadoop # shuffled以及RDD的数据存放目录 SPARK_LOCAL_DIRS=/data/spark_data # worker端进程的工作目录 SPARK_WORKER_DIR=/data/spark_data/spark_works 注意：需要在本地创建/data/spark_data/spark_works目录
配置文件2：slaves
master slave1 slave2 配置文件3：spark-defaults.conf
spark.master spark://master:7077 spark.serializer org.apache.spark.serializer.KryoSerializer spark.eventLog.enabled true spark.eventLog.dir file:///data/spark_data/history/event-log spark.history.fs.logDirectory file:///data/spark_data/history/spark-events spark.eventLog.compress true 注意：需要在本地创建/data/spark_data/history/event-log、/data/spark_data/history/spark-events
3. 复制到其他节点 在master上：
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.介绍,原理,原因 见 hive中的数据倾斜
2. 解决方案 ++自定义分区++,这需要用户自己继承partition类,指定分区策略,这种方式效果比较显著。
重新设计key,++有一种方案是在MAP阶段时给KEY加上一个随机数++,有了随机数的key就不会被大量的分配到同一节点(小几率),++待到REDUCE后再把随机数去掉++即可。(大表连接大表的情况可以用)
++使用combinner合并++,combinner是在map阶段,reduce之前的一个中间阶段,在这个阶段可以选择性的把大量的相同key数据先进行一个合并,可以看做是local reduce,然后再交给reduce来处理,这样做的好处很多,即减轻了map端向reduce端发送的数据量(减轻了网络带宽),也减轻了map端和reduce端中间的shuffle阶段的数据拉取数量(本地化磁盘IO速率)
原文链接：https://blog.csdn.net/weixin_35353187/article/details/84303518
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/spark/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
          
  <div class="pagination-bar">
    <ul class="pagination">
      
        
          <li class="pagination-prev">
            <a class="btn btn--default btn--small" href="https://xiaokunji.github.io/myBlog/post/page/5/" aria-label="NEWER POSTS">
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>NEWER POSTS</span>
            </a>
          </li>
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="https://xiaokunji.github.io/myBlog/post/page/7/" aria-label="OLDER POSTS">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
      
      <li class="pagination-number">page 6 of 40</li>
    </ul>
  </div>


        </section>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2023 Firstname Lastname. All Rights Reserved
  </span>
</footer>

      </div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Firstname Lastname</h4>
    
      <div id="about-card-bio">Super bio with markdown support <strong>COOL</strong></div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Your job title
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        France
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://xiaokunji.github.io/myBlog/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js" integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://xiaokunji.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>


  
    <script async crossorigin="anonymous" defer integrity="sha512-gE8KAQyFIzV1C9+GZ8TKJHZS2s+n7EjNtC+IMRn1l5+WYJTHOODUM6JSjZhFhqXmc7bG8Av6XXpckA4tYhflnw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/apache.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-EWROca+bote+7Oaaar1F6y74iZj1r1F9rm/ly7o+/FwJopbBaWtsFDmaKoZDd3QiGU2pGacBirHJNivmGLYrow==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/go.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-GDVzAn0wpx1yVtQsRWmFc6PhJiLBPdUic+h4GWgljBh904O3JU10fk9EKNpVyIoPqkFn54rgL2QBG4BmUTMpiQ==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/http.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-UgZlma8NzkrDb/NWgmLIcTrH7i/CSnLLDRFqCSNF5NGPpjKmzyM25qcoXGOup8+cDakKyaiTDd7N4dyH4YT+IA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/less.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-lot9koe73sfXIrUvIPM/UEhuMciN56RPyBdOyZgfO53P2lkWyyXN7J+njcxIIBRV+nVDQeiWtiXg+bLAJZDTfg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/nginx.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-Zd3e7XxHP00TD0Imr0PIfeM0fl0v95kMWuhyAS3Wn1UTSXTkz0OhtRgBAr4JlmADRgiXr4x7lpeUdqaGN8xIog==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/puppet.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-qtqDO052iXMSP+5d/aE/jMtL9vIIGvONgTJziC2K/ZIB1yEGa55WVxGE9/08rSQ62EoDifS9SWVGZ7ihSLhzMA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/scss.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-1NmkjnEDnwwwcu28KoQF8vs3oaPFokQHbmbtwGhFfeDsQZtVFI8zW2aE9O8yMYdpdyKV/5blE4pSWw4Z/Sv97w==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/stylus.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-B2wSfruPjr8EJL6IIzQr1eAuDwrsfIfccNf/LCEdxELCgC/S/ZMt/Uvk80aD79m7IqOqW+Sw8nbkvha20yZpzg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/swift.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-28oDiQZGKUVN6wQ7PSLPNipOcmkCALXKwOi7bnkyFf8QiMZQxG9EQoy/iiNx6Zxj2cG2SbVa4dXKigQhu7GiFw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/yaml.min.js"></script>
  


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>




    
  </body>
</html>

