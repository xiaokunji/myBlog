<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <script type="application/ld+json">

{  
  "@context":"http://schema.org",
  "@type":"Website",
  "@id":"https:\/\/xiaokunji.github.io\/myBlog\/",
  "author": {
    "@type": "Person",
    "name": "Firstname Lastname",
    
    "image": "https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c"
    
  },
  "name":"Hugo tranquilpeak theme",
  "description":"Hugo tranquilpeak theme demo",
  "url":"https:\/\/xiaokunji.github.io\/myBlog\/post\/",
  "keywords":"[]"
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.116.1 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="Firstname Lastname">
<meta name="keywords" content="">
<meta name="description" content="Hugo tranquilpeak theme demo">


<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta property="og:type" content="website">
<meta property="og:title" content="Posts">
<meta name="twitter:title" content="Posts">
<meta property="og:url" content="https://xiaokunji.github.io/myBlog/post/">
<meta property="twitter:url" content="https://xiaokunji.github.io/myBlog/post/">
<meta property="og:site_name" content="Hugo tranquilpeak theme">
<meta property="og:description" content="Hugo tranquilpeak theme demo">
<meta name="twitter:description" content="Hugo tranquilpeak theme demo">
<meta property="og:locale" content="en-us">


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=640">






    <title>Posts</title>

    <link rel="icon" href="https://xiaokunji.github.io/myBlog/favicon.png">
    
      <link rel="alternate" type="application/rss+xml" title="RSS" href="https://xiaokunji.github.io/myBlog/post/index.xml">
    

    

    <link rel="canonical" href="https://xiaokunji.github.io/myBlog/post/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://xiaokunji.github.io/myBlog/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://xiaokunji.github.io/myBlog/" aria-label="Go to homepage">Hugo tranquilpeak theme</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://xiaokunji.github.io/myBlog/#about" aria-label="Open the link: /#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://xiaokunji.github.io/myBlog/#about" aria-label="Read more about the author">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Firstname Lastname</h4>
        
          <h5 class="sidebar-profile-bio">Super bio with markdown support <strong>COOL</strong></h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/content" title="我的">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">我的</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/categories" title="Categories">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/tags" title="Tags">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/archives" title="Archives">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/#about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/kakawait" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stackoverflow.com/users/636472/kakawait" target="_blank" rel="noopener" title="Stack Overflow">
    
      <i class="sidebar-button-icon fab fa-lg fa-stack-overflow" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Stack Overflow</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaokunji.github.io/myBlog/index.xml" title="RSS">
    
      <i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <section class="postShorten-group main-content-wrap">
          
          
          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1. 介绍 Hive自定义函数包括三种UDF、UDAF、UDTF
UDF(User-Defined-Function) 一进一出 UDAF(User- Defined Aggregation Funcation) 聚集函数，多进一出。Count/max/min UDTF(User-Defined Table-Generating Functions) 一进多出，如lateral view explore) 2. 函数类型 2.1. UDF(一进一出) 继承UDF类
重写evaluate方法
将该java文件编译成jar
2.2. UDAF(多进一出) 实现方法:
用户的UDAF必须继承了org.apache.hadoop.hive.ql.exec.UDAF；
用户的UDAF必须包含至少一个实现了org.apache.hadoop.hive.ql.exec的静态类，诸如实现了 UDAFEvaluator
一个计算函数必须实现的5个方法的具体含义如下：
init()：主要是负责初始化计算函数并且重设其内部状态，一般就是重设其内部字段。一般在静态类中定义一个内部字段来存放最终的结果。
iterate()：每一次对一个新值进行聚集计算时候都会调用该方法，计算函数会根据聚集计算结果更新内部状态。当输 入值合法或者正确计算了，则 就返回true。
terminatePartial()：Hive需要部分聚集结果的时候会调用该方法，必须要返回一个封装了聚集计算当前状态的对象。
merge()：Hive进行合并一个部分聚集和另一个部分聚集的时候会调用该方法。
terminate()：Hive最终聚集结果的时候就会调用该方法。计算函数需要把状态作为一个值返回给用户。
部分聚集结果的数据类型和最终结果的数据类型可以不同。
2.3. UDTF(一进多出) 继承org.apache.hadoop.hive.ql.udf.generic.GenericUDTF
initialize()：UDTF首先会调用initialize方法，此方法返回UDTF的返回行的信息（返回个数，类型）
process：初始化完成后，会调用process方法,真正的处理过程在process函数中，在process中，每一次forward() 调用产生一行；如果产生多列 可以将多个列的值放在一个数组中，然后将该数组传入到forward()函数
最后close()方法调用，对需要清理的方法进行清理
来自: https://blog.csdn.net/weixin_42181917/article/details/82865140
https://www.cnblogs.com/lrxvx/p/10974341.html
3. 加载函数的方式 3.1 使用add jar [classPath]语句(临时加载) #加载jar add jar [classPath] #创建函数 create temporary function [functionName] as [calssPath] 这种方式不建议在生产环境中使用，通过该方式添加的jar文件只存在于当前会话中，当会话关闭后不能够继续使用该jar文件，最常见的问题是创建了永久函数到metastore中，再次使用该函数时却提示ClassNotFoundException。所以使用该方式每次都要使用add jar [classPath]语句添加相关的jar文件到classPath中。倒是可以用在临时使用函数的情况
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hive/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hue/hue%E4%B8%8Ezeppelin/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        （1）功能
Zeppelin和Hue都能提供一定的数据可视化的功能，都提供了多种图形化数据表示形式。单从这点来说，个人认为功能类似，大同小异，Hue可以通过经纬度进行地图定位，这个功能我在Zeppelin 0.6.0上没有找到。 Zeppelin支持的后端数据查询程序较多，0.6.0版本缺省有18种，原生支持Spark。而Hue的3.9.0版本缺省只支持Hive、Impala、Pig和数据库查询。 Zeppelin只提供了单一的数据处理功能，包括前面提到的数据摄取、数据发现、数据分析、数据可视化等都属于数据处理的范畴。而Hue的功能相对丰富的多，除了类似的数据处理，还有元数据管理、Oozie工作流管理、作业管理、用户管理、Sqoop集成等很多管理功能。从这点看，Zeppelin只是一个数据处理工具，而Hue更像是一个综合管理工具。 （2）架构
Zeppelin采用插件式的翻译器，通过插件开发，可以添加任何后端语言和数据处理程序。相对来说更独立和开放。 Hue与Hadoop生态圈的其它组件密切相关，一般都与CDH一同部署。 （3）使用场景
Zeppelin适合单一数据处理、但后端处理语言繁多的场景，尤其适合Spark。 Hue适合与Hadoop集群的多个组件交互、如Oozie工作流、Sqoop等联合处理数据的场景，尤其适合与Impala协同工作。 来自 &lt;http://blog.csdn.net/wzy0623/article/details/52370045&gt;
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/hue/hue%E4%B8%8Ezeppelin/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/impala/impala%E4%B8%8Ehive/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.Impala和Hive的关系 Impala是基于Hive的大数据实时分析查询引擎，直接使用Hive的元数据库Metadata,意味着impala元数据都存储在Hive的metastore中。并且impala兼容Hive的sql解析，实现了Hive的SQL语义的子集，功能还在不断的完善中。
与Hive的关系
Impala 与Hive都是构建在Hadoop之上的数据查询工具各有不同的侧重适应面，但从客户端使用来看Impala与Hive有很多的共同之处，如数据表元数 据、ODBC/JDBC驱动、SQL语法、灵活的文件格式、存储资源池等。Impala与Hive在Hadoop中的关系如下图所示。
Hive适合于长时间的批处理查询分析，而Impala适合于实时交互式SQL查询，Impala给数据分析人员提供了快速实验、验证想法的大数 据分析工具。可以先使用hive进行数据转换处理，之后使用Impala在Hive处理后的结果数据集上进行快速的数据分析。
2. Impala相对于Hive所使用的优化技术 1、没有使用 MapReduce进行并行计算，虽然MapReduce是非常好的并行计算框架，但它更多的面向批处理模式，而不是面向交互式的SQL执行。与 MapReduce相比：Impala把整个查询分成一执行计划树，而不是一连串的MapReduce任务，在分发执行计划后，Impala使用拉式获取 数据的方式获取结果，把结果数据组成按执行树流式传递汇集，减少的了把中间结果写入磁盘的步骤，再从磁盘读取数据的开销。Impala使用服务的方式避免 每次执行查询都需要启动的开销，即相比Hive没了MapReduce启动时间。 2、使用LLVM产生运行代码，针对特定查询生成特定代码，同时使用Inline的方式减少函数调用的开销，加快执行效率。 3、充分利用可用的硬件指令（SSE4.2）。 4、更好的IO调度，Impala知道数据块所在的磁盘位置能够更好的利用多磁盘的优势，同时Impala支持直接数据块读取和本地代码计算checksum。 5、通过选择合适的数据存储格式可以得到最好的性能（Impala支持多种存储格式）。 6、最大使用内存，中间结果不写磁盘，及时通过网络以stream的方式传递。 3. Impala与Hive的异同 数据存储：使用相同的存储数据池都支持把数据存储于HDFS, HBase。 元数据：两者使用相同的元数据。 SQL****解释处理：比较相似都是通过词法分析生成执行计划。 执行计划：
Hive: 依赖于MapReduce执行框架，执行计划分成 map-&gt;shuffle-&gt;reduce-&gt;map-&gt;shuffle-&gt;reduce…的模型。如果一个Query会 被编译成多轮MapReduce，则会有更多的写中间结果。由于MapReduce执行框架本身的特点，过多的中间过程会增加整个Query的执行时间。 Impala: 把执行计划表现为一棵完整的执行计划树，可以更自然地分发执行计划到各个Impalad执行查询，而不用像Hive那样把它组合成管道型的 map-&gt;reduce模式，以此保证Impala有更好的并发性和避免不必要的中间sort与shuffle。 数据流：
Hive: 采用推的方式，每一个计算节点计算完成后将数据主动推给后续节点。 Impala: 采用拉的方式，后续节点通过getNext主动向前面节点要数据，以此方式数据可以流式的返回给客户端，且只要有1条数据被处理完，就可以立即展现出来，而不用等到全部处理完成，更符合SQL交互式查询使用。 内存使用：
Hive: 在执行过程中如果内存放不下所有数据，则会使用外存，以保证Query能顺序执行完。每一轮MapReduce结束，中间结果也会写入HDFS中，同样由于MapReduce执行架构的特性，shuffle过程也会有写本地磁盘的操作。 Impala: 在遇到内存放不下数据时，当前版本1.0.1是直接返回错误，而不会利用外存，以后版本应该会进行改进。这使用得Impala目前处理Query会受到一 定的限制，最好还是与Hive配合使用。Impala在多个阶段之间利用网络传输数据，在执行过程不会有写磁盘的操作（insert除外）。 调度：
Hive: 任务调度依赖于Hadoop的调度策略。 Impala: 调度由自己完成，目前只有一种调度器simple-schedule，它会尽量满足数据的局部性，扫描数据的进程尽量靠近数据本身所在的物理机器。调度器 目前还比较简单，在SimpleScheduler::GetBackend中可以看到，现在还没有考虑负载，网络IO状况等因素进行调度。但目前 Impala已经有对执行过程的性能统计分析，应该以后版本会利用这些统计信息进行调度吧。 容错：
Hive: 依赖于Hadoop的容错能力。 Impala: 在查询过程中，没有容错逻辑，如果在执行过程中发生故障，则直接返回错误（这与Impala的设计有关，因为Impala定位于实时查询，一次查询失败， 再查一次就好了，再查一次的成本很低）。但从整体来看，Impala是能很好的容错，所有的Impalad是对等的结构，用户可以向任何一个 Impalad提交查询，如果一个Impalad失效，其上正在运行的所有Query都将失败，但用户可以重新提交查询由其它Impalad代替执行，不 会影响服务。对于State Store目前只有一个，但当State Store失效，也不会影响服务，每个Impalad都缓存了State Store的信息，只是不能再更新集群状态，有可能会把执行任务分配给已经失效的Impalad执行，导致本次Query失败。 适用面：
Hive: 复杂的批处理查询任务，数据转换任务。 Impala：实时数据分析，因为不支持UDF，能处理的问题域有一定的限制，与Hive配合使用,对Hive的结果数据集进行实时分析。 来自* &lt;https://www.cnblogs.com/zlslch/p/6785207.html?utm_source=itdadao&amp;utm_medium=referral&gt;
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/impala/impala%E4%B8%8Ehive/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/impala/%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%8E%9F%E7%90%86/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1. 前言 Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。已有的Hive系统虽然也提供了SQL语义，但由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性。相比之下，Impala的最大特点也是最大卖点就是它的快速。但也依赖Hive (impala元数据都存储在Hive的metastore中,或者说两者元数据共存)
来自* &lt;https://baike.baidu.com/item/Impala/7458017?fr=aladdin&gt;
2.Impala核心组件 2.1 Impala Daemon Impala的核心组件是运行在各个节点上面的impalad这个守护进程（Impala daemon），它负责读写数据文件，接收从impala-shell、Hue、JDBC、ODBC等接口发送的查询语句，并行化查询语句和分发工作任务到Impala集群的各个节点上，同时负责将本地计算好的查询结果发送给协调器节点（coordinator node）。
你可以向运行在任意节点的Impala daemon提交查询，这个节点将会作为这个查询的协调器（coordinator node），其他节点将会传输部分结果集给这个协调器节点。由这个协调器节点构建最终的结果集。在做实验或者测试的时候为了方便，我们往往连接到同一个Impala daemon来执行查询，但是在生产环境运行产品级的应用时，我们应该循环（按顺序）的在不同节点上面提交查询，这样才能使得集群的负载达到均衡。
Impala daemon不间断的跟statestore进行通信交流，从而确认哪个节点是健康的能接收新的工作任务。它同时接收catalogd daemon（从Impala 1.2之后支持）传来的广播消息来更新元数据信息，当集群中的任意节点create、alter、drop任意对象、或者执行INSERT、LOAD DATA的时候触发广播消息。
2.2 Impala Statestore Impala Statestore检查集群各个节点上Impala daemon的健康状态，同时不间断地将结果反馈给各个Impala daemon。这个服务的物理进程名称是statestored，在整个集群中我们仅需要一个这样的进程即可。如果某个Impala节点由于硬件错误、软件错误或者其他原因导致离线，statestore就会通知其他的节点，避免其他节点再向这个离线的节点发送请求。
由于statestore是当集群节点有问题的时候起通知作用，所以它对Impala集群并不是有关键影响的。如果statestore没有运行或者运行失败，其他节点和分布式任务会照常运行，只是说当节点掉线的时候集群会变得没那么健壮。当statestore恢复正常运行时，它就又开始与其他节点通信并进行监控。
2.3 Impala Catalog Imppalla catalog服务将SQL语句做出的元数据变化通知给集群的各个节点，catalog服务的物理进程名称是catalogd，在整个集群中仅需要一个这样的进程。由于它的请求会跟statestore daemon交互，所以最好让statestored和catalogd这两个进程在同一节点上。
Impala 1.2中加入的catalog服务减少了REFRESH和INVALIDATE METADATA语句的使用。在之前的版本中，当在某个节点上执行了CREATE DATABASE、DROP DATABASE、CREATE TABLE、ALTER TABLE、或者DROP TABLE语句之后，需要在其它的各个节点上执行命令INVALIDATE METADATA来确保元数据信息的更新。同样的，当你在某个节点上执行了INSERT语句，在其它节点上执行查询时就得先执行REFRESH table_name这个操作，这样才能识别到新增的数据文件。需要注意的是，通过Impala执行的操作带来的元数据变化，有了catalog就不需要再执行REFRESH和INVALIDATE METADATA，但如果是通过Hive进行的建表、加载数据，则仍然需要执行REFRESH和INVALIDATE METADATA来通知Impala更新元数据信息。
来自* &lt;http://www.cnblogs.com/chenz/articles/3947147.html&gt;
3. Impala执行步骤 Impala执行的查询有以下几个步骤：
1. 客户端通过ODBC、JDBC、或者Impala shell向Impala集群中的任意节点发送SQL语句，这个节点的impalad实例作为这个查询的协调器（coordinator）。
2. Impala解析和分析这个查询语句来决定集群中的哪个impalad实例来执行某个任务。
3. HDFS和HBase给本地的impalad实例提供数据访问。
4. 各个impalad向协调器impalad返回数据，然后由协调器impalad向client发送结果集。
来自 &lt;http://www.cnblogs.com/chenz/articles/3947147.html&gt;
Impala为什么比Hive速度快
Impala自称数据查询效率比Hive快几倍甚至数十倍，它之所以这么快的原因大致有以下几点：
真正的MPP查询引擎。 使用C++开发而不是Java，降低运行负荷。 运行时代码生成（LLVM IR），提高效率。 在执行SQL语句的时候，Impala不会把中间数据写入到磁盘，而是在内存中完成了所有的处理。 使用Impala的时候，查询任务会马上执行而不是生产Mapreduce任务，这会节约大量的初始化时间。 Impala查询计划解析器使用更智能的算法在多节点上分布式执行各个查询步骤，同时避免了sorting和shuffle这两个非常耗时的阶段，这两个阶段往往是不需要的。 Impala拥有HDFS上面各个data block的信息，当它处理查询的时候能够在各个datanode上面更均衡的分发查询。 另外一个关键原因是，Impala为每个查询产生汇编级的代码，当Impala在本地内存中运行的时候，这些汇编代码执行效率比其它任何代码框架都更快，因为代码框架会增加额外的延迟。 来自* &lt;http://www.
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/impala/%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%8E%9F%E7%90%86/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/kafka/kafka-stream%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1.1. 目标 本快速入门指南的目标是提供与KafkaStreams的第一个应用程序示例。我们将演示在你的第一个示例程序中，如果使用Kafka Streams库和演示一个简单的端到端的数据流。 值得注意的是，这种快速入门只涵盖了KafkaStreams的表面，这篇文档的剩余部分将会提供更多的细节，我们将在快速入门指南中为你指明方向。
1.2. 我们想做什么 在这个快速入门中，我们将运行包含Apachekafka的一个wordcount演示应用程序。下面代码的关键在于使用Java8的lambda表达式，易于阅读。(摘自WordCountLambdaExample):
[java] view plain copy//序列化/反序列化Sting和Long类型 final Serde&lt;String&gt; stringSerde = Serdes.String(); final Serde&lt;Long&gt; longSerde = Serdes.Long(); //通过指定输入topic “mystream”来构造KStream实例，
//输入数据就以文本的形式保存在topic “mystream” 中。
//(在本示例中，我们忽略所有消息的key.)
KStream&lt;String, String&gt; textLines = builder.stream(stringSerde, stringSerde, &quot;mystream&quot;); KStream&lt;String, Long&gt; wordCounts = textLines
//以空格为分隔符，将每行文本数据拆分成多个单词。
//这些文本行就是从输入topic中读到的每行消息的Value。
//我们使用flatMapValues方法来处理每个消息Value，而不是更通用的flatMap .flatMapValues(value -&gt; Arrays.asList(value.toLowerCase().split(&quot;\\W+&quot;)))
//我们随后将调用countByKey来计算每个单词出现的次数
//所以我们将每个单词作为map的key。
.map((key, value) -&gt; new KeyValue&lt;&gt;(value, value)) //通过key来统计每个单词的次数
//
//这会将流类型从KStream&lt;String,String&gt;转为KTable&lt;String,Long&gt; (word-count).
//因此我们必须提供String和long的序列化反序列化方法。
//
.countByKey(stringSerde, &quot;Counts&quot;) //转化KTable&lt;String,Long&gt;到KStream&lt;String,Long&gt;
.toStream();
//将KStream&lt;String,Long&gt;写入到输出topic中。
wordCounts.to(stringSerde, longSerde, &quot;streams-wordcount-output&quot;); 在上面的代码执行过程中，我们将执行如下步骤：
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/kafka/kafka-stream%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/kafka/kafka%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%8E%9F%E7%90%86/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
1、Kafka使用背景 在我们大量使用分布式数据库、分布式计算集群的时候，是否会遇到这样的一些问题：
a.我们想分析下用户行为（pageviews），以便我们设计出更好的广告位
b.我想对用户的搜索关键词进行统计，分析出当前的流行趋势
c.有些数据，存储数据库浪费，直接存储硬盘效率又低
这些场景都有一个共同点：
数据是由上游模块产生，上游模块，使用上游模块的数据计算、统计、分析，这个时候就可以使用消息系统，尤其是分布式消息系统！
2、Kafka的定义 What is Kafka：它是一个分布式消息系统，由linkedin使用scala编写，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。具有高水平扩展和高吞吐量。
3.kafka的特点 Zookeeper是一种在分布式系统中被广泛用来作为：分布式状态管理、分布式协调管理、分布式配置管理、和分布式锁服务的集群。
kafka增加和减少服务器都会在Zookeeper节点上触发相应的事件kafka系统会捕获这些事件，进行新一轮的负载均衡，客户端也会捕获这些事件来进行新一轮的处理。
Kafka在底层摒弃了Java堆缓存机制，采用了操作系统级别的页缓存，同时将随机写操作改为顺序写，再结合Zero-Copy的特性极大地改善了IO性能。但是，这只是一个方面，毕竟单机优化的能力是有上限的。如何通过水平扩展甚至是线性扩展来进一步提升吞吐量呢？ Kafka就是使用了分区(partition)，通过将topic的消息打散到多个分区并分布保存在不同的broker上实现了消息处理(不管是producer还是consumer)的高吞吐量。
4.Kafka相关概念 1.AMQP协议 Advanced Message Queuing Protocol （高级消息队列协议）
The Advanced Message Queuing Protocol (AMQP)：是一个标准开放的应用层的消息中间件（Message Oriented Middleware）协议。AMQP定义了通过网络发送的字节流的数据格式。因此兼容性非常好，任何实现AMQP协议的程序都可以和与AMQP协议兼容的其他程序交互，可以很容易做到跨语言，跨平台。
上面说的3种比较流行的消息队列协议，要么支持AMQP协议，要么借鉴了AMQP协议的思想进行了开发、实现、设计。
2.什么是消息系统？ ​ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不必担心如何共享数据。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息传递模式可用 - 一种是点对点的，另一种是发布 - 订阅(pub-sub)消息传递系统。 大多数消息传递模式遵循pub-sub。
点对点消息系统 在点对点系统中，消息被保存在一个队列中。 一个或多个消费者可以消费队列中的消息，但是特定的消息只能由最多一个消费者消费。 一旦消费者在队列中读取消息，消息就从该队列中消失。 这个系统的典型例子是一个订单处理系统，其中每个订单将由一个订单处理器处理，但是多订单处理器也可以同时工作。 下图描述了结构。
发布-订阅消息系统 在发布-订阅系统中，消息被保存在一个主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布-订阅系统中，消息生产者称为发布者，消息消费者称为订阅者。 一个真实的例子是Dish TV，它发布体育，电影，音乐等不同的频道，任何人都可以订阅他们自己的一套频道，并在他们的订阅频道可用时获得内容。
来自* &lt;https://www.yiibai.com/kafka/apache_kafka_introduction.html#article-start&gt;
3. 一些基本的概念 1、消费者（Consumer）：从消息队列中请求消息的客户端应用程序
2、生产者（Producer） ：向broker发布消息的应用程序
3、AMQP服务端（broker）：用来接收生产者发送的消息并将这些消息路由给服务器中的队列，便于fafka将生产者发送的消息，动态的添加到磁盘并给每一条消息一个偏移量，所以对于kafka一个broker就是一个应用程序的实例
4、复制因子: 数据的备份数
5、偏移量(offset) : 来表示哪些消息是否被消费,偏移量唯一,消费后只是消费者的偏移量改变了,直到过期消息才会被清除(偏移量有很多,如下图) 来自 http://orchome.
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/kafka/kafka%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%8E%9F%E7%90%86/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title">
      
        <a class="link-unstyled" href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/kafka/kafka%E5%91%BD%E4%BB%A4/" aria-label="Open the post: ">
      
          
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

    </div>
    <div class="postShorten-excerpt">
      
        [toc]
注:kafka依赖zookeeper,所以启动kafka前需开启zookeeper,kafka依赖zookeeper来分发消息,并会在zookeeper中存储分区和broker的信息
1、启动服务 #从后台启动Kafka集群（3台都需要启动）
cd /mysoftware/kafka_2.11-0.10.1.0//bin
#进入到kafka的bin目录
./kafka-server-start.sh -daemon ../config/server.properties
(每台都)启动:
kafka-server-start.sh config/server.properties &gt;/dev/null &amp; 停止: kafka-server-stop.sh &gt;/dev/null &amp; 如果启动报错,必须先停止,才能启动
启动后会有kafka进程
2. 创建Topic ./kafka-topics.sh --create --zookeeper slave02:2181 --replication-factor 2 --partitions 1 --topic mystream
解释
&ndash;replication-factor 2 #复制两份 &ndash;partitions 1 #创建1个分区 &ndash;topic #主题为shuaige 3. 在一台服务器上创建一个发布者(相当于生产者) #创建一个broker，发布者
./kafka-console-producer.sh --broker-list master:9092 --topic shuaige
4 在一台服务器上创建一个订阅者(相当于消费者) &gt;--bootstrap-server 新的kafka,可以用这个参数取代--zookeeper 端口号要变成9092old: kafka-console-consumer.sh --zookeeper localhost:2181 --topic shuaige --from-beginning new: kafka-console-consumer.sh --bootstrap-server master:9092 --topic shuaige --from-beginning 5 、查看topic .
      
      <p>
        
          <a href="https://xiaokunji.github.io/myBlog/post/hadoop%E7%94%9F%E6%80%81%E5%9C%88/kafka/kafka%E5%91%BD%E4%BB%A4/" class="postShorten-excerpt_link link" aria-label="Open the post: ">Continue reading</a>
        
        
      </p>
    </div>
  </div>
  
</article>

          
          
  <div class="pagination-bar">
    <ul class="pagination">
      
        
          <li class="pagination-prev">
            <a class="btn btn--default btn--small" href="https://xiaokunji.github.io/myBlog/post/page/3/" aria-label="NEWER POSTS">
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>NEWER POSTS</span>
            </a>
          </li>
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="https://xiaokunji.github.io/myBlog/post/page/5/" aria-label="OLDER POSTS">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
      
      <li class="pagination-number">page 4 of 40</li>
    </ul>
  </div>


        </section>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2023 Firstname Lastname. All Rights Reserved
  </span>
</footer>

      </div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/d09dc2d7aa5c467519e8af89f7b3d94c?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Firstname Lastname</h4>
    
      <div id="about-card-bio">Super bio with markdown support <strong>COOL</strong></div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Your job title
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        France
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://xiaokunji.github.io/myBlog/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js" integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://xiaokunji.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>


  
    <script async crossorigin="anonymous" defer integrity="sha512-gE8KAQyFIzV1C9+GZ8TKJHZS2s+n7EjNtC+IMRn1l5+WYJTHOODUM6JSjZhFhqXmc7bG8Av6XXpckA4tYhflnw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/apache.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-EWROca+bote+7Oaaar1F6y74iZj1r1F9rm/ly7o+/FwJopbBaWtsFDmaKoZDd3QiGU2pGacBirHJNivmGLYrow==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/go.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-GDVzAn0wpx1yVtQsRWmFc6PhJiLBPdUic+h4GWgljBh904O3JU10fk9EKNpVyIoPqkFn54rgL2QBG4BmUTMpiQ==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/http.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-UgZlma8NzkrDb/NWgmLIcTrH7i/CSnLLDRFqCSNF5NGPpjKmzyM25qcoXGOup8+cDakKyaiTDd7N4dyH4YT+IA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/less.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-lot9koe73sfXIrUvIPM/UEhuMciN56RPyBdOyZgfO53P2lkWyyXN7J+njcxIIBRV+nVDQeiWtiXg+bLAJZDTfg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/nginx.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-Zd3e7XxHP00TD0Imr0PIfeM0fl0v95kMWuhyAS3Wn1UTSXTkz0OhtRgBAr4JlmADRgiXr4x7lpeUdqaGN8xIog==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/puppet.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-qtqDO052iXMSP+5d/aE/jMtL9vIIGvONgTJziC2K/ZIB1yEGa55WVxGE9/08rSQ62EoDifS9SWVGZ7ihSLhzMA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/scss.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-1NmkjnEDnwwwcu28KoQF8vs3oaPFokQHbmbtwGhFfeDsQZtVFI8zW2aE9O8yMYdpdyKV/5blE4pSWw4Z/Sv97w==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/stylus.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-B2wSfruPjr8EJL6IIzQr1eAuDwrsfIfccNf/LCEdxELCgC/S/ZMt/Uvk80aD79m7IqOqW+Sw8nbkvha20yZpzg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/swift.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-28oDiQZGKUVN6wQ7PSLPNipOcmkCALXKwOi7bnkyFf8QiMZQxG9EQoy/iiNx6Zxj2cG2SbVa4dXKigQhu7GiFw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/yaml.min.js"></script>
  


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>




    
  </body>
</html>

